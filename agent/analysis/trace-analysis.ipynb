{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# Filter for LLM spans\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import ijson\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset_path = Path(os.path.abspath('')).parent / \"dataset\"\n",
    "\n",
    "with open('dspy_hashes.json', 'r') as file:\n",
    "    dspy_hashes = json.load(file)\n",
    "with open(\"lm_mapping.json\", \"r\") as file:\n",
    "    lm_mapping = json.load(file)\n",
    "lm_mapping_inverse = {v: k for k, v in lm_mapping.items()}\n",
    "\n",
    "\n",
    "def raw_model_mapper(file_path):\n",
    "    return lm_mapping.get(file_path, file_path)\n",
    "\n",
    "# Helper functions\n",
    "def get_language_model(file_path):\n",
    "    if isinstance(file_path, Path):\n",
    "        file_path = str(file_path)\n",
    "\n",
    "    if not \"meta_llama-3.1-70b-instruct\" in file_path and not \"meta_llama-3.1-405b-instruct\" in file_path:\n",
    "        lm = file_path.split(\"/\")[-2].split(\"_\")[0]\n",
    "    elif \"meta_llama-3.1-405b-instruct\" in file_path:\n",
    "        lm = \"meta_llama-3.1-405b-instruct\"\n",
    "    else: \n",
    "        lm = \"meta_llama-3.1-70b-instruct\"\n",
    "    # Adjust LM names to match the desired format\n",
    "    return raw_model_mapper(lm)\n",
    "\n",
    "def load_solution(solution_path):\n",
    "    with open(solution_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Estimation and Token Sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sum_tokens(lm_name):\n",
    "    total_input_tokens = 0\n",
    "    total_output_tokens = 0\n",
    "    total_total_tokens = 0\n",
    "\n",
    "    subset_input_tokens = 0\n",
    "    subset_output_tokens = 0\n",
    "    subset_total_tokens = 0\n",
    "\n",
    "    message_count = 0\n",
    "\n",
    "    # lm_name is the value of lm_mapping, resolve the key\n",
    "    lm_name = lm_mapping_inverse.get(lm_name, lm_name)\n",
    "\n",
    "    file_pattern = Path(os.path.join(os.path.abspath(\"\"), \"..\", \"dataset\")) / f\"*/out/{lm_name}_augmented_prompt/chat_log.jsonl\"\n",
    "    glob_pattern = glob.glob(file_pattern.as_posix())\n",
    "    assert len(glob_pattern) > 0, f\"No files found for pattern {file_pattern}\"\n",
    "    for filename in glob_pattern:\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    if \"AIMessage\" in data['id']:\n",
    "                        if 'usage_metadata' in data['kwargs']:\n",
    "                            metadata = data['kwargs']['usage_metadata']\n",
    "\n",
    "                            add_to_input = metadata.get('input_tokens', 0) + metadata.get('prompt_token_count', 0)\n",
    "                            add_to_output = metadata.get('output_tokens', 0) + metadata.get('candidates_token_count', 0)\n",
    "                            add_to_total = metadata.get('total_tokens', 0) + metadata.get('total_token_count', 0)\n",
    "\n",
    "                            total_input_tokens += add_to_input\n",
    "                            total_output_tokens += add_to_output\n",
    "                            total_total_tokens += add_to_total\n",
    "\n",
    "                            if any(dspy_hash in filename for dspy_hash in dspy_hashes):\n",
    "                                subset_input_tokens += add_to_input\n",
    "                                subset_output_tokens += add_to_output\n",
    "                                subset_total_tokens += add_to_total\n",
    "\n",
    "                            message_count += 1\n",
    "\n",
    "                        elif 'token_usage' in data['kwargs'].get('response_metadata', {}):\n",
    "                            metadata = data['kwargs']['response_metadata']['token_usage']\n",
    "\n",
    "\n",
    "                            total_input_tokens += metadata.get('prompt_tokens', 0)\n",
    "                            total_output_tokens += metadata.get('completion_tokens', 0)\n",
    "                            total_total_tokens += metadata.get('total_tokens', 0)\n",
    "\n",
    "                            if any(dspy_hash in filename for dspy_hash in dspy_hashes):\n",
    "                                subset_input_tokens += metadata.get('prompt_tokens', 0)\n",
    "                                subset_output_tokens += metadata.get('completion_tokens', 0)\n",
    "                                subset_total_tokens += metadata.get('total_tokens', 0)\n",
    "                            message_count += 1\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON in file {filename}\")\n",
    "\n",
    "    return total_input_tokens, total_output_tokens, message_count, total_total_tokens, subset_input_tokens, subset_output_tokens, subset_total_tokens\n",
    "\n",
    "# Use the file pattern\n",
    "\n",
    "\n",
    "# input_tokens, output_tokens, message_count, total_total_tokens = sum_tokens(\"gemini-1.5-pro\")\n",
    "\n",
    "\n",
    "# print(f\"Total input tokens: {input_tokens:,}\")\n",
    "# print(f\"Total output tokens: {output_tokens:,}\")\n",
    "# print(f\"Total tokens: {input_tokens + output_tokens:,}\")\n",
    "\n",
    "# print(f\"Total total tokens: {total_total_tokens:,}\")\n",
    "# print(f\"Total messages: {message_count:,}\")\n",
    "\n",
    "# print(f\"Average input tokens per message: {input_tokens / message_count:.2f}\")\n",
    "\n",
    "# print()\n",
    "# print(f\"\"\"total_input_tokens = {input_tokens}\n",
    "# total_output_tokens = {output_tokens}\n",
    "# num_invocations = {message_count}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Table total successes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Percentages: 88.25% mean, 93.57% median, 10.57% stdev\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\caption{Agentic Execution with different language models (n=140)}\n",
      "\\label{tab:agentic-execution}\n",
      "\\begin{tabular}{lllrr}\n",
      "\\toprule\n",
      "LM & Attempts & \\begin{tabular}[c]{@{}l@{}}Test\\\\Success\\end{tabular} & \\begin{tabular}[c]{@{}l@{}}Test\\\\Errors\\end{tabular} & \\begin{tabular}[c]{@{}l@{}}Other\\\\Errors\\end{tabular} \\\\\n",
      "\\midrule\n",
      "claude-3.5-sonnet & 140 & 32 & 12 & 96 \\\\\n",
      "gpt-4o & 140 & 17 & 11 & 112 \\\\\n",
      "gpt-4o-mini & 140 & 9 & 8 & 123 \\\\\n",
      "gemini-1.5-pro & 140 & 7 & 2 & 131 \\\\\n",
      "Llama-3.1-70B & 140 & 6 & 2 & 132 \\\\\n",
      "claude-3-haiku & 140 & 6 & 1 & 133 \\\\\n",
      "mistral-nemo & 132 & 1 & 1 & 130 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>Attempts</th>\n",
       "      <th>Test Success</th>\n",
       "      <th>Test Errors</th>\n",
       "      <th>Other Errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>140</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>140</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>140</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-3-haiku</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LM  Attempts  Test Success  Test Errors  Other Errors\n",
       "2  claude-3.5-sonnet       140            32           12            96\n",
       "4             gpt-4o       140            17           11           112\n",
       "5        gpt-4o-mini       140             9            8           123\n",
       "3     gemini-1.5-pro       140             7            2           131\n",
       "0      Llama-3.1-70B       140             6            2           132\n",
       "1     claude-3-haiku       140             6            1           133\n",
       "6       mistral-nemo       132             1            1           130"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = Path(os.path.abspath('')).parent / \"dataset\"\n",
    "\n",
    "generated_graphs_path = Path(os.path.expanduser(\"~/Projects/Masterthesis-paper/generated_graphs\"))\n",
    "\n",
    "\n",
    "def format_percentage(value, total):\n",
    "    percentage = (value / total) * 100\n",
    "    if percentage.is_integer():\n",
    "        return f\"{value} ({int(percentage)}\\\\%)\"\n",
    "    return f\"{value} ({percentage:.1f}\\\\%)\"\n",
    "\n",
    "def split_header_for_latex(header_name: str): \n",
    "    split = header_name.split(\" \")\n",
    "    if len(split) == 1:\n",
    "        return header_name\n",
    "    return '\\\\begin{tabular}[c]{@{}l@{}}' + '\\\\\\\\'.join(split) + '\\\\end{tabular}'\n",
    "\n",
    "# Main processing\n",
    "out_path = dataset_path /\"*/out\"\n",
    "all_commits = set(path.split(\"/\")[-2] for path in glob.glob(out_path.as_posix()))\n",
    "\n",
    "\n",
    "\n",
    "successes = defaultdict(lambda: {'Compilation': [], 'Test': []})\n",
    "non_successes = defaultdict(lambda: {'Failures': []})\n",
    "\n",
    "lm_attempts = defaultdict(set)\n",
    "\n",
    "\n",
    "\n",
    "all_data = []\n",
    "chatlog_path = dataset_path /\"*/out/*/chat_log.jsonl\"\n",
    "for file in glob.glob(chatlog_path.as_posix()):\n",
    "    lm = get_language_model(file)\n",
    "    commit = file.split(\"/\")[-4]\n",
    "    if lm == \"gemini-1.5-flash\":\n",
    "        continue\n",
    "    lm_attempts[lm].add(commit)\n",
    "    \n",
    "    commit_hash = Path(file).parent.parent.parent.name\n",
    "    solution_path = Path(file).parent / \"solution.json\"\n",
    "    error_path = Path(file).parent / \"error.txt\"\n",
    "    \n",
    "    row = {\n",
    "        'LM': lm,\n",
    "        'Commit': commit_hash,\n",
    "        'Attempts': 1,\n",
    "        'Other Errors': 0,\n",
    "        'Test Errors': 0,\n",
    "        'Test Success': 0\n",
    "    }\n",
    "    \n",
    "    if solution_path.exists():\n",
    "        solution = load_solution(solution_path)\n",
    "        if solution[\"compilation_has_succeeded\"] and not solution[\"test_has_succeeded\"]:\n",
    "            row['Test Errors'] = 1\n",
    "            successes[\"agent_\"+lm][\"Compilation\"].append(commit_hash)\n",
    "        if solution[\"test_has_succeeded\"] and solution[\"compilation_has_succeeded\"]:\n",
    "            row['Test Success'] = 1\n",
    "            successes[\"agent_\"+lm][\"Test\"].append(commit_hash)\n",
    "    \n",
    "    if error_path.exists():\n",
    "        row['Other Errors'] = 1\n",
    "        non_successes[\"agent_\"+lm][\"Failures\"].append(commit_hash)\n",
    "    all_data.append(row)\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Filter for dspy_hashes\n",
    "filtered_df = df[df['Commit'].isin(dspy_hashes)]\n",
    "\n",
    "aggregation_params = {\n",
    "    'Attempts': 'sum',\n",
    "    'Test Success': 'sum',\n",
    "    'Test Errors': 'sum',\n",
    "    'Other Errors': 'sum',\n",
    "}\n",
    "\n",
    "# Aggregate data\n",
    "success_df = df.groupby('LM').agg(aggregation_params).reset_index().sort_values('Test Success', ascending=False)\n",
    "\n",
    "success_65_df = filtered_df.groupby('LM').agg(aggregation_params).reset_index().sort_values('Test Success', ascending=False)\n",
    "\n",
    "\n",
    "success_df['Error Percentage'] = (success_df['Other Errors'] / success_df['Attempts']) * 100\n",
    "\n",
    "# Calculate mean, median, and standard deviation of the error percentages\n",
    "mean_error_percentage = success_df['Error Percentage'].mean()\n",
    "median_error_percentage = success_df['Error Percentage'].median()\n",
    "stdev_error_percentage = success_df['Error Percentage'].std()\n",
    "\n",
    "print(\"Error Percentages: {:.2f}% mean, {:.2f}% median, {:.2f}% stdev\".format(\n",
    "    mean_error_percentage, \n",
    "    median_error_percentage, \n",
    "    stdev_error_percentage\n",
    "))\n",
    "success_df = success_df.drop('Error Percentage', axis=1)\n",
    "\n",
    "columns = success_df.columns\n",
    "\n",
    "\n",
    "# Prepare column names for LaTeX\n",
    "latex_columns = [split_header_for_latex(col) for col in columns]\n",
    "success_df.columns = latex_columns\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = success_df.to_latex(index=False, \n",
    "                          escape=False, \n",
    "                          column_format='lllrr',\n",
    "                          caption=f\"Agentic Execution with different language models (n={len(all_commits)})\",\n",
    "                          position=\"H\",\n",
    "                          label=\"tab:agentic-execution\")\n",
    "print()\n",
    "\n",
    "print(latex_table)\n",
    "\n",
    "if generated_graphs_path.exists():\n",
    "    with open(generated_graphs_path / \"agentic_execution_table.tex\", \"w\") as f:\n",
    "        f.write(latex_table)\n",
    "\n",
    "print()\n",
    "missing_commits = {lm: all_commits - attempts for lm, attempts in lm_attempts.items()}\n",
    "\n",
    "# Reset column names for further processing if needed\n",
    "success_df.columns = columns\n",
    "\n",
    "success_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersections between Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x74a02f5d98a0>, {'agent_gpt-4o-mini': {'Compilation': ['489aad6060454d0b7b34a144e0b345c5a3a199f5', '8502e85f9ee2ff90ce96b47b5904f011e81e8bb8', 'b6a48a6e557fad1ceda680618e0a34c7b8c5c087', 'af6e5d1cc94f031f29b4838e7a8b56704c8c5de4', 'ad80bdff62b1b0520d3fb9e8d627532a38a7c60c', '250cafc7d6ae47d5d4803b5a5e58186eb81fa3b5', 'c3818c076f0c088d1d11b7812b880be579c19ec2', '14fc5fa696f499cac48401b3a86882b3bf7d9b82'], 'Test': ['0a11c04038eae517540051dbf51f7f26b7221f20', '36859167815292f279e570d39dd2ddbcf1622dc6', '0abf7148300f40a1da0538ab060552bca4a2f1d8', 'cd5bb39f43e4570b875027073da3d4e43349ead1', '165381d26b2c3d2278fde88c16f95807506451fe', 'ff8b5b61548d50cf60b77784a181e917cb35033b', '5769bdad76925da568294cb8a40e7d4469699ac3', '6c53cd904bd66fc79af8687571e607c259226b81', '0305beafdecb0b28f7c94264ed20cdc4e41ff067']}, 'agent_claude-3.5-sonnet': {'Compilation': ['489aad6060454d0b7b34a144e0b345c5a3a199f5', '8502e85f9ee2ff90ce96b47b5904f011e81e8bb8', 'a2b0fc53611f8705640773f18c8dd6a47eed3b7f', 'b6a48a6e557fad1ceda680618e0a34c7b8c5c087', 'a4c360001134c2e3a9f7fbde88a07a9fd767e78e', 'af6e5d1cc94f031f29b4838e7a8b56704c8c5de4', 'ad80bdff62b1b0520d3fb9e8d627532a38a7c60c', '250cafc7d6ae47d5d4803b5a5e58186eb81fa3b5', 'c3818c076f0c088d1d11b7812b880be579c19ec2', '14fc5fa696f499cac48401b3a86882b3bf7d9b82', '067f5d2c81ff87c90755f4ed48f62eb5faa8ecf9', 'a784b326d0821fc03fe6c5c13053424f8c2c358e'], 'Test': ['bd3ce213e2771c6ef7817c80818807a757d4e94a', 'c7c9590a206d4fb77dd05b9df391d888e6181667', 'e40f76d1150d41821ccfd72e9dd3fabbc8763c1e', '500d9c021d34b307b1a70d3f29fb7f9b5ab9d1a6', '54857351e0b0a655970d7e2ccdb67f175cc5d688', '06c5386831e97e94d9b9fd155d3ea4aa8711c4e7', '3ff575ae202cdf76ddfa8a4228a1711a6fa1e921', '0a11c04038eae517540051dbf51f7f26b7221f20', '1ef97ea6c5b6e34151fe6167001b69e003449f95', 'c09896887acf0fe59320e01145a7034cd8d4e326', '42a220bd546d293886df0d5e3892cc3ff82f1091', '36859167815292f279e570d39dd2ddbcf1622dc6', '0abf7148300f40a1da0538ab060552bca4a2f1d8', '441f7f07d9265cc1d4c4f369ee6524973d9c6e17', '5cf5a482bd430d81257b4ecd85b3d4f7da911621', '165381d26b2c3d2278fde88c16f95807506451fe', 'ff8b5b61548d50cf60b77784a181e917cb35033b', '88c1f903cede03ff371059cdaf009dab12007043', '5769bdad76925da568294cb8a40e7d4469699ac3', '24d4a90ec1b375751e71f33d18949405c9529d77', '8ab7a7214f9ac1d130b416fae7280cfda533a54f', '07e4b2894bc68cd3bb1892beaa13ec353564dcf1', 'b8f92ff37d1aed054d8320283fd6d6a492703a55', '40feecdd9c649644668d7c84bb87b73a2b2723ca', '6c53cd904bd66fc79af8687571e607c259226b81', '16ae40b1e17e14ee3ae20ac211647e47399a01a9', 'dbdc7d2c4a28a8d65edcd0cdece91c0bc357b869', '6ad104c4fb9263ad1bb29e6b33618b8225efd92d', '18eff0121ded81b30af0924676407bfc663e6557', '741f3b5e20a91b0e9305ae79261e3c5e64971c98', '979d6237a50840cd925cc1a33c415ffbbbc42846', '7e8c62e2bb21097e563747184636cf8e8934ce98']}, 'agent_gpt-4o': {'Compilation': ['489aad6060454d0b7b34a144e0b345c5a3a199f5', '8502e85f9ee2ff90ce96b47b5904f011e81e8bb8', 'a2b0fc53611f8705640773f18c8dd6a47eed3b7f', 'b6a48a6e557fad1ceda680618e0a34c7b8c5c087', 'a4c360001134c2e3a9f7fbde88a07a9fd767e78e', 'af6e5d1cc94f031f29b4838e7a8b56704c8c5de4', 'ad80bdff62b1b0520d3fb9e8d627532a38a7c60c', '250cafc7d6ae47d5d4803b5a5e58186eb81fa3b5', 'c3818c076f0c088d1d11b7812b880be579c19ec2', '14fc5fa696f499cac48401b3a86882b3bf7d9b82', 'a784b326d0821fc03fe6c5c13053424f8c2c358e'], 'Test': ['e40f76d1150d41821ccfd72e9dd3fabbc8763c1e', '54857351e0b0a655970d7e2ccdb67f175cc5d688', '3ff575ae202cdf76ddfa8a4228a1711a6fa1e921', '0a11c04038eae517540051dbf51f7f26b7221f20', '1ef97ea6c5b6e34151fe6167001b69e003449f95', 'c09896887acf0fe59320e01145a7034cd8d4e326', '36859167815292f279e570d39dd2ddbcf1622dc6', '0abf7148300f40a1da0538ab060552bca4a2f1d8', '28be199c825d419957bc753a9519e8e9ecc6a08e', '5769bdad76925da568294cb8a40e7d4469699ac3', 'f9763c18c7e1fa54fb67dcf3935aa5106807aba9', '6c53cd904bd66fc79af8687571e607c259226b81', '979d6237a50840cd925cc1a33c415ffbbbc42846', '7e8c62e2bb21097e563747184636cf8e8934ce98', '26fd1cd7639b7deb7078df5e4cb05c6d463ad07a', '3a4a2b11483689ca3e99e92785a7b27c56d072b8', '0305beafdecb0b28f7c94264ed20cdc4e41ff067']}, 'agent_Llama-3.1-70B': {'Compilation': ['af6e5d1cc94f031f29b4838e7a8b56704c8c5de4', 'c3818c076f0c088d1d11b7812b880be579c19ec2'], 'Test': ['c7c9590a206d4fb77dd05b9df391d888e6181667', '54857351e0b0a655970d7e2ccdb67f175cc5d688', '0abf7148300f40a1da0538ab060552bca4a2f1d8', 'ff8b5b61548d50cf60b77784a181e917cb35033b', '88c1f903cede03ff371059cdaf009dab12007043', '16ae40b1e17e14ee3ae20ac211647e47399a01a9']}, 'agent_claude-3-haiku': {'Compilation': ['a784b326d0821fc03fe6c5c13053424f8c2c358e'], 'Test': ['54857351e0b0a655970d7e2ccdb67f175cc5d688', '88c1f903cede03ff371059cdaf009dab12007043', '6c53cd904bd66fc79af8687571e607c259226b81', '16ae40b1e17e14ee3ae20ac211647e47399a01a9', '1cc7071371953a7880c2c2c3a5a32c36af7f88f9', '0305beafdecb0b28f7c94264ed20cdc4e41ff067']}, 'agent_gemini-1.5-pro': {'Compilation': ['c3818c076f0c088d1d11b7812b880be579c19ec2', 'a784b326d0821fc03fe6c5c13053424f8c2c358e'], 'Test': ['42a220bd546d293886df0d5e3892cc3ff82f1091', '36859167815292f279e570d39dd2ddbcf1622dc6', '165381d26b2c3d2278fde88c16f95807506451fe', 'ff8b5b61548d50cf60b77784a181e917cb35033b', '6c53cd904bd66fc79af8687571e607c259226b81', '46979207151a43361447d64afd2658df40033419', '979d6237a50840cd925cc1a33c415ffbbbc42846']}, 'agent_mistral-nemo': {'Compilation': ['b6a48a6e557fad1ceda680618e0a34c7b8c5c087'], 'Test': ['ff8b5b61548d50cf60b77784a181e917cb35033b']}})\n",
      "{'Compilation': ['489aad6060454d0b7b34a144e0b345c5a3a199f5', '8502e85f9ee2ff90ce96b47b5904f011e81e8bb8', 'b6a48a6e557fad1ceda680618e0a34c7b8c5c087', 'af6e5d1cc94f031f29b4838e7a8b56704c8c5de4', 'ad80bdff62b1b0520d3fb9e8d627532a38a7c60c', '250cafc7d6ae47d5d4803b5a5e58186eb81fa3b5', 'c3818c076f0c088d1d11b7812b880be579c19ec2', '14fc5fa696f499cac48401b3a86882b3bf7d9b82'], 'Test': ['0a11c04038eae517540051dbf51f7f26b7221f20', '36859167815292f279e570d39dd2ddbcf1622dc6', '0abf7148300f40a1da0538ab060552bca4a2f1d8', 'cd5bb39f43e4570b875027073da3d4e43349ead1', '165381d26b2c3d2278fde88c16f95807506451fe', 'ff8b5b61548d50cf60b77784a181e917cb35033b', '5769bdad76925da568294cb8a40e7d4469699ac3', '6c53cd904bd66fc79af8687571e607c259226b81', '0305beafdecb0b28f7c94264ed20cdc4e41ff067']}\n",
      "{'Compilation': ['489aad6060454d0b7b34a144e0b345c5a3a199f5', '8502e85f9ee2ff90ce96b47b5904f011e81e8bb8', 'a2b0fc53611f8705640773f18c8dd6a47eed3b7f', 'b6a48a6e557fad1ceda680618e0a34c7b8c5c087', 'a4c360001134c2e3a9f7fbde88a07a9fd767e78e', 'af6e5d1cc94f031f29b4838e7a8b56704c8c5de4', 'ad80bdff62b1b0520d3fb9e8d627532a38a7c60c', '250cafc7d6ae47d5d4803b5a5e58186eb81fa3b5', 'c3818c076f0c088d1d11b7812b880be579c19ec2', '14fc5fa696f499cac48401b3a86882b3bf7d9b82', '067f5d2c81ff87c90755f4ed48f62eb5faa8ecf9', 'a784b326d0821fc03fe6c5c13053424f8c2c358e'], 'Test': ['bd3ce213e2771c6ef7817c80818807a757d4e94a', 'c7c9590a206d4fb77dd05b9df391d888e6181667', 'e40f76d1150d41821ccfd72e9dd3fabbc8763c1e', '500d9c021d34b307b1a70d3f29fb7f9b5ab9d1a6', '54857351e0b0a655970d7e2ccdb67f175cc5d688', '06c5386831e97e94d9b9fd155d3ea4aa8711c4e7', '3ff575ae202cdf76ddfa8a4228a1711a6fa1e921', '0a11c04038eae517540051dbf51f7f26b7221f20', '1ef97ea6c5b6e34151fe6167001b69e003449f95', 'c09896887acf0fe59320e01145a7034cd8d4e326', '42a220bd546d293886df0d5e3892cc3ff82f1091', '36859167815292f279e570d39dd2ddbcf1622dc6', '0abf7148300f40a1da0538ab060552bca4a2f1d8', '441f7f07d9265cc1d4c4f369ee6524973d9c6e17', '5cf5a482bd430d81257b4ecd85b3d4f7da911621', '165381d26b2c3d2278fde88c16f95807506451fe', 'ff8b5b61548d50cf60b77784a181e917cb35033b', '88c1f903cede03ff371059cdaf009dab12007043', '5769bdad76925da568294cb8a40e7d4469699ac3', '24d4a90ec1b375751e71f33d18949405c9529d77', '8ab7a7214f9ac1d130b416fae7280cfda533a54f', '07e4b2894bc68cd3bb1892beaa13ec353564dcf1', 'b8f92ff37d1aed054d8320283fd6d6a492703a55', '40feecdd9c649644668d7c84bb87b73a2b2723ca', '6c53cd904bd66fc79af8687571e607c259226b81', '16ae40b1e17e14ee3ae20ac211647e47399a01a9', 'dbdc7d2c4a28a8d65edcd0cdece91c0bc357b869', '6ad104c4fb9263ad1bb29e6b33618b8225efd92d', '18eff0121ded81b30af0924676407bfc663e6557', '741f3b5e20a91b0e9305ae79261e3c5e64971c98', '979d6237a50840cd925cc1a33c415ffbbbc42846', '7e8c62e2bb21097e563747184636cf8e8934ce98']}\n",
      "{'Compilation': ['489aad6060454d0b7b34a144e0b345c5a3a199f5', '8502e85f9ee2ff90ce96b47b5904f011e81e8bb8', 'a2b0fc53611f8705640773f18c8dd6a47eed3b7f', 'b6a48a6e557fad1ceda680618e0a34c7b8c5c087', 'a4c360001134c2e3a9f7fbde88a07a9fd767e78e', 'af6e5d1cc94f031f29b4838e7a8b56704c8c5de4', 'ad80bdff62b1b0520d3fb9e8d627532a38a7c60c', '250cafc7d6ae47d5d4803b5a5e58186eb81fa3b5', 'c3818c076f0c088d1d11b7812b880be579c19ec2', '14fc5fa696f499cac48401b3a86882b3bf7d9b82', 'a784b326d0821fc03fe6c5c13053424f8c2c358e'], 'Test': ['e40f76d1150d41821ccfd72e9dd3fabbc8763c1e', '54857351e0b0a655970d7e2ccdb67f175cc5d688', '3ff575ae202cdf76ddfa8a4228a1711a6fa1e921', '0a11c04038eae517540051dbf51f7f26b7221f20', '1ef97ea6c5b6e34151fe6167001b69e003449f95', 'c09896887acf0fe59320e01145a7034cd8d4e326', '36859167815292f279e570d39dd2ddbcf1622dc6', '0abf7148300f40a1da0538ab060552bca4a2f1d8', '28be199c825d419957bc753a9519e8e9ecc6a08e', '5769bdad76925da568294cb8a40e7d4469699ac3', 'f9763c18c7e1fa54fb67dcf3935aa5106807aba9', '6c53cd904bd66fc79af8687571e607c259226b81', '979d6237a50840cd925cc1a33c415ffbbbc42846', '7e8c62e2bb21097e563747184636cf8e8934ce98', '26fd1cd7639b7deb7078df5e4cb05c6d463ad07a', '3a4a2b11483689ca3e99e92785a7b27c56d072b8', '0305beafdecb0b28f7c94264ed20cdc4e41ff067']}\n",
      "{'Compilation': ['af6e5d1cc94f031f29b4838e7a8b56704c8c5de4', 'c3818c076f0c088d1d11b7812b880be579c19ec2'], 'Test': ['c7c9590a206d4fb77dd05b9df391d888e6181667', '54857351e0b0a655970d7e2ccdb67f175cc5d688', '0abf7148300f40a1da0538ab060552bca4a2f1d8', 'ff8b5b61548d50cf60b77784a181e917cb35033b', '88c1f903cede03ff371059cdaf009dab12007043', '16ae40b1e17e14ee3ae20ac211647e47399a01a9']}\n",
      "{'Compilation': ['a784b326d0821fc03fe6c5c13053424f8c2c358e'], 'Test': ['54857351e0b0a655970d7e2ccdb67f175cc5d688', '88c1f903cede03ff371059cdaf009dab12007043', '6c53cd904bd66fc79af8687571e607c259226b81', '16ae40b1e17e14ee3ae20ac211647e47399a01a9', '1cc7071371953a7880c2c2c3a5a32c36af7f88f9', '0305beafdecb0b28f7c94264ed20cdc4e41ff067']}\n",
      "{'Compilation': ['c3818c076f0c088d1d11b7812b880be579c19ec2', 'a784b326d0821fc03fe6c5c13053424f8c2c358e'], 'Test': ['42a220bd546d293886df0d5e3892cc3ff82f1091', '36859167815292f279e570d39dd2ddbcf1622dc6', '165381d26b2c3d2278fde88c16f95807506451fe', 'ff8b5b61548d50cf60b77784a181e917cb35033b', '6c53cd904bd66fc79af8687571e607c259226b81', '46979207151a43361447d64afd2658df40033419', '979d6237a50840cd925cc1a33c415ffbbbc42846']}\n",
      "{'Compilation': ['b6a48a6e557fad1ceda680618e0a34c7b8c5c087'], 'Test': ['ff8b5b61548d50cf60b77784a181e917cb35033b']}\n",
      "\\begin{table}[H]\n",
      "\\caption{Frequency of Intersections between LLMs for Compilation and Test categories}\n",
      "\\label{tab:intersection-frequency}\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "LLM-Intersections & 0 & 1 & 2 & 3 & 4 \\\\\n",
      "\\midrule\n",
      "Compilation (%) & 8.33 & 16.67 & 41.67 & 25.00 & 8.33 \\\\\n",
      "Test (%) & 52.50 & 17.50 & 17.50 & 7.50 & 5.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "compilation_intersections = defaultdict(set)\n",
    "test_intersections = defaultdict(set)\n",
    "\n",
    "print(successes)\n",
    "\n",
    "\n",
    "\n",
    "# Fill the dictionaries with hash values from each agent\n",
    "for agent, results in successes.items():\n",
    "    print(results)\n",
    "    for hash_value in results['Compilation']:\n",
    "        compilation_intersections[hash_value].add(agent)\n",
    "    for hash_value in results['Test']:\n",
    "        test_intersections[hash_value].add(agent)\n",
    "\n",
    "# Create a DataFrame to show intersections at the commit level with count and shortened hashes\n",
    "commit_data = []\n",
    "\n",
    "for hash_value, agents in compilation_intersections.items():\n",
    "    if len(agents) > 0:\n",
    "        commit_data.append({'Type': 'Compilation', 'Hash': hash_value, 'Count': len(agents)})\n",
    "\n",
    "for hash_value, agents in test_intersections.items():\n",
    "    if len(agents) > 0:\n",
    "        commit_data.append({'Type': 'Test', 'Hash': hash_value, 'Count': len(agents)})\n",
    "\n",
    "commit_df_short = pd.DataFrame(commit_data)\n",
    "\n",
    "\n",
    "# Sort by count and take top 5 for each type\n",
    "top_compilation = commit_df_short[commit_df_short['Type'] == 'Compilation'].nlargest(4, 'Count')\n",
    "top_test = commit_df_short[commit_df_short['Type'] == 'Test'].nlargest(4, 'Count')\n",
    "\n",
    "# Combine top entries\n",
    "top_commits = pd.concat([top_compilation, top_test])\n",
    "\n",
    "# Set multiindex\n",
    "top_commits.set_index(['Type', 'Hash'], inplace=True)\n",
    "\n",
    "# Convert DataFrame to LaTeX table with booktabs and multiindex\n",
    "commit_latex_table_top = top_commits.T.to_latex(index=True, multirow=True, header=True, caption=\"Top 3 intersections for Compilation and Test categories\", label=\"tab:top-intersections\", position=\"H\")\n",
    "\n",
    "# print(commit_latex_table_top)\n",
    "\n",
    "# top_commits\n",
    "# Filter rows for Compilation and Test types\n",
    "unique_compilation = commit_df_short[commit_df_short['Type'] == 'Compilation']\n",
    "unique_test = commit_df_short[commit_df_short['Type'] == 'Test']\n",
    "\n",
    "# Get the frequency of each value in the 'Count' column for Compilation\n",
    "compilation_count_frequency = unique_compilation['Count'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "# Get the frequency of each value in the 'Count' column for Test as a percentage\n",
    "test_count_frequency = unique_test['Count'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "# Combine both frequencies into a single DataFrame\n",
    "combined_frequency = pd.DataFrame({\n",
    "    'Compilation (%)': compilation_count_frequency,\n",
    "    'Test (%)': test_count_frequency\n",
    "}).fillna(0)  # Fill NaN values with 0\n",
    "\n",
    "combined_frequency.index = combined_frequency.index - 1\n",
    "\n",
    "combined_frequency.index.name = 'LLM-Intersections'\n",
    "\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = combined_frequency.to_latex(index=True, float_format=\"%.2f\", caption=\"Frequency of Intersections between LLMs for Compilation and Test categories\", label=\"tab:intersection-frequency\", position=\"H\")\n",
    "\n",
    "# print(latex_table)\n",
    "\n",
    "\n",
    "# print()\n",
    "\n",
    "print(combined_frequency.T.to_latex(index=True, float_format=\"%.2f\", caption=\"Frequency of Intersections between LLMs for Compilation and Test categories\", label=\"tab:intersection-frequency\", position=\"H\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Commits per language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mistral-nemo - Missing 8 commits:\n",
      "[\n",
      "  \"24d4a90ec1b375751e71f33d18949405c9529d77\",\n",
      "  \"2dfaa41bfb97674d11f09a5885011f19808548a3\",\n",
      "  \"54857351e0b0a655970d7e2ccdb67f175cc5d688\",\n",
      "  \"41ec14e7e0ccf28476905eb28b2155b11d8a55f5\",\n",
      "  \"923a6b2027e3ca1762deb6a60fc0a768c284122b\",\n",
      "  \"867e69e208ff59d1f8baae7ed41d3e163a51bc65\",\n",
      "  \"cb541fd65c7b9bbc3424ea927f1dab223261d156\",\n",
      "  \"5769bdad76925da568294cb8a40e7d4469699ac3\"\n",
      "]\n",
      "\n",
      "Overall Statistics:\n",
      "Total Commits: 140\n",
      "Percentage of Commits Attempted by at least one LM: 100.00%\n",
      "Analysis of Missing Commits by Language Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>Missing Commits</th>\n",
       "      <th>Total Commits</th>\n",
       "      <th>Attempted Commits</th>\n",
       "      <th>Percentage Missing</th>\n",
       "      <th>Percentage Attempted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>8</td>\n",
       "      <td>140</td>\n",
       "      <td>132</td>\n",
       "      <td>5.71</td>\n",
       "      <td>94.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-3-haiku</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LM  Missing Commits  Total Commits  Attempted Commits  \\\n",
       "4       mistral-nemo                8            140                132   \n",
       "1        gpt-4o-mini                0            140                140   \n",
       "0     claude-3-haiku                0            140                140   \n",
       "2      Llama-3.1-70B                0            140                140   \n",
       "3  claude-3.5-sonnet                0            140                140   \n",
       "5     gemini-1.5-pro                0            140                140   \n",
       "6             gpt-4o                0            140                140   \n",
       "\n",
       "   Percentage Missing  Percentage Attempted  \n",
       "4                5.71                 94.29  \n",
       "1                0.00                100.00  \n",
       "0                0.00                100.00  \n",
       "2                0.00                100.00  \n",
       "3                0.00                100.00  \n",
       "5                0.00                100.00  \n",
       "6                0.00                100.00  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Get attempted commits for each LM\n",
    "\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df_missing = pd.DataFrame({\n",
    "    'LM': list(missing_commits.keys()),\n",
    "    'Missing Commits': [len(commits) for commits in missing_commits.values()],\n",
    "    'Total Commits': len(all_commits),\n",
    "    'Attempted Commits': [len(all_commits) - len(commits) for commits in missing_commits.values()],\n",
    "})\n",
    "\n",
    "df_missing['Percentage Missing'] = (df_missing['Missing Commits'] / df_missing['Total Commits'] * 100).round(2)\n",
    "df_missing['Percentage Attempted'] = (df_missing['Attempted Commits'] / df_missing['Total Commits'] * 100).round(2)\n",
    "\n",
    "# Sort by percentage missing in descending order\n",
    "df_missing = df_missing.sort_values('Percentage Missing', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# Optional: Display the actual missing commit hashes for each LM\n",
    "# print(\"\\nDetailed Missing Commits by LM:\")\n",
    "for lm, commits in missing_commits.items():\n",
    "    if commits:\n",
    "        print(f\"\\n{lm} - Missing {len(commits)} commits:\")\n",
    "        print(json.dumps(list(commits), indent=2))\n",
    "        # for commit in sorted(commits):\n",
    "        #     print(f\"  {commit}\")\n",
    "\n",
    "# Calculate overall statistics\n",
    "total_attempts = sum(len(attempts) for attempts in lm_attempts.values())\n",
    "unique_attempts = len(set.union(*lm_attempts.values()))\n",
    "overall_missing = len(all_commits) - unique_attempts\n",
    "\n",
    "print(f\"\\nOverall Statistics:\")\n",
    "print(f\"Total Commits: {len(all_commits)}\")\n",
    "# print(f\"Unique Attempted Commits: {unique_attempts}\")\n",
    "# print(f\"Overall Missing Commits: {overall_missing}\")\n",
    "print(f\"Percentage of Commits Attempted by at least one LM: {(unique_attempts / len(all_commits) * 100):.2f}%\")\n",
    "\n",
    "print(\"Analysis of Missing Commits by Language Model:\")\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation of Performance to Berkeley Function Calling Leaderboard\n",
    "```\n",
    "@misc{berkeley-function-calling-leaderboard,\n",
    "    title={Berkeley Function Calling Leaderboard}, \n",
    "    author={Fanjia Yan and Huanzhi Mao and Charlie Cheng-Jie Ji\n",
    "    and Tianjun Zhang and Shishir G. Patil and Ion Stoica and Joseph E.\n",
    "    Gonzalez},\n",
    "    howpublished={\\url{https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html}},\n",
    "    year={2024},\n",
    "}\n",
    "```\n",
    "\n",
    "Version used: 2024-07-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_690398/2028199607.py:7: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  function_calling_leaderboard = function_calling_leaderboard[~function_calling_leaderboard['Model'].str.contains(\"(Prompt)\")]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Overall Acc</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Link</th>\n",
       "      <th>Organization</th>\n",
       "      <th>License</th>\n",
       "      <th>AST Summary</th>\n",
       "      <th>Python Simple AST</th>\n",
       "      <th>Python Multiple AST</th>\n",
       "      <th>Python Parallel AST</th>\n",
       "      <th>Python Parallel Multiple AST</th>\n",
       "      <th>Irrelevance Detection</th>\n",
       "      <th>Relevance Detection</th>\n",
       "      <th>Cost ($ Per 1k Function Calls)</th>\n",
       "      <th>Latency Mean (s)</th>\n",
       "      <th>Latency Standard Deviation (s)</th>\n",
       "      <th>Latency 95th Percentile (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>74.54%</td>\n",
       "      <td>GPT-4-0613 (FC)</td>\n",
       "      <td>https://platform.openai.com/docs/models/gpt-4-...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>73.26%</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>77.72%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>76.57%</td>\n",
       "      <td>73.17%</td>\n",
       "      <td>15.36</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.84</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>73.39%</td>\n",
       "      <td>GPT-4-turbo-2024-04-09 (FC)</td>\n",
       "      <td>https://platform.openai.com/docs/models/gpt-4-...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>72.96%</td>\n",
       "      <td>67.83%</td>\n",
       "      <td>74.45%</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>62.50%</td>\n",
       "      <td>74.17%</td>\n",
       "      <td>70.73%</td>\n",
       "      <td>6.24</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.33</td>\n",
       "      <td>8.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>71.79%</td>\n",
       "      <td>GPT-4o-2024-08-06 (FC)</td>\n",
       "      <td>https://openai.com/index/hello-gpt-4o/</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>69.14%</td>\n",
       "      <td>67.83%</td>\n",
       "      <td>69.43%</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>76.23%</td>\n",
       "      <td>63.41%</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>71.70%</td>\n",
       "      <td>Gemini-1.5-Pro-Preview-0409 (FC)</td>\n",
       "      <td>https://deepmind.google/technologies/gemini/#i...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>67.42%</td>\n",
       "      <td>62.40%</td>\n",
       "      <td>68.85%</td>\n",
       "      <td>81.25%</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>78.63%</td>\n",
       "      <td>63.41%</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.07</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>71.39%</td>\n",
       "      <td>Claude-3.5-Sonnet-20240620 (FC)</td>\n",
       "      <td>https://www.anthropic.com/news/claude-3-5-sonnet</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>71.09%</td>\n",
       "      <td>72.48%</td>\n",
       "      <td>70.68%</td>\n",
       "      <td>68.75%</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>72.23%</td>\n",
       "      <td>63.41%</td>\n",
       "      <td>5.31</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.16</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>71.26%</td>\n",
       "      <td>Functionary-Medium-v3.1 (FC)</td>\n",
       "      <td>https://huggingface.co/meetkai/functionary-med...</td>\n",
       "      <td>MeetKai</td>\n",
       "      <td>MIT</td>\n",
       "      <td>77.15%</td>\n",
       "      <td>72.09%</td>\n",
       "      <td>78.69%</td>\n",
       "      <td>68.75%</td>\n",
       "      <td>70.83%</td>\n",
       "      <td>62.29%</td>\n",
       "      <td>70.73%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.45</td>\n",
       "      <td>13.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>71.12%</td>\n",
       "      <td>Gemini-1.5-Pro-Preview-0514 (FC)</td>\n",
       "      <td>https://deepmind.google/technologies/gemini/pro/</td>\n",
       "      <td>Google</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>66.82%</td>\n",
       "      <td>61.63%</td>\n",
       "      <td>68.27%</td>\n",
       "      <td>81.25%</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>78.29%</td>\n",
       "      <td>58.54%</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.14</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>70.99%</td>\n",
       "      <td>GPT-4-0125-Preview (FC)</td>\n",
       "      <td>https://platform.openai.com/docs/models/gpt-4-...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>74.38%</td>\n",
       "      <td>69.77%</td>\n",
       "      <td>75.89%</td>\n",
       "      <td>68.75%</td>\n",
       "      <td>62.50%</td>\n",
       "      <td>65.14%</td>\n",
       "      <td>85.37%</td>\n",
       "      <td>6.49</td>\n",
       "      <td>3.37</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>70.81%</td>\n",
       "      <td>Gemini-1.5-Flash-Preview-0514 (FC)</td>\n",
       "      <td>https://deepmind.google/technologies/gemini/fl...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>70.34%</td>\n",
       "      <td>64.34%</td>\n",
       "      <td>72.52%</td>\n",
       "      <td>56.25%</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>71.89%</td>\n",
       "      <td>63.41%</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>70.50%</td>\n",
       "      <td>Claude-3-Opus-20240229 (FC tools-2024-04-04)</td>\n",
       "      <td>https://www.anthropic.com/news/claude-3-family</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>68.09%</td>\n",
       "      <td>64.73%</td>\n",
       "      <td>70.40%</td>\n",
       "      <td>43.75%</td>\n",
       "      <td>20.83%</td>\n",
       "      <td>74.06%</td>\n",
       "      <td>73.17%</td>\n",
       "      <td>37.72</td>\n",
       "      <td>12.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>19.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>70.46%</td>\n",
       "      <td>GPT-4o-2024-05-13 (FC)</td>\n",
       "      <td>https://openai.com/index/hello-gpt-4o/</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>73.26%</td>\n",
       "      <td>69.38%</td>\n",
       "      <td>74.16%</td>\n",
       "      <td>87.50%</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>66.17%</td>\n",
       "      <td>70.73%</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.03</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>69.84%</td>\n",
       "      <td>GPT-4-1106-Preview (FC)</td>\n",
       "      <td>https://platform.openai.com/docs/models/gpt-4-...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>74.53%</td>\n",
       "      <td>68.22%</td>\n",
       "      <td>76.37%</td>\n",
       "      <td>81.25%</td>\n",
       "      <td>58.33%</td>\n",
       "      <td>62.06%</td>\n",
       "      <td>82.93%</td>\n",
       "      <td>6.72</td>\n",
       "      <td>3.46</td>\n",
       "      <td>4.01</td>\n",
       "      <td>10.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>69.12%</td>\n",
       "      <td>Mistral-small-2402 (FC Auto)</td>\n",
       "      <td>https://docs.mistral.ai/guides/model-selection/</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>66.89%</td>\n",
       "      <td>62.79%</td>\n",
       "      <td>70.01%</td>\n",
       "      <td>6.25%</td>\n",
       "      <td>16.67%</td>\n",
       "      <td>72.00%</td>\n",
       "      <td>80.49%</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>68.81%</td>\n",
       "      <td>xLAM-7b-fc-r (FC)</td>\n",
       "      <td>https://huggingface.co/Salesforce/xLAM-7b-fc-r</td>\n",
       "      <td>Salesforce</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>63.07%</td>\n",
       "      <td>63.57%</td>\n",
       "      <td>63.36%</td>\n",
       "      <td>56.25%</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>77.03%</td>\n",
       "      <td>80.49%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>68.59%</td>\n",
       "      <td>Gorilla-OpenFunctions-v2 (FC)</td>\n",
       "      <td>https://gorilla.cs.berkeley.edu/blogs/7_open_f...</td>\n",
       "      <td>Gorilla LLM</td>\n",
       "      <td>Apache 2.0</td>\n",
       "      <td>63.60%</td>\n",
       "      <td>63.95%</td>\n",
       "      <td>63.93%</td>\n",
       "      <td>62.50%</td>\n",
       "      <td>45.83%</td>\n",
       "      <td>75.43%</td>\n",
       "      <td>85.37%</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>68.46%</td>\n",
       "      <td>Functionary-Small-v3.2 (FC)</td>\n",
       "      <td>https://huggingface.co/meetkai/functionary-sma...</td>\n",
       "      <td>MeetKai</td>\n",
       "      <td>MIT</td>\n",
       "      <td>67.04%</td>\n",
       "      <td>65.50%</td>\n",
       "      <td>67.50%</td>\n",
       "      <td>68.75%</td>\n",
       "      <td>62.50%</td>\n",
       "      <td>70.06%</td>\n",
       "      <td>80.49%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.72</td>\n",
       "      <td>3.49</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>68.10%</td>\n",
       "      <td>Functionary-Small-v3.1 (FC)</td>\n",
       "      <td>https://huggingface.co/meetkai/functionary-sma...</td>\n",
       "      <td>MeetKai</td>\n",
       "      <td>MIT</td>\n",
       "      <td>71.76%</td>\n",
       "      <td>68.99%</td>\n",
       "      <td>72.61%</td>\n",
       "      <td>81.25%</td>\n",
       "      <td>58.33%</td>\n",
       "      <td>61.71%</td>\n",
       "      <td>85.37%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.58</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>67.53%</td>\n",
       "      <td>GPT-4o-mini-2024-07-18 (FC)</td>\n",
       "      <td>https://openai.com/index/gpt-4o-mini-advancing...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>69.59%</td>\n",
       "      <td>67.83%</td>\n",
       "      <td>69.82%</td>\n",
       "      <td>81.25%</td>\n",
       "      <td>70.83%</td>\n",
       "      <td>63.66%</td>\n",
       "      <td>82.93%</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>67.17%</td>\n",
       "      <td>mistral-large-2407 (FC Auto)</td>\n",
       "      <td>https://mistral.ai/news/mistral-large-2407/</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>78.95%</td>\n",
       "      <td>79.07%</td>\n",
       "      <td>78.88%</td>\n",
       "      <td>87.50%</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>48.69%</td>\n",
       "      <td>78.05%</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.92</td>\n",
       "      <td>7.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>65.44%</td>\n",
       "      <td>FireFunction-v1 (FC)</td>\n",
       "      <td>https://huggingface.co/fireworks-ai/firefuncti...</td>\n",
       "      <td>Fireworks</td>\n",
       "      <td>Apache 2.0</td>\n",
       "      <td>66.44%</td>\n",
       "      <td>65.50%</td>\n",
       "      <td>69.24%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>62.51%</td>\n",
       "      <td>95.12%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>65.30%</td>\n",
       "      <td>Open-Mixtral-8x22b (FC Auto)</td>\n",
       "      <td>https://mistral.ai/news/mixtral-8x22b/</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>69.21%</td>\n",
       "      <td>68.99%</td>\n",
       "      <td>70.49%</td>\n",
       "      <td>12.50%</td>\n",
       "      <td>54.17%</td>\n",
       "      <td>58.40%</td>\n",
       "      <td>85.37%</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.76</td>\n",
       "      <td>5.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>64.77%</td>\n",
       "      <td>Gemini-1.0-Pro-001 (FC)</td>\n",
       "      <td>https://deepmind.google/technologies/gemini/#i...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>65.39%</td>\n",
       "      <td>62.79%</td>\n",
       "      <td>67.31%</td>\n",
       "      <td>43.75%</td>\n",
       "      <td>25.00%</td>\n",
       "      <td>63.43%</td>\n",
       "      <td>73.17%</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>63.93%</td>\n",
       "      <td>Claude-3-Sonnet-20240229 (FC tools-2024-04-04)</td>\n",
       "      <td>https://www.anthropic.com/news/claude-3-family</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>68.61%</td>\n",
       "      <td>65.50%</td>\n",
       "      <td>71.75%</td>\n",
       "      <td>12.50%</td>\n",
       "      <td>4.17%</td>\n",
       "      <td>55.20%</td>\n",
       "      <td>97.56%</td>\n",
       "      <td>4.22</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>61.71%</td>\n",
       "      <td>FireFunction-v2 (FC)</td>\n",
       "      <td>https://huggingface.co/fireworks-ai/firefuncti...</td>\n",
       "      <td>Fireworks</td>\n",
       "      <td>Apache 2.0</td>\n",
       "      <td>70.19%</td>\n",
       "      <td>69.38%</td>\n",
       "      <td>70.97%</td>\n",
       "      <td>56.25%</td>\n",
       "      <td>54.17%</td>\n",
       "      <td>47.54%</td>\n",
       "      <td>87.80%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.34</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>61.44%</td>\n",
       "      <td>Open-Mistral-Nemo-2407 (FC Auto)</td>\n",
       "      <td>https://mistral.ai/news/mistral-nemo/</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>68.01%</td>\n",
       "      <td>68.22%</td>\n",
       "      <td>67.98%</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>62.50%</td>\n",
       "      <td>51.20%</td>\n",
       "      <td>65.85%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>59.57%</td>\n",
       "      <td>Hermes-2-Theta-Llama-3-8B (FC)</td>\n",
       "      <td>https://huggingface.co/NousResearch/Hermes-2-T...</td>\n",
       "      <td>NousResearch</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>53.33%</td>\n",
       "      <td>55.81%</td>\n",
       "      <td>53.13%</td>\n",
       "      <td>43.75%</td>\n",
       "      <td>41.67%</td>\n",
       "      <td>69.49%</td>\n",
       "      <td>51.22%</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>59.00%</td>\n",
       "      <td>GPT-3.5-Turbo-0125 (FC)</td>\n",
       "      <td>https://platform.openai.com/docs/models/gpt-3-...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>71.91%</td>\n",
       "      <td>65.50%</td>\n",
       "      <td>74.16%</td>\n",
       "      <td>56.25%</td>\n",
       "      <td>54.17%</td>\n",
       "      <td>37.49%</td>\n",
       "      <td>97.56%</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>58.60%</td>\n",
       "      <td>Hermes-2-Pro-Llama-3-70B (FC)</td>\n",
       "      <td>https://huggingface.co/NousResearch/Hermes-2-P...</td>\n",
       "      <td>NousResearch</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>63.22%</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>62.49%</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>50.51%</td>\n",
       "      <td>80.49%</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>57.80%</td>\n",
       "      <td>Hermes-2-Pro-Llama-3-8B (FC)</td>\n",
       "      <td>https://huggingface.co/NousResearch/Hermes-2-P...</td>\n",
       "      <td>NousResearch</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>58.73%</td>\n",
       "      <td>60.47%</td>\n",
       "      <td>58.92%</td>\n",
       "      <td>43.75%</td>\n",
       "      <td>41.67%</td>\n",
       "      <td>56.57%</td>\n",
       "      <td>53.66%</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>57.44%</td>\n",
       "      <td>xLAM-1b-fc-r (FC)</td>\n",
       "      <td>https://huggingface.co/Salesforce/xLAM-1b-fc-r</td>\n",
       "      <td>Salesforce</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>56.03%</td>\n",
       "      <td>55.81%</td>\n",
       "      <td>56.12%</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>58.33%</td>\n",
       "      <td>57.83%</td>\n",
       "      <td>95.12%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>55.89%</td>\n",
       "      <td>Granite-20b-FunctionCalling (FC)</td>\n",
       "      <td>https://huggingface.co/ibm-granite/granite-20b...</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>54.53%</td>\n",
       "      <td>57.36%</td>\n",
       "      <td>54.10%</td>\n",
       "      <td>37.50%</td>\n",
       "      <td>54.17%</td>\n",
       "      <td>56.11%</td>\n",
       "      <td>95.12%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>54.24%</td>\n",
       "      <td>Command-R-Plus (FC) (Original)</td>\n",
       "      <td>https://txt.cohere.com/command-r-plus-microsof...</td>\n",
       "      <td>Cohere For AI</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>57.15%</td>\n",
       "      <td>58.91%</td>\n",
       "      <td>56.89%</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>54.17%</td>\n",
       "      <td>48.00%</td>\n",
       "      <td>92.68%</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.91</td>\n",
       "      <td>1.79</td>\n",
       "      <td>5.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>54.11%</td>\n",
       "      <td>Hermes-2-Pro-Mistral-7B (FC)</td>\n",
       "      <td>https://huggingface.co/NousResearch/Hermes-2-P...</td>\n",
       "      <td>NousResearch</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>57.23%</td>\n",
       "      <td>59.30%</td>\n",
       "      <td>57.47%</td>\n",
       "      <td>43.75%</td>\n",
       "      <td>33.33%</td>\n",
       "      <td>48.34%</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>51.98%</td>\n",
       "      <td>Claude-3-Haiku-20240307 (FC tools-2024-04-04)</td>\n",
       "      <td>https://www.anthropic.com/news/claude-3-family</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>64.27%</td>\n",
       "      <td>71.32%</td>\n",
       "      <td>64.90%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.17%</td>\n",
       "      <td>31.09%</td>\n",
       "      <td>97.56%</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>49.44%</td>\n",
       "      <td>mistral-large-2407 (FC Any)</td>\n",
       "      <td>https://mistral.ai/news/mistral-large-2407/</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>79.85%</td>\n",
       "      <td>79.84%</td>\n",
       "      <td>79.85%</td>\n",
       "      <td>87.50%</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.63</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>45.31%</td>\n",
       "      <td>Open-Mixtral-8x22b (FC Any)</td>\n",
       "      <td>https://mistral.ai/news/mixtral-8x22b/</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>72.88%</td>\n",
       "      <td>70.54%</td>\n",
       "      <td>74.83%</td>\n",
       "      <td>12.50%</td>\n",
       "      <td>54.17%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.61</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>45.00%</td>\n",
       "      <td>Open-Mistral-Nemo-2407 (FC Any)</td>\n",
       "      <td>https://mistral.ai/news/mistral-nemo/</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>72.13%</td>\n",
       "      <td>71.71%</td>\n",
       "      <td>72.42%</td>\n",
       "      <td>68.75%</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>1.03%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.86</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>43.94%</td>\n",
       "      <td>Mistral-small-2402 (FC Any)</td>\n",
       "      <td>https://docs.mistral.ai/guides/model-selection/</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>70.56%</td>\n",
       "      <td>65.12%</td>\n",
       "      <td>74.06%</td>\n",
       "      <td>6.25%</td>\n",
       "      <td>20.83%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.42</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>38.87%</td>\n",
       "      <td>Hermes-2-Theta-Llama-3-70B (FC)</td>\n",
       "      <td>https://huggingface.co/NousResearch/Hermes-2-T...</td>\n",
       "      <td>NousResearch</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank Overall Acc                                           Model  \\\n",
       "0      1      74.54%                                 GPT-4-0613 (FC)   \n",
       "3      4      73.39%                     GPT-4-turbo-2024-04-09 (FC)   \n",
       "6      7      71.79%                          GPT-4o-2024-08-06 (FC)   \n",
       "7      8      71.70%                Gemini-1.5-Pro-Preview-0409 (FC)   \n",
       "9     10      71.39%                 Claude-3.5-Sonnet-20240620 (FC)   \n",
       "10    11      71.26%                    Functionary-Medium-v3.1 (FC)   \n",
       "11    12      71.12%                Gemini-1.5-Pro-Preview-0514 (FC)   \n",
       "13    14      70.99%                         GPT-4-0125-Preview (FC)   \n",
       "14    15      70.81%              Gemini-1.5-Flash-Preview-0514 (FC)   \n",
       "15    16      70.50%    Claude-3-Opus-20240229 (FC tools-2024-04-04)   \n",
       "16    17      70.46%                          GPT-4o-2024-05-13 (FC)   \n",
       "19    20      69.84%                         GPT-4-1106-Preview (FC)   \n",
       "20    21      69.12%                    Mistral-small-2402 (FC Auto)   \n",
       "22    23      68.81%                               xLAM-7b-fc-r (FC)   \n",
       "23    24      68.59%                   Gorilla-OpenFunctions-v2 (FC)   \n",
       "24    25      68.46%                     Functionary-Small-v3.2 (FC)   \n",
       "26    27      68.10%                     Functionary-Small-v3.1 (FC)   \n",
       "30    31      67.53%                     GPT-4o-mini-2024-07-18 (FC)   \n",
       "31    32      67.17%                    mistral-large-2407 (FC Auto)   \n",
       "33    34      65.44%                            FireFunction-v1 (FC)   \n",
       "34    35      65.30%                    Open-Mixtral-8x22b (FC Auto)   \n",
       "35    36      64.77%                         Gemini-1.0-Pro-001 (FC)   \n",
       "36    37      63.93%  Claude-3-Sonnet-20240229 (FC tools-2024-04-04)   \n",
       "39    40      61.71%                            FireFunction-v2 (FC)   \n",
       "40    41      61.44%                Open-Mistral-Nemo-2407 (FC Auto)   \n",
       "43    44      59.57%                  Hermes-2-Theta-Llama-3-8B (FC)   \n",
       "45    46      59.00%                         GPT-3.5-Turbo-0125 (FC)   \n",
       "46    47      58.60%                   Hermes-2-Pro-Llama-3-70B (FC)   \n",
       "48    49      57.80%                    Hermes-2-Pro-Llama-3-8B (FC)   \n",
       "49    50      57.44%                               xLAM-1b-fc-r (FC)   \n",
       "51    52      55.89%                Granite-20b-FunctionCalling (FC)   \n",
       "52    53      54.24%                  Command-R-Plus (FC) (Original)   \n",
       "53    54      54.11%                    Hermes-2-Pro-Mistral-7B (FC)   \n",
       "55    56      51.98%   Claude-3-Haiku-20240307 (FC tools-2024-04-04)   \n",
       "56    57      49.44%                     mistral-large-2407 (FC Any)   \n",
       "61    62      45.31%                     Open-Mixtral-8x22b (FC Any)   \n",
       "62    63      45.00%                 Open-Mistral-Nemo-2407 (FC Any)   \n",
       "64    65      43.94%                     Mistral-small-2402 (FC Any)   \n",
       "65    66      38.87%                 Hermes-2-Theta-Llama-3-70B (FC)   \n",
       "\n",
       "                                           Model Link   Organization  \\\n",
       "0   https://platform.openai.com/docs/models/gpt-4-...         OpenAI   \n",
       "3   https://platform.openai.com/docs/models/gpt-4-...         OpenAI   \n",
       "6              https://openai.com/index/hello-gpt-4o/         OpenAI   \n",
       "7   https://deepmind.google/technologies/gemini/#i...         Google   \n",
       "9    https://www.anthropic.com/news/claude-3-5-sonnet      Anthropic   \n",
       "10  https://huggingface.co/meetkai/functionary-med...        MeetKai   \n",
       "11   https://deepmind.google/technologies/gemini/pro/         Google   \n",
       "13  https://platform.openai.com/docs/models/gpt-4-...         OpenAI   \n",
       "14  https://deepmind.google/technologies/gemini/fl...         Google   \n",
       "15     https://www.anthropic.com/news/claude-3-family      Anthropic   \n",
       "16             https://openai.com/index/hello-gpt-4o/         OpenAI   \n",
       "19  https://platform.openai.com/docs/models/gpt-4-...         OpenAI   \n",
       "20    https://docs.mistral.ai/guides/model-selection/     Mistral AI   \n",
       "22     https://huggingface.co/Salesforce/xLAM-7b-fc-r     Salesforce   \n",
       "23  https://gorilla.cs.berkeley.edu/blogs/7_open_f...    Gorilla LLM   \n",
       "24  https://huggingface.co/meetkai/functionary-sma...        MeetKai   \n",
       "26  https://huggingface.co/meetkai/functionary-sma...        MeetKai   \n",
       "30  https://openai.com/index/gpt-4o-mini-advancing...         OpenAI   \n",
       "31        https://mistral.ai/news/mistral-large-2407/     Mistral AI   \n",
       "33  https://huggingface.co/fireworks-ai/firefuncti...      Fireworks   \n",
       "34             https://mistral.ai/news/mixtral-8x22b/     Mistral AI   \n",
       "35  https://deepmind.google/technologies/gemini/#i...         Google   \n",
       "36     https://www.anthropic.com/news/claude-3-family      Anthropic   \n",
       "39  https://huggingface.co/fireworks-ai/firefuncti...      Fireworks   \n",
       "40              https://mistral.ai/news/mistral-nemo/     Mistral AI   \n",
       "43  https://huggingface.co/NousResearch/Hermes-2-T...   NousResearch   \n",
       "45  https://platform.openai.com/docs/models/gpt-3-...         OpenAI   \n",
       "46  https://huggingface.co/NousResearch/Hermes-2-P...   NousResearch   \n",
       "48  https://huggingface.co/NousResearch/Hermes-2-P...   NousResearch   \n",
       "49     https://huggingface.co/Salesforce/xLAM-1b-fc-r     Salesforce   \n",
       "51  https://huggingface.co/ibm-granite/granite-20b...            IBM   \n",
       "52  https://txt.cohere.com/command-r-plus-microsof...  Cohere For AI   \n",
       "53  https://huggingface.co/NousResearch/Hermes-2-P...   NousResearch   \n",
       "55     https://www.anthropic.com/news/claude-3-family      Anthropic   \n",
       "56        https://mistral.ai/news/mistral-large-2407/     Mistral AI   \n",
       "61             https://mistral.ai/news/mixtral-8x22b/     Mistral AI   \n",
       "62              https://mistral.ai/news/mistral-nemo/     Mistral AI   \n",
       "64    https://docs.mistral.ai/guides/model-selection/     Mistral AI   \n",
       "65  https://huggingface.co/NousResearch/Hermes-2-T...   NousResearch   \n",
       "\n",
       "         License AST Summary Python Simple AST Python Multiple AST  \\\n",
       "0    Proprietary      73.26%            66.67%              77.72%   \n",
       "3    Proprietary      72.96%            67.83%              74.45%   \n",
       "6    Proprietary      69.14%            67.83%              69.43%   \n",
       "7    Proprietary      67.42%            62.40%              68.85%   \n",
       "9    Proprietary      71.09%            72.48%              70.68%   \n",
       "10           MIT      77.15%            72.09%              78.69%   \n",
       "11   Proprietary      66.82%            61.63%              68.27%   \n",
       "13   Proprietary      74.38%            69.77%              75.89%   \n",
       "14   Proprietary      70.34%            64.34%              72.52%   \n",
       "15   Proprietary      68.09%            64.73%              70.40%   \n",
       "16   Proprietary      73.26%            69.38%              74.16%   \n",
       "19   Proprietary      74.53%            68.22%              76.37%   \n",
       "20   Proprietary      66.89%            62.79%              70.01%   \n",
       "22  cc-by-nc-4.0      63.07%            63.57%              63.36%   \n",
       "23    Apache 2.0      63.60%            63.95%              63.93%   \n",
       "24           MIT      67.04%            65.50%              67.50%   \n",
       "26           MIT      71.76%            68.99%              72.61%   \n",
       "30   Proprietary      69.59%            67.83%              69.82%   \n",
       "31   Proprietary      78.95%            79.07%              78.88%   \n",
       "33    Apache 2.0      66.44%            65.50%              69.24%   \n",
       "34   Proprietary      69.21%            68.99%              70.49%   \n",
       "35   Proprietary      65.39%            62.79%              67.31%   \n",
       "36   Proprietary      68.61%            65.50%              71.75%   \n",
       "39    Apache 2.0      70.19%            69.38%              70.97%   \n",
       "40   Proprietary      68.01%            68.22%              67.98%   \n",
       "43    apache-2.0      53.33%            55.81%              53.13%   \n",
       "45   Proprietary      71.91%            65.50%              74.16%   \n",
       "46    apache-2.0      63.22%            66.67%              62.49%   \n",
       "48    apache-2.0      58.73%            60.47%              58.92%   \n",
       "49  cc-by-nc-4.0      56.03%            55.81%              56.12%   \n",
       "51    Apache-2.0      54.53%            57.36%              54.10%   \n",
       "52  cc-by-nc-4.0      57.15%            58.91%              56.89%   \n",
       "53    apache-2.0      57.23%            59.30%              57.47%   \n",
       "55   Proprietary      64.27%            71.32%              64.90%   \n",
       "56   Proprietary      79.85%            79.84%              79.85%   \n",
       "61   Proprietary      72.88%            70.54%              74.83%   \n",
       "62   Proprietary      72.13%            71.71%              72.42%   \n",
       "64   Proprietary      70.56%            65.12%              74.06%   \n",
       "65    apache-2.0       0.00%             0.00%               0.00%   \n",
       "\n",
       "   Python Parallel AST Python Parallel Multiple AST Irrelevance Detection  \\\n",
       "0                0.00%                        0.00%                76.57%   \n",
       "3               75.00%                       62.50%                74.17%   \n",
       "6               75.00%                       66.67%                76.23%   \n",
       "7               81.25%                       50.00%                78.63%   \n",
       "9               68.75%                       75.00%                72.23%   \n",
       "10              68.75%                       70.83%                62.29%   \n",
       "11              81.25%                       50.00%                78.29%   \n",
       "13              68.75%                       62.50%                65.14%   \n",
       "14              56.25%                       50.00%                71.89%   \n",
       "15              43.75%                       20.83%                74.06%   \n",
       "16              87.50%                       66.67%                66.17%   \n",
       "19              81.25%                       58.33%                62.06%   \n",
       "20               6.25%                       16.67%                72.00%   \n",
       "22              56.25%                       50.00%                77.03%   \n",
       "23              62.50%                       45.83%                75.43%   \n",
       "24              68.75%                       62.50%                70.06%   \n",
       "26              81.25%                       58.33%                61.71%   \n",
       "30              81.25%                       70.83%                63.66%   \n",
       "31              87.50%                       75.00%                48.69%   \n",
       "33               0.00%                        0.00%                62.51%   \n",
       "34              12.50%                       54.17%                58.40%   \n",
       "35              43.75%                       25.00%                63.43%   \n",
       "36              12.50%                        4.17%                55.20%   \n",
       "39              56.25%                       54.17%                47.54%   \n",
       "40              75.00%                       62.50%                51.20%   \n",
       "43              43.75%                       41.67%                69.49%   \n",
       "45              56.25%                       54.17%                37.49%   \n",
       "46              50.00%                       66.67%                50.51%   \n",
       "48              43.75%                       41.67%                56.57%   \n",
       "49              50.00%                       58.33%                57.83%   \n",
       "51              37.50%                       54.17%                56.11%   \n",
       "52              50.00%                       54.17%                48.00%   \n",
       "53              43.75%                       33.33%                48.34%   \n",
       "55               0.00%                        4.17%                31.09%   \n",
       "56              87.50%                       75.00%                 0.69%   \n",
       "61              12.50%                       54.17%                 0.69%   \n",
       "62              68.75%                       66.67%                 1.03%   \n",
       "64               6.25%                       20.83%                 0.69%   \n",
       "65               0.00%                        0.00%               100.00%   \n",
       "\n",
       "   Relevance Detection  Cost ($ Per 1k Function Calls)  Latency Mean (s)  \\\n",
       "0               73.17%                           15.36              2.46   \n",
       "3               70.73%                            6.24              2.85   \n",
       "6               63.41%                            1.62              1.02   \n",
       "7               63.41%                            1.49              1.91   \n",
       "9               63.41%                            5.31              3.11   \n",
       "10              70.73%                             NaN              5.06   \n",
       "11              58.54%                            1.49              2.03   \n",
       "13              85.37%                            6.49              3.37   \n",
       "14              63.41%                            0.13              0.77   \n",
       "15              73.17%                           37.72             12.05   \n",
       "16              70.73%                            3.04              1.06   \n",
       "19              82.93%                            6.72              3.46   \n",
       "20              80.49%                            0.81              2.07   \n",
       "22              80.49%                             NaN               NaN   \n",
       "23              85.37%                            0.31              0.05   \n",
       "24              80.49%                             NaN              2.72   \n",
       "26              85.37%                             NaN              3.11   \n",
       "30              82.93%                            0.10              1.01   \n",
       "31              78.05%                            2.53              2.93   \n",
       "33              95.12%                             NaN              1.63   \n",
       "34              85.37%                            1.74              2.16   \n",
       "35              73.17%                            0.22              1.05   \n",
       "36              97.56%                            4.22              2.69   \n",
       "39              87.80%                             NaN              2.10   \n",
       "40              65.85%                            0.19              1.86   \n",
       "43              51.22%                            0.24              0.04   \n",
       "45              97.56%                            0.28              0.97   \n",
       "46              80.49%                            2.45              0.40   \n",
       "48              53.66%                            0.31              0.05   \n",
       "49              95.12%                             NaN               NaN   \n",
       "51              95.12%                             NaN               NaN   \n",
       "52              92.68%                            2.14              2.91   \n",
       "53              75.61%                            0.49              0.08   \n",
       "55              97.56%                            0.36              1.10   \n",
       "56             100.00%                            2.37              2.51   \n",
       "61             100.00%                            1.55              1.88   \n",
       "62             100.00%                            0.19              1.74   \n",
       "64             100.00%                            0.77              1.91   \n",
       "65               0.00%                            2.57              0.42   \n",
       "\n",
       "    Latency Standard Deviation (s)  Latency 95th Percentile (s)  \n",
       "0                             2.84                         6.40  \n",
       "3                             3.33                         8.76  \n",
       "6                             0.94                         2.69  \n",
       "7                             1.07                         3.62  \n",
       "9                             1.16                         5.30  \n",
       "10                            5.45                        13.35  \n",
       "11                            1.14                         3.96  \n",
       "13                            4.00                        12.05  \n",
       "14                            0.34                         1.19  \n",
       "15                            4.07                        19.30  \n",
       "16                            1.03                         2.73  \n",
       "19                            4.01                        10.13  \n",
       "20                            1.43                         5.41  \n",
       "22                             NaN                          NaN  \n",
       "23                             NaN                          NaN  \n",
       "24                            3.49                         7.08  \n",
       "26                            3.58                         7.24  \n",
       "30                            1.05                         2.73  \n",
       "31                            3.92                         7.32  \n",
       "33                            1.12                         2.86  \n",
       "34                            1.76                         5.65  \n",
       "35                            1.01                         1.86  \n",
       "36                            1.25                         5.24  \n",
       "39                            1.34                         4.34  \n",
       "40                            1.98                         5.30  \n",
       "43                             NaN                          NaN  \n",
       "45                            0.75                         1.96  \n",
       "46                             NaN                          NaN  \n",
       "48                             NaN                          NaN  \n",
       "49                             NaN                          NaN  \n",
       "51                             NaN                          NaN  \n",
       "52                            1.79                         5.85  \n",
       "53                             NaN                          NaN  \n",
       "55                            0.31                         1.63  \n",
       "56                            1.63                         5.42  \n",
       "61                            1.61                         5.42  \n",
       "62                            1.86                         5.27  \n",
       "64                            1.42                         5.44  \n",
       "65                             NaN                          NaN  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/ShishirPatil/gorilla/gh-pages/data_live.csv'\n",
    "\n",
    "function_calling_leaderboard = pd.read_csv(url)\n",
    "\n",
    "\n",
    "# discard all models that have (prompt) in their name\n",
    "function_calling_leaderboard = function_calling_leaderboard[~function_calling_leaderboard['Model'].str.contains(\"(Prompt)\")]\n",
    "\n",
    "# get all columns that contain either a number with a percent sign, a number or NaN\n",
    "\n",
    "def is_numeric_or_percent(s):\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return True\n",
    "    elif pd.api.types.is_object_dtype(s):\n",
    "        try:\n",
    "            # Try to convert to numeric, treating '%' as a special case\n",
    "            return pd.to_numeric(s.astype(str).str.rstrip('%'), errors='coerce').notna().any()\n",
    "        except AttributeError:\n",
    "            # If we can't use .str accessor, it's not a string column\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "numeric_percent_nan_cols = function_calling_leaderboard.columns[\n",
    "    function_calling_leaderboard.apply(lambda col: is_numeric_or_percent(col) or col.isna().any())\n",
    "]\n",
    "\n",
    "# filter out Rankm Cost, Latency columns\n",
    "relevant_cols = numeric_percent_nan_cols[~numeric_percent_nan_cols.str.contains(\"Rank|Cost|Latency\")]\n",
    "\n",
    "\n",
    "function_calling_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_690398/2746134888.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  function_calling_leaderboard['LM'] = function_calling_leaderboard['Model'].apply(lambda x: correlation_with_df.get(x, x))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Other Errors</th>\n",
       "      <th>Test Errors</th>\n",
       "      <th>Test Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[BFCL] Python Simple AST</th>\n",
       "      <td>-0.534404</td>\n",
       "      <td>0.428754</td>\n",
       "      <td>0.504786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[BFCL] Irrelevance Detection</th>\n",
       "      <td>-0.487553</td>\n",
       "      <td>0.522474</td>\n",
       "      <td>0.469418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[BFCL] Relevance Detection</th>\n",
       "      <td>0.349609</td>\n",
       "      <td>-0.209742</td>\n",
       "      <td>-0.283967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[BFCL] AST Summary</th>\n",
       "      <td>-0.772036</td>\n",
       "      <td>0.885236</td>\n",
       "      <td>0.630211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[BFCL] Python Multiple AST</th>\n",
       "      <td>-0.683107</td>\n",
       "      <td>0.837526</td>\n",
       "      <td>0.560922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[BFCL] Overall Acc</th>\n",
       "      <td>-0.598612</td>\n",
       "      <td>0.661539</td>\n",
       "      <td>0.550183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[BFCL] Python Parallel AST</th>\n",
       "      <td>-0.335354</td>\n",
       "      <td>0.451071</td>\n",
       "      <td>0.185546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Other Errors  Test Errors  Test Success\n",
       "[BFCL] Python Simple AST         -0.534404     0.428754      0.504786\n",
       "[BFCL] Irrelevance Detection     -0.487553     0.522474      0.469418\n",
       "[BFCL] Relevance Detection        0.349609    -0.209742     -0.283967\n",
       "[BFCL] AST Summary               -0.772036     0.885236      0.630211\n",
       "[BFCL] Python Multiple AST       -0.683107     0.837526      0.560922\n",
       "[BFCL] Overall Acc               -0.598612     0.661539      0.550183\n",
       "[BFCL] Python Parallel AST       -0.335354     0.451071      0.185546"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "correlation_with_df = {\n",
    "  \"Claude-3.5-Sonnet-20240620 (FC)\": \"claude-3.5-sonnet\",\n",
    "  \"Gemini-1.5-Pro-Preview-0514 (FC)\": \"gemini-1.5-pro\",\n",
    "#   \"Gemini-1.5-Flash-Preview-0514 (FC)\": \"gemini-1.5-flash\",\n",
    "  \"GPT-4o-mini-2024-07-18 (FC)\": \"gpt-4o-mini\",\n",
    "  \"Open-Mistral-Nemo-2407 (FC Auto)\": \"mistral-nemo\",\n",
    "  \"GPT-4o-2024-05-13 (FC)\": \"gpt-4o\",\n",
    "  \"Claude-3-Haiku-20240307 (FC tools-2024-04-04)\": \"claude-3-haiku\"\n",
    "}\n",
    "\n",
    "# pick the models that are in the correlation\n",
    "function_calling_leaderboard = function_calling_leaderboard[function_calling_leaderboard['Model'].isin(list(correlation_with_df.keys()))]\n",
    "\n",
    "# rename model names\n",
    "function_calling_leaderboard['LM'] = function_calling_leaderboard['Model'].apply(lambda x: correlation_with_df.get(x, x))\n",
    "\n",
    "leaderboard_relevant = function_calling_leaderboard[list(relevant_cols) + ['LM']]\n",
    "success_relevant = success_df[['LM', 'Other Errors', 'Test Errors', 'Test Success']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Merge dataframes on the 'LM' column\n",
    "merged_df = pd.merge(leaderboard_relevant, success_relevant, on='LM')\n",
    "\n",
    "# Convert percentages to numerical values\n",
    "for col in relevant_cols:\n",
    "    merged_df[col] = merged_df[col].str.rstrip('%').astype(float)\n",
    "\n",
    "# Convert 'Errors' column to numeric\n",
    "# merged_df['Errors'] = pd.to_numeric(merged_df['Errors'].str.extract(r'(\\d+)')[0])\n",
    "\n",
    "# rename every column but LM to include [BFCL] as prefix\n",
    "merged_df = merged_df.rename(columns={col: f\"[BFCL] {col}\" for col in relevant_cols if col != 'LM'})\n",
    "\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "updated_correlation_matrix = merged_df.corr(numeric_only=True)\n",
    "\n",
    "# Function to get the highest and lowest correlations for a target column\n",
    "def get_top_bottom_corr(corr_matrix, target_col, num=3):\n",
    "    corr_series = corr_matrix[target_col].drop(target_col)\n",
    "    highest_corr = corr_series.nlargest(num).index.tolist()\n",
    "    lowest_corr = corr_series.nsmallest(num).index.tolist()\n",
    "    return highest_corr + lowest_corr\n",
    "\n",
    "# Get top and bottom correlations for Errors, Compile Success, and Test Success\n",
    "top_bottom_errors = get_top_bottom_corr(updated_correlation_matrix, 'Other Errors')\n",
    "top_bottom_compile_success = get_top_bottom_corr(updated_correlation_matrix, 'Test Errors')\n",
    "top_bottom_test_success = get_top_bottom_corr(updated_correlation_matrix, 'Test Success')\n",
    "\n",
    "# Combine all selected columns with Overall Acc\n",
    "\n",
    "# get the column from updated_correlation_matrix that resembles Overall Acc\n",
    "overall_acc = [col for col in updated_correlation_matrix.columns.tolist() if 'Overall Acc' in col]\n",
    "\n",
    "java_ast = [col for col in updated_correlation_matrix.columns.tolist() if 'Java ' in col]\n",
    "\n",
    "selected_columns = list(set(overall_acc + java_ast + top_bottom_errors + top_bottom_compile_success + top_bottom_test_success ))\n",
    "selected_columns = [col for col in selected_columns if col not in ['Other Errors', 'Test Errors', 'Test Success']]\n",
    "\n",
    "selected_correlations = updated_correlation_matrix.loc[selected_columns, ['Other Errors', 'Test Errors', 'Test Success']]\n",
    "\n",
    "# Plot the correlation heatmap with better labeling\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(selected_correlations, annot=True, cmap='coolwarm', center=0, linewidths=0.5)\n",
    "# plt.title('Correlation Heatmap between Berkeley Function Calling Leaderboard and Success Metrics')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add labels to the side of the heatmap for clarity\n",
    "for ytick, ylabel in zip(plt.gca().get_yticks(), plt.gca().get_yticklabels()):\n",
    "    ylabel.set_rotation(0)\n",
    "    ylabel.set_horizontalalignment('right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if generated_graphs_path.exists():\n",
    "    plt.savefig(generated_graphs_path / \"bfcl_correlation_heatmap_agent.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "selected_correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\caption{Correlation Heatmap between Berkeley Function Calling Leaderboard and Success Metrics}\n",
      "\\label{tab:bfcl-correlation-agent}\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Metric & Other Errors & Test Errors & \\begin{mlhead}Test \\\\Success\\end{mlhead} \\\\\n",
      "\\midrule\n",
      "Python Simple AST & -0.534 & 0.429 & 0.505 \\\\\n",
      "Irrelevance Detection & -0.488 & 0.522 & 0.469 \\\\\n",
      "Relevance Detection & 0.350 & -0.210 & -0.284 \\\\\n",
      "AST Summary & -0.772 & 0.885 & 0.630 \\\\\n",
      "Python Multiple AST & -0.683 & 0.838 & 0.561 \\\\\n",
      "Overall Acc & -0.599 & 0.662 & 0.550 \\\\\n",
      "Python Parallel AST & -0.335 & 0.451 & 0.186 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bfcl_correlations_latex = selected_correlations.copy()\n",
    "\n",
    "# make metric a col\n",
    "bfcl_correlations_latex = bfcl_correlations_latex.reset_index()\n",
    "bfcl_correlations_latex = bfcl_correlations_latex.rename(columns={'index': 'Metric'})\n",
    "bfcl_correlations_latex['Metric'] = bfcl_correlations_latex['Metric'].str.replace('[BFCL] ', '')\n",
    "\n",
    "\n",
    "\n",
    "# Replace column names\n",
    "bfcl_correlations_latex = bfcl_correlations_latex.rename(columns={'Compile Success': '\\\\begin{mlhead}Compile \\\\\\\\Success\\\\end{mlhead}',\n",
    "                                   'Test Success': '\\\\begin{mlhead}Test \\\\\\\\Success\\\\end{mlhead}'})\n",
    "\n",
    "print(bfcl_correlations_latex.to_latex(index=False, escape=False, position=\"H\", caption=\"Correlation Heatmap between Berkeley Function Calling Leaderboard and Success Metrics\", label=\"tab:bfcl-correlation-agent\", float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff Analysis per Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dataset_path = Path(os.path.abspath('')).parent / \"dataset\"\n",
    "\n",
    "\n",
    "diffs = defaultdict(dict)\n",
    "for file in dataset_path.glob(\"*/out/*/solution.json\"):\n",
    "    lm = get_language_model(file)\n",
    "    file = str(file)\n",
    "    commit = file.split(\"/\")[-4]\n",
    "    final_diff_path = Path(file).parent / \"final_state.diff\"\n",
    "    if final_diff_path.exists():\n",
    "        with open(final_diff_path, \"r\") as f:\n",
    "            diff = f.read()\n",
    "            if commit not in diffs[lm]:\n",
    "              diffs[lm][commit] = set()\n",
    "            diffs[lm][commit].add(diff)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from unidiff import LINE_TYPE_ADDED, LINE_TYPE_REMOVED, PatchSet\n",
    "\n",
    "from masterthesis.agent.aider.AdvancedDiffAgent import UnifiedDiffCoder\n",
    "\n",
    "# Function to calculate diff statistics\n",
    "def calculate_diff_stats(diff, commit):\n",
    "\n",
    "    patch = PatchSet(diff)\n",
    "\n",
    "    \n",
    "    operation_count = sum([file_patch.added+file_patch.removed for file_patch in patch])\n",
    "    hunk_count = sum([len(file_patch) for file_patch in patch])\n",
    "\n",
    "    return {\n",
    "        'files_modified': len(patch),  \n",
    "        'operation_count': operation_count,\n",
    "        'hunk_count': hunk_count\n",
    "    } \n",
    "\n",
    "# Transform diffs and add statistics\n",
    "transformed_diffs = defaultdict(lambda: defaultdict(list))\n",
    "for lm, commits in diffs.items():\n",
    "    for commit, diff_set in commits.items():\n",
    "        for diff in diff_set:\n",
    "            stats = calculate_diff_stats(diff, commit)\n",
    "            transformed_diffs[lm][commit].append({\n",
    "                'diff': diff,\n",
    "                'files_modified': stats['files_modified'],\n",
    "                'operation_count': stats['operation_count'],\n",
    "                'hunk_count': stats['hunk_count']\n",
    "            })\n",
    "\n",
    "# Create a DataFrame\n",
    "rows = []\n",
    "for lm, commits in transformed_diffs.items():\n",
    "    for commit, diffs in commits.items():\n",
    "        for diff_data in diffs:\n",
    "            rows.append({\n",
    "                'language_model': lm,\n",
    "                'commit': commit,\n",
    "                'files_modified': diff_data['files_modified'],\n",
    "                'operation_count': diff_data['operation_count'],\n",
    "                'hunk_count': diff_data['hunk_count']\n",
    "            })\n",
    "\n",
    "diff_df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit-level statistics for 52 commits:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>language_model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">files_modified</th>\n",
       "      <th colspan=\"3\" halign=\"left\">operation_count</th>\n",
       "      <th colspan=\"3\" halign=\"left\">hunk_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.807722</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-3-haiku</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.103264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.136341</td>\n",
       "      <td>13.295455</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.190559</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.347235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.301708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.669047</td>\n",
       "      <td>1.321429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>7.785714</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.220943</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      language_model files_modified                  operation_count         \\\n",
       "                               mean median       std            mean median   \n",
       "0      Llama-3.1-70B       1.000000    1.0  0.000000        2.875000    2.0   \n",
       "1     claude-3-haiku       1.000000    1.0  0.000000       13.000000    2.0   \n",
       "2  claude-3.5-sonnet       1.750000    1.0  2.136341       13.295455   10.0   \n",
       "3     gemini-1.5-pro       1.000000    1.0  0.000000        2.777778    2.0   \n",
       "4             gpt-4o       1.035714    1.0  0.188982        7.428571    6.5   \n",
       "5        gpt-4o-mini       1.071429    1.0  0.267261        7.785714    9.5   \n",
       "6       mistral-nemo       1.000000    1.0  0.000000        2.000000    2.0   \n",
       "\n",
       "             hunk_count                   \n",
       "         std       mean median       std  \n",
       "0   1.807722   1.125000    1.0  0.353553  \n",
       "1  29.103264   1.000000    1.0  0.000000  \n",
       "2  17.190559   2.545455    2.0  2.347235  \n",
       "3   1.301708   1.000000    1.0  0.000000  \n",
       "4   6.669047   1.321429    1.0  0.722832  \n",
       "5   5.220943   1.214286    1.0  0.578934  \n",
       "6   0.000000   1.000000    1.0  0.000000  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diff_df_prepared = diff_df[diff_df['commit'].isin(dspy_hashes)]\n",
    "diff_df_prepared = diff_df.copy()\n",
    "\n",
    "# Commit-level statistics\n",
    "commit_stats = diff_df_prepared.groupby(['language_model', 'commit']).agg({\n",
    "    'files_modified': ['mean', 'median', 'std'],\n",
    "    'operation_count': ['mean', 'median', 'std'],\n",
    "    'hunk_count': ['mean', 'median', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "len_of_commit = len(commit_stats['commit'].unique())\n",
    "\n",
    "print(f\"Commit-level statistics for {len_of_commit} commits:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Language model comparison\n",
    "lm_comparison = diff_df_prepared.groupby('language_model').agg({\n",
    "    'files_modified': ['mean', 'median', 'std'],\n",
    "    'operation_count': ['mean', 'median', 'std'],\n",
    "    'hunk_count': ['mean', 'median', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# diff_df.to_pickle(\"diff_stats.pkl\")\n",
    "\n",
    "lm_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\caption{Diff Statistics by Language Model (n=52)}\n",
      "\\label{tab:diff-stats}\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "Language Model & Files Modified & Operation Count & Hunk Count \\\\\n",
      "\\midrule\n",
      "Llama-3.1-70B & 1 (1) & 2.88 $\\pm$ 1.81 (2) & 1.12 $\\pm$ 0.35 (1) \\\\\n",
      "claude-3-haiku & 1 (1) & 13 $\\pm$ 29.10 (2) & 1 (1) \\\\\n",
      "claude-3.5-sonnet & 1.75 $\\pm$ 2.14 (1) & 13.30 $\\pm$ 17.19 (10) & 2.55 $\\pm$ 2.35 (2) \\\\\n",
      "gemini-1.5-pro & 1 (1) & 2.78 $\\pm$ 1.30 (2) & 1 (1) \\\\\n",
      "gpt-4o & 1.04 $\\pm$ 0.19 (1) & 7.43 $\\pm$ 6.67 (6.50) & 1.32 $\\pm$ 0.72 (1) \\\\\n",
      "gpt-4o-mini & 1.07 $\\pm$ 0.27 (1) & 7.79 $\\pm$ 5.22 (9.50) & 1.21 $\\pm$ 0.58 (1) \\\\\n",
      "mistral-nemo & 1 (1) & 2 (2) & 1 (1) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:49: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\p'\n",
      "/tmp/ipykernel_690398/2994451253.py:49: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  latex_text = latex_text.replace(\"\", \"$\\pm$\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lm_comparison_human = lm_comparison.rename(columns={'files_modified': 'Files Modified', 'operation_count': 'Operation Count', 'language_model': \"Language Model\"})\n",
    "\n",
    "# print(lm_comparison_human)\n",
    "\n",
    "def convert_float_to_int(value):\n",
    "    # if isinstance(value, float):\n",
    "    #     print(value, value.is_integer())\n",
    "    if isinstance(value, float) and value.is_integer():\n",
    "        return str(int(value))\n",
    "    return value\n",
    "# lm_comparison_human = lm_comparison_human.map(convert_float_to_int)\n",
    "\n",
    "\n",
    "\n",
    "def format_mean_std_median(mean, std, median):\n",
    "    if np.isnan(mean) or np.isnan(std) or np.isnan(median):\n",
    "        return \"N/A\"\n",
    "    \n",
    "    if mean.is_integer():\n",
    "        mean_str = str(int(mean))\n",
    "    else:\n",
    "        mean_str = f\"{mean:.2f}\"\n",
    "    mean_std = f\"{mean_str}  {std:.2f}\"\n",
    "    if mean.is_integer() and std == 0:\n",
    "        mean_std = f\"{int(mean)}\"\n",
    "    if median.is_integer():\n",
    "        median_str = str(int(median))\n",
    "    else:\n",
    "        median_str = f\"{median:.2f}\"\n",
    "    return f\"{mean_std} ({median_str})\"\n",
    "\n",
    "# Create a new DataFrame for the formatted data\n",
    "formatted_data = []\n",
    "\n",
    "for lm, row in lm_comparison.iterrows():\n",
    "    formatted_row = {\n",
    "        'Language Model': row[\"language_model\"].to_string().strip(),\n",
    "        'Files Modified': format_mean_std_median(row['files_modified']['mean'], row['files_modified']['std'], row['files_modified']['median']),\n",
    "        'Operation Count': format_mean_std_median(row['operation_count']['mean'], row['operation_count']['std'], row['operation_count']['median']),\n",
    "        'Hunk Count': format_mean_std_median(row['hunk_count']['mean'], row['hunk_count']['std'], row['hunk_count']['median'])\n",
    "    }\n",
    "    formatted_data.append(formatted_row)\n",
    "\n",
    "formatted_df = pd.DataFrame(formatted_data)\n",
    "\n",
    "\n",
    "latex_text = formatted_df.to_latex(index=False, escape=False, float_format=\"%.2f\", position=\"H\", caption=f\"Diff Statistics by Language Model (n={len_of_commit})\", label=\"tab:diff-stats\")\n",
    "                                          # , column_format=\"lrrr|rrr\")\n",
    "latex_text = latex_text.replace(\"\", \"$\\pm$\")\n",
    "print(latex_text)\n",
    "# custom_header = [\n",
    "#     ('Language Model', ''),\n",
    "#     ('Files Modified', 'mean'), ('Files Modified', 'median'), ('Files Modified', 'std'),\n",
    "#     ('Operation Count', 'mean'), ('Operation Count', 'median'), ('Operation Count', 'std'),\n",
    "#     ('Hunk Count', 'mean'), ('Hunk Count', 'median'), ('Hunk Count', 'std')\n",
    "# ]\n",
    "\n",
    "\n",
    "# # latex_text = latex_text.replace(\"\\\\multicolumn{3}{r}{Files Modified}\", \"\\\\multicolumn{3}{r|}{Files Modified}\")\n",
    "# # print(latex_text)\n",
    "\n",
    "# from tabulate import tabulate\n",
    "# latex_table=tabulate(lm_comparison_human, tablefmt=\"latex_booktabs\",headers=custom_header, showindex=False, floatfmt=\".2f\")\n",
    "# latex_table = latex_table.replace(\"Language Model &\", \"\\\\multicolumn{1}{c}{Language Model} &\")\n",
    "# latex_table = latex_table.replace(\"Files Modified & Files Modified & Files Modified\", \"\\\\multicolumn{3}{c}{Files Modified}\")\n",
    "# latex_table = latex_table.replace(\"Operation Count & Operation Count & Operation Count\", \"\\\\multicolumn{3}{c}{Operation Count}\")\n",
    "# latex_table = latex_table.replace(\"Hunk Count & Hunk Count & Hunk Count\", \"\\\\multicolumn{3}{c}{Hunk Count}\")\n",
    "# latex_table = f\"\\\\begin{{table}}[H]\\n\\\\caption{{Diff Statistics by Language Model}}\\n\\\\label{{tab:diff-stats}}\\n{latex_table}\\n\\\\end{{table}}\"\n",
    "# print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Other Errors</th>\n",
       "      <th>Test Errors</th>\n",
       "      <th>Test Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diff Files Modified</th>\n",
       "      <td>-0.228356</td>\n",
       "      <td>0.164682</td>\n",
       "      <td>0.240381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diff Operation Count</th>\n",
       "      <td>-0.221971</td>\n",
       "      <td>0.176184</td>\n",
       "      <td>0.231639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diff Hunk Count</th>\n",
       "      <td>-0.378988</td>\n",
       "      <td>0.291783</td>\n",
       "      <td>0.392730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Other Errors  Test Errors  Test Success\n",
       "Diff Files Modified      -0.228356     0.164682      0.240381\n",
       "Diff Operation Count     -0.221971     0.176184      0.231639\n",
       "Diff Hunk Count          -0.378988     0.291783      0.392730"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Renaming columns to match for merging\n",
    "renamed_diff_df = diff_df.rename(columns={'language_model': 'LM', 'files_modified': 'Diff Files Modified', 'operation_count': 'Diff Operation Count', 'hunk_count': 'Diff Hunk Count'})\n",
    "\n",
    "success_df_copy = success_df.copy()\n",
    "# success_df_copy['Errors'] = pd.to_numeric(success_df_copy['Errors'].str.extract(r'(\\d+)')[0])\n",
    "success_relevant = success_df_copy[['LM', 'Other Errors', 'Test Errors', 'Test Success']]\n",
    "\n",
    "\n",
    "# Merge the datasets on the language model\n",
    "merged_data_new = pd.merge(renamed_diff_df, success_relevant, on='LM')\n",
    "\n",
    "\n",
    "# Calculate the correlation matrix with renamed columns\n",
    "# correlation_matrix_renamed = merged_data_new[['Files Modified', 'Hunk Count', 'Compile Success', 'Test Success', 'Errors']].corr()\n",
    "\n",
    "correlation_matrix_renamed = merged_data_new.corr(numeric_only=True)\n",
    "\n",
    "# selected_columns\n",
    "\n",
    "\n",
    "selected_correlations = correlation_matrix_renamed.loc[['Diff Files Modified', 'Diff Operation Count', 'Diff Hunk Count'], ['Other Errors', 'Test Errors', 'Test Success']]\n",
    "\n",
    "\n",
    "selected_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\caption{Correlation Heatmap between Diff Metrics and Success Metrics}\n",
      "\\label{tab:diff-correlation-agent}\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Diff Metric & Other Errors & Test Errors & \\begin{mlhead}Test \\\\Success\\end{mlhead} \\\\\n",
      "\\midrule\n",
      "Files Modified & -0.228 & 0.165 & 0.240 \\\\\n",
      "Operation Count & -0.222 & 0.176 & 0.232 \\\\\n",
      "Hunk Count & -0.379 & 0.292 & 0.393 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff_correlations_latex = selected_correlations.copy()\n",
    "\n",
    "# make metric a col\n",
    "diff_correlations_latex = diff_correlations_latex.reset_index()\n",
    "diff_correlations_latex = diff_correlations_latex.rename(columns={'index': 'Diff Metric'})\n",
    "diff_correlations_latex['Diff Metric'] = diff_correlations_latex['Diff Metric'].str.replace('Diff ', '')\n",
    "\n",
    "\n",
    "\n",
    "# Replace column names\n",
    "diff_correlations_latex = diff_correlations_latex.rename(columns={'Compile Success': '\\\\begin{mlhead}Compile \\\\\\\\Success\\\\end{mlhead}',\n",
    "                                   'Test Success': '\\\\begin{mlhead}Test \\\\\\\\Success\\\\end{mlhead}'})\n",
    "\n",
    "print(diff_correlations_latex.to_latex(index=False, escape=False, position=\"H\", caption=\"Correlation Heatmap between Diff Metrics and Success Metrics\", label=\"tab:diff-correlation-agent\", float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.load import loads\n",
    "\n",
    "chat_logs = dataset_path.glob('./*/out/*_prompt/chat_log.jsonl')\n",
    "\n",
    "\n",
    "# Build dictionary of first HumanMessage from each chat log\n",
    "message_to_commit = {}\n",
    "commit_to_message = defaultdict(set)\n",
    "\n",
    "for chat_log_path in chat_logs:\n",
    "    commit = chat_log_path.parts[-4]  # Assuming the commit is 4 levels up from the chat_log.jsonl file\n",
    "    lm = chat_log_path.parts[-2]\n",
    "    # print(commit)\n",
    "    with open(chat_log_path, 'r') as f:\n",
    "        file_text = f.read()\n",
    "        for line in file_text.split('\\n'):\n",
    "            msg = loads(line)\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                content = msg.content\n",
    "                composite_key = commit+'_'+lm\n",
    "                commit_to_message[composite_key].add(content)\n",
    "                message_to_commit[content] = commit\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae47f93961d4e83a0a760a8963458f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing trace files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-1.5-pro-001\n",
      "gpt-4o-mini\n",
      "claude-3-haiku@20240307\n",
      "claude-3-5-sonnet@20240620\n",
      "meta_llama-3.1-70b-instruct\n",
      "gpt-4o\n",
      "open-mistral-nemo\n"
     ]
    }
   ],
   "source": [
    "def process_trace_file(file_path, message_to_commit):\n",
    "    trace_to_commit = {}\n",
    "    lm = file_path.replace('../trace_langchain_', '').replace('_augmented_prompt.json', '')\n",
    "    print(lm)\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        parser = ijson.parse(f, multiple_values=True)\n",
    "        current_trace_id = None\n",
    "        current_content = None\n",
    "        \n",
    "        for prefix, event, value in parser:\n",
    "            if prefix.endswith('trace_id'):\n",
    "                current_trace_id = value\n",
    "            elif prefix.endswith('attributes.llm.input_messages.1.message.content'):\n",
    "                current_content = value\n",
    "            \n",
    "            if current_trace_id and current_content:\n",
    "                if current_content in message_to_commit:\n",
    "                    commit = message_to_commit[current_content]\n",
    "                    if commit in dspy_hashes:\n",
    "                        trace_to_commit[current_trace_id] = message_to_commit[current_content]\n",
    "                current_trace_id = None\n",
    "                current_content = None\n",
    "    \n",
    "    return trace_to_commit,lm\n",
    "\n",
    "# Main processing logic\n",
    "dataset_path = Path('dataset')\n",
    "\n",
    "trace_files = glob.glob('../trace_*.json')\n",
    "trace_to_commit = defaultdict(dict)\n",
    "\n",
    "flat_trace_to_commit = defaultdict(str)\n",
    "\n",
    "for trace_file in tqdm(trace_files, desc=\"Processing trace files\"):\n",
    "    trace, lm = process_trace_file(trace_file, message_to_commit)\n",
    "    trace_to_commit[lm] = trace\n",
    "    for key, value in trace.items():\n",
    "        flat_trace_to_commit[key] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trace_to_commit.json\", \"w\") as f:\n",
    "    json.dump(trace_to_commit, f, indent=2)\n",
    "\n",
    "with open(\"message_to_commit.json\", \"w\") as f:\n",
    "    json.dump(message_to_commit, f, indent=2)\n",
    "\n",
    "len(trace_to_commit[\"gemini-1.5-pro-001\"])\n",
    "\n",
    "traces_filtered = flat_trace_to_commit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Time for Execution and Unified Token Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891775d7b31b431c9d292fe80075fe74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /root/thesis/masterthesis-implementation-gpt/analysis/../trace_langchain_gemini-1.5-pro-001_augmented_prompt.json for language model: gemini-1.5-pro-001\n",
      "{'overall_metrics': {'min_start_time': datetime.datetime(2024, 8, 3, 12, 5, 10, 403077, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 4, 3, 16, 17, 78041, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=54666, microseconds=674964), 'total_input_token_count': 13539104, 'total_output_token_count': 539635}, 'trace_metrics': {'min_start_time': datetime.datetime(2024, 8, 3, 12, 5, 10, 403077, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 4, 3, 16, 17, 78041, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=13350, microseconds=174242), 'total_input_token_count': 5060767, 'total_output_token_count': 183225}}\n",
      "Minimum start time: 2024-08-03T12:05:10.403077+00:00\n",
      "Maximum end time: 2024-08-04T03:16:17.078041+00:00\n",
      "Total duration: 15:11:06.674964\n",
      "Total input token count: 13539104\n",
      "Total output token count: 539635\n",
      "-------------------- Subset --------------------\n",
      "Minimum start time: 2024-08-03T12:05:10.403077+00:00\n",
      "Maximum end time: 2024-08-04T03:16:17.078041+00:00\n",
      "Subset duration: 3:42:30.174242\n",
      "Subset input token count: 5060767\n",
      "Subset output token count: 183225\n",
      "\n",
      "Processing file: /root/thesis/masterthesis-implementation-gpt/analysis/../trace_langchain_gpt-4o-mini_augmented_prompt.json for language model: gpt-4o-mini\n",
      "{'overall_metrics': {'min_start_time': datetime.datetime(2024, 8, 1, 1, 20, 8, 345650, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 1, 22, 26, 35, 281486, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=75986, microseconds=935836), 'total_input_token_count': 30544504, 'total_output_token_count': 768981}, 'trace_metrics': {'min_start_time': datetime.datetime(2024, 8, 1, 1, 20, 8, 345650, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 1, 20, 52, 21, 672809, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=12943, microseconds=323159), 'total_input_token_count': 11002546, 'total_output_token_count': 261282}}\n",
      "Minimum start time: 2024-08-01T01:20:08.345650+00:00\n",
      "Maximum end time: 2024-08-01T22:26:35.281486+00:00\n",
      "Total duration: 21:06:26.935836\n",
      "Total input token count: 30544504\n",
      "Total output token count: 768981\n",
      "-------------------- Subset --------------------\n",
      "Minimum start time: 2024-08-01T01:20:08.345650+00:00\n",
      "Maximum end time: 2024-08-01T20:52:21.672809+00:00\n",
      "Subset duration: 3:35:43.323159\n",
      "Subset input token count: 11002546\n",
      "Subset output token count: 261282\n",
      "\n",
      "Processing file: /root/thesis/masterthesis-implementation-gpt/analysis/../trace_langchain_claude-3-haiku@20240307_augmented_prompt.json for language model: claude-3-haiku@20240307\n",
      "{'overall_metrics': {'min_start_time': datetime.datetime(2024, 8, 7, 10, 38, 49, 552432, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 7, 18, 26, 58, 36626, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=28088, microseconds=484194), 'total_input_token_count': 24644288, 'total_output_token_count': 1340665}, 'trace_metrics': {'min_start_time': datetime.datetime(2024, 8, 7, 10, 38, 49, 552432, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 7, 18, 26, 58, 36626, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=7574, microseconds=701563), 'total_input_token_count': 11446633, 'total_output_token_count': 606152}}\n",
      "Minimum start time: 2024-08-07T10:38:49.552432+00:00\n",
      "Maximum end time: 2024-08-07T18:26:58.036626+00:00\n",
      "Total duration: 7:48:08.484194\n",
      "Total input token count: 24644288\n",
      "Total output token count: 1340665\n",
      "-------------------- Subset --------------------\n",
      "Minimum start time: 2024-08-07T10:38:49.552432+00:00\n",
      "Maximum end time: 2024-08-07T18:26:58.036626+00:00\n",
      "Subset duration: 2:06:14.701563\n",
      "Subset input token count: 11446633\n",
      "Subset output token count: 606152\n",
      "\n",
      "Processing file: /root/thesis/masterthesis-implementation-gpt/analysis/../trace_langchain_claude-3-5-sonnet@20240620_augmented_prompt.json for language model: claude-3-5-sonnet@20240620\n",
      "{'overall_metrics': {'min_start_time': datetime.datetime(2024, 8, 4, 21, 57, 33, 40180, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 5, 20, 26, 6, 447754, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=80913, microseconds=407574), 'total_input_token_count': 41357473, 'total_output_token_count': 975658}, 'trace_metrics': {'min_start_time': datetime.datetime(2024, 8, 4, 21, 57, 33, 40180, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 5, 20, 26, 6, 447754, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=15072, microseconds=818008), 'total_input_token_count': 16362722, 'total_output_token_count': 397480}}\n",
      "Minimum start time: 2024-08-04T21:57:33.040180+00:00\n",
      "Maximum end time: 2024-08-05T20:26:06.447754+00:00\n",
      "Total duration: 22:28:33.407574\n",
      "Total input token count: 41357473\n",
      "Total output token count: 975658\n",
      "-------------------- Subset --------------------\n",
      "Minimum start time: 2024-08-04T21:57:33.040180+00:00\n",
      "Maximum end time: 2024-08-05T20:26:06.447754+00:00\n",
      "Subset duration: 4:11:12.818008\n",
      "Subset input token count: 16362722\n",
      "Subset output token count: 397480\n",
      "\n",
      "Processing file: /root/thesis/masterthesis-implementation-gpt/analysis/../trace_langchain_meta_llama-3.1-70b-instruct_augmented_prompt.json for language model: meta_llama-3.1-70b-instruct\n",
      "{'overall_metrics': {'min_start_time': datetime.datetime(2024, 8, 15, 23, 46, 27, 255065, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 16, 7, 37, 58, 7336, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=28290, microseconds=752271), 'total_input_token_count': 21204060, 'total_output_token_count': 403687}, 'trace_metrics': {'min_start_time': datetime.datetime(2024, 8, 15, 23, 46, 27, 255065, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 16, 7, 37, 58, 7336, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=9181, microseconds=341502), 'total_input_token_count': 10491635, 'total_output_token_count': 129332}}\n",
      "Minimum start time: 2024-08-15T23:46:27.255065+00:00\n",
      "Maximum end time: 2024-08-16T07:37:58.007336+00:00\n",
      "Total duration: 7:51:30.752271\n",
      "Total input token count: 21204060\n",
      "Total output token count: 403687\n",
      "-------------------- Subset --------------------\n",
      "Minimum start time: 2024-08-15T23:46:27.255065+00:00\n",
      "Maximum end time: 2024-08-16T07:37:58.007336+00:00\n",
      "Subset duration: 2:33:01.341502\n",
      "Subset input token count: 10491635\n",
      "Subset output token count: 129332\n",
      "\n",
      "Processing file: /root/thesis/masterthesis-implementation-gpt/analysis/../trace_langchain_gpt-4o_augmented_prompt.json for language model: gpt-4o\n",
      "{'overall_metrics': {'min_start_time': datetime.datetime(2024, 8, 8, 16, 21, 47, 502378, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 9, 16, 12, 35, 627575, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=85848, microseconds=125197), 'total_input_token_count': 28343858, 'total_output_token_count': 535741}, 'trace_metrics': {'min_start_time': datetime.datetime(2024, 8, 8, 16, 21, 47, 502378, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 9, 16, 12, 35, 627575, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=17180, microseconds=880250), 'total_input_token_count': 12480035, 'total_output_token_count': 190924}}\n",
      "Minimum start time: 2024-08-08T16:21:47.502378+00:00\n",
      "Maximum end time: 2024-08-09T16:12:35.627575+00:00\n",
      "Total duration: 23:50:48.125197\n",
      "Total input token count: 28343858\n",
      "Total output token count: 535741\n",
      "-------------------- Subset --------------------\n",
      "Minimum start time: 2024-08-08T16:21:47.502378+00:00\n",
      "Maximum end time: 2024-08-09T16:12:35.627575+00:00\n",
      "Subset duration: 4:46:20.880250\n",
      "Subset input token count: 12480035\n",
      "Subset output token count: 190924\n",
      "\n",
      "Processing file: /root/thesis/masterthesis-implementation-gpt/analysis/../trace_langchain_open-mistral-nemo_augmented_prompt.json for language model: open-mistral-nemo\n",
      "{'overall_metrics': {'min_start_time': datetime.datetime(2024, 8, 1, 23, 2, 48, 149979, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 2, 8, 7, 2, 525455, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=32654, microseconds=375476), 'total_input_token_count': 13652980, 'total_output_token_count': 296483}, 'trace_metrics': {'min_start_time': datetime.datetime(2024, 8, 1, 23, 2, 48, 149979, tzinfo=datetime.timezone.utc), 'max_end_time': datetime.datetime(2024, 8, 2, 8, 7, 2, 525455, tzinfo=datetime.timezone.utc), 'duration': datetime.timedelta(seconds=5744, microseconds=118297), 'total_input_token_count': 6859628, 'total_output_token_count': 122175}}\n",
      "Minimum start time: 2024-08-01T23:02:48.149979+00:00\n",
      "Maximum end time: 2024-08-02T08:07:02.525455+00:00\n",
      "Total duration: 9:04:14.375476\n",
      "Total input token count: 13652980\n",
      "Total output token count: 296483\n",
      "-------------------- Subset --------------------\n",
      "Minimum start time: 2024-08-01T23:02:48.149979+00:00\n",
      "Maximum end time: 2024-08-02T08:07:02.525455+00:00\n",
      "Subset duration: 1:35:44.118297\n",
      "Subset input token count: 6859628\n",
      "Subset output token count: 122175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def process_large_jsonl(file_path, language_model_id):\n",
    "    print(f\"Processing file: {file_path} for language model: {language_model_id}\")\n",
    "    \n",
    "    trace_data = {}\n",
    "    total_input_token_count, total_output_token_count, message_count, _, subset_input_token_count, subset_output_token_count, _ = sum_tokens(language_model_id)\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        parser = ijson.parse(file, multiple_values=True)\n",
    "        current_trace_id = None\n",
    "        current_span_kind = None\n",
    "        current_start = None\n",
    "        current_end = None\n",
    "        \n",
    "        for prefix, event, value in parser:\n",
    "            if prefix.endswith('.trace_id') and event == 'string':\n",
    "\n",
    "                if current_trace_id :\n",
    "                    # Save data for the previous trace\n",
    "                    trace_data[current_trace_id] = {\n",
    "                        'start_time': current_start,\n",
    "                        'end_time': current_end,\n",
    "                        'input_tokens': current_input_tokens,\n",
    "                        'output_tokens': current_output_tokens\n",
    "                    }\n",
    "                # Reset for new trace\n",
    "                current_trace_id = value\n",
    "                current_start = None\n",
    "                current_end = None\n",
    "                current_input_tokens = 0\n",
    "                current_output_tokens = 0\n",
    "            \n",
    "            if prefix.endswith('attributes.openinference.span.kind') and event == 'string':\n",
    "                current_span_kind = value\n",
    "            \n",
    "            if prefix.endswith('start_time') and event == 'string':\n",
    "                current_start = datetime.fromisoformat(value.rstrip('Z')).replace(tzinfo=timezone.utc)\n",
    "            \n",
    "            elif prefix.endswith('end_time') and event == 'string':\n",
    "                current_end = datetime.fromisoformat(value.rstrip('Z')).replace(tzinfo=timezone.utc)\n",
    "\n",
    "            # target_date = datetime(2024,8,17, tzinfo=timezone.utc)\n",
    "            # if current_end and current_end.date() == target_date.date() and 'nemo' in file_path:\n",
    "            #     current_end = None\n",
    "            # if current_start and current_start.date() == target_date.date() and 'nemo' in file_path:\n",
    "            #     current_start = None\n",
    "\n",
    "    \n",
    "    # Save data for the last trace\n",
    "    if current_trace_id:\n",
    "        trace_data[current_trace_id] = {\n",
    "            'start_time': current_start,\n",
    "            'end_time': current_end,\n",
    "            'input_tokens': current_input_tokens,\n",
    "            'output_tokens': current_output_tokens\n",
    "        }\n",
    "\n",
    "    assert len(trace_data) > 0, \"No valid trace data found in the file.\"\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    min_start_time = min(data['start_time'] for data in trace_data.values() if data['start_time'])\n",
    "    max_end_time = max(data['end_time'] for data in trace_data.values() if data['end_time'])\n",
    "    overall_duration = max_end_time - min_start_time if min_start_time and max_end_time else None\n",
    "\n",
    "    trace_data_subset = {k: v for k, v in trace_data.items() if k in traces_filtered}\n",
    "    subset_start_times = [data['start_time'] for data in trace_data_subset.values() if data['start_time']]\n",
    "    subset_end_times = [data['end_time'] for data in trace_data_subset.values() if data['end_time']]\n",
    "    subset_min_start_time = min(subset_start_times) if subset_start_times else None\n",
    "    subset_max_end_time = max(subset_end_times) if subset_end_times else None\n",
    "    subset_duration = sum((data['end_time'] - data['start_time'] for data in trace_data_subset.values() if data['start_time'] and data['end_time']), timedelta())\n",
    "    \n",
    "    return {\n",
    "        'overall_metrics': {\n",
    "            'min_start_time': min_start_time,\n",
    "            'max_end_time': max_end_time,\n",
    "            'duration': overall_duration,\n",
    "            'total_input_token_count': total_input_token_count,\n",
    "            'total_output_token_count': total_output_token_count\n",
    "        },\n",
    "        'trace_metrics': {\n",
    "            'min_start_time': subset_min_start_time,\n",
    "            'max_end_time': subset_max_end_time,\n",
    "            'duration': subset_duration,\n",
    "            'total_input_token_count': subset_input_token_count,\n",
    "            'total_output_token_count': subset_output_token_count\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# glob *_augmented_prompt.json  \n",
    "glob_paths = glob.glob(os.path.join(os.path.abspath(\"\"), \"..\", \"trace_langchain_*_augmented_prompt.json\"))\n",
    "\n",
    "duration_by_language_model = defaultdict(dict)\n",
    "subset_duration_by_language_model = defaultdict(dict)\n",
    "\n",
    "for file_path in tqdm(glob_paths):\n",
    "    language_model_id = Path(file_path).parts[-1].replace(\"trace_langchain_\", \"\").replace(\"_augmented_prompt.json\", \"\")\n",
    "\n",
    "    # Usage\n",
    "    metrics = process_large_jsonl(file_path, language_model_id)\n",
    "\n",
    "    print(metrics)\n",
    "    overall_metrics, trace_metrics = metrics['overall_metrics'], metrics['trace_metrics']\n",
    "\n",
    "    min_start_time = overall_metrics['min_start_time']\n",
    "    max_end_time = overall_metrics['max_end_time']\n",
    "    overall_duration = overall_metrics['duration']\n",
    "    total_input_token_count = overall_metrics['total_input_token_count']\n",
    "    total_output_token_count = overall_metrics['total_output_token_count']\n",
    "\n",
    "    subset_min_start_time = trace_metrics['min_start_time']\n",
    "    subset_max_end_time = trace_metrics['max_end_time']\n",
    "    subset_duration = trace_metrics['duration']\n",
    "    subset_input_token_count = trace_metrics['total_input_token_count']\n",
    "    subset_output_token_count = trace_metrics['total_output_token_count']\n",
    "\n",
    "    duration_by_language_model[language_model_id] = {\"duration\": overall_duration, \"total_input_token_count\": total_input_token_count, \"total_output_token_count\": total_output_token_count}\n",
    "    subset_duration_by_language_model[language_model_id] = {\"duration\": subset_duration, \"total_input_token_count\": subset_input_token_count, \"total_output_token_count\": subset_output_token_count}\n",
    "\n",
    "    if min_start_time and max_end_time:\n",
    "        print(f\"Minimum start time: {min_start_time.isoformat()}\")\n",
    "        print(f\"Maximum end time: {max_end_time.isoformat()}\")\n",
    "        print(f\"Total duration: {overall_duration}\")\n",
    "        print(f\"Total input token count: {total_input_token_count}\")\n",
    "        print(f\"Total output token count: {total_output_token_count}\")\n",
    "\n",
    "        print(\"-\"*20, \"Subset\", \"-\"*20)\n",
    "        print(f\"Minimum start time: {subset_min_start_time.isoformat()}\")\n",
    "        print(f\"Maximum end time: {subset_max_end_time.isoformat()}\")\n",
    "        print(f\"Subset duration: {subset_duration}\")\n",
    "        print(f\"Subset input token count: {subset_input_token_count}\")\n",
    "        print(f\"Subset output token count: {subset_output_token_count}\")\n",
    "        print()\n",
    "\n",
    "    else:\n",
    "        print(\"No valid time entries found in the file.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    duration total_input_token_count  \\\n",
      "LM                                                                     \n",
      "gemini-1.5-pro-001           15:11:06.674964                13539104   \n",
      "gpt-4o-mini                  21:06:26.935836                30544504   \n",
      "claude-3-haiku@20240307       7:48:08.484194                24644288   \n",
      "claude-3-5-sonnet@20240620   22:28:33.407574                41357473   \n",
      "meta_llama-3.1-70b-instruct   7:51:30.752271                21204060   \n",
      "gpt-4o                       23:50:48.125197                28343858   \n",
      "open-mistral-nemo             9:04:14.375476                13652980   \n",
      "\n",
      "                            total_output_token_count Agent65 duration  \\\n",
      "LM                                                                      \n",
      "gemini-1.5-pro-001                            539635   3:42:30.174242   \n",
      "gpt-4o-mini                                   768981   3:35:43.323159   \n",
      "claude-3-haiku@20240307                      1340665   2:06:14.701563   \n",
      "claude-3-5-sonnet@20240620                    975658   4:11:12.818008   \n",
      "meta_llama-3.1-70b-instruct                   403687   2:33:01.341502   \n",
      "gpt-4o                                        535741   4:46:20.880250   \n",
      "open-mistral-nemo                             296483   1:35:44.118297   \n",
      "\n",
      "                            Agent65 total_input_token_count  \\\n",
      "LM                                                            \n",
      "gemini-1.5-pro-001                                  5060767   \n",
      "gpt-4o-mini                                        11002546   \n",
      "claude-3-haiku@20240307                            11446633   \n",
      "claude-3-5-sonnet@20240620                         16362722   \n",
      "meta_llama-3.1-70b-instruct                        10491635   \n",
      "gpt-4o                                             12480035   \n",
      "open-mistral-nemo                                   6859628   \n",
      "\n",
      "                            Agent65 total_output_token_count  \n",
      "LM                                                            \n",
      "gemini-1.5-pro-001                                    183225  \n",
      "gpt-4o-mini                                           261282  \n",
      "claude-3-haiku@20240307                               606152  \n",
      "claude-3-5-sonnet@20240620                            397480  \n",
      "meta_llama-3.1-70b-instruct                           129332  \n",
      "gpt-4o                                                190924  \n",
      "open-mistral-nemo                                     122175  \n",
      "                  LM         duration total_input_token_count  \\\n",
      "0     gemini-1.5-pro  15:11:06.674964                13539104   \n",
      "1        gpt-4o-mini  21:06:26.935836                30544504   \n",
      "2     claude-3-haiku   7:48:08.484194                24644288   \n",
      "3  claude-3.5-sonnet  22:28:33.407574                41357473   \n",
      "4      Llama-3.1-70B   7:51:30.752271                21204060   \n",
      "5             gpt-4o  23:50:48.125197                28343858   \n",
      "6       mistral-nemo   9:04:14.375476                13652980   \n",
      "\n",
      "  total_output_token_count Agent65 duration Agent65 total_input_token_count  \\\n",
      "0                   539635   3:42:30.174242                         5060767   \n",
      "1                   768981   3:35:43.323159                        11002546   \n",
      "2                  1340665   2:06:14.701563                        11446633   \n",
      "3                   975658   4:11:12.818008                        16362722   \n",
      "4                   403687   2:33:01.341502                        10491635   \n",
      "5                   535741   4:46:20.880250                        12480035   \n",
      "6                   296483   1:35:44.118297                         6859628   \n",
      "\n",
      "  Agent65 total_output_token_count total_tokens Agent65 total_tokens  Attempts  \n",
      "0                           183225     14078739              5243992       140  \n",
      "1                           261282     31313485             11263828       140  \n",
      "2                           606152     25984953             12052785       140  \n",
      "3                           397480     42333131             16760202       140  \n",
      "4                           129332     21607747             10620967       140  \n",
      "5                           190924     28879599             12670959       140  \n",
      "6                           122175     13949463              6981803       132  \n",
      "--------------------------------------------------\n",
      "gemini-1.5-pro\n",
      "Agent65\n",
      "19.636547 140 0.14026105\n",
      "--------------------------------------------------\n",
      "gpt-4o-mini\n",
      "Agent65\n",
      "input in prices\n",
      "1.8071511 140 0.012908222142857143\n",
      "--------------------------------------------------\n",
      "claude-3-haiku\n",
      "Agent65\n",
      "input in prices\n",
      "3.61934825 140 0.0258524875\n",
      "--------------------------------------------------\n",
      "claude-3.5-sonnet\n",
      "Agent65\n",
      "input in prices\n",
      "55.050366000000004 140 0.39321690000000004\n",
      "--------------------------------------------------\n",
      "Llama-3.1-70B\n",
      "Agent65\n",
      "9.34645096 140 0.066760364\n",
      "--------------------------------------------------\n",
      "gpt-4o\n",
      "Agent65\n",
      "input in prices\n",
      "65.264035 140 0.4661716785714286\n",
      "--------------------------------------------------\n",
      "mistral-nemo\n",
      "Agent65\n",
      "input in prices\n",
      "2.0945409 132 0.01586773409090909\n",
      "--------------------------------------------------\n",
      "gemini-1.5-pro\n",
      "Agent65\n",
      "19.636547 140 0.3021007230769231\n",
      "--------------------------------------------------\n",
      "gpt-4o-mini\n",
      "Agent65\n",
      "input in prices\n",
      "1.8071511 140 0.027802324615384615\n",
      "--------------------------------------------------\n",
      "claude-3-haiku\n",
      "Agent65\n",
      "input in prices\n",
      "3.61934825 140 0.05568228076923076\n",
      "--------------------------------------------------\n",
      "claude-3.5-sonnet\n",
      "Agent65\n",
      "input in prices\n",
      "55.050366000000004 140 0.8469287076923078\n",
      "--------------------------------------------------\n",
      "Llama-3.1-70B\n",
      "Agent65\n",
      "9.34645096 140 0.14379155323076923\n",
      "--------------------------------------------------\n",
      "gpt-4o\n",
      "Agent65\n",
      "input in prices\n",
      "65.264035 140 1.004062076923077\n",
      "--------------------------------------------------\n",
      "mistral-nemo\n",
      "Agent65\n",
      "input in prices\n",
      "2.0945409 132 0.032223706153846156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>Agent Time (h)</th>\n",
       "      <th>Agent Token Sum</th>\n",
       "      <th>Agent Avg. Cost /Try</th>\n",
       "      <th>Agent65 Time (h)</th>\n",
       "      <th>Agent65 Token Sum</th>\n",
       "      <th>Agent65 Avg. Cost /Try</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>15.185187</td>\n",
       "      <td>14,078,739</td>\n",
       "      <td>0.140261</td>\n",
       "      <td>3.708382</td>\n",
       "      <td>5,243,992</td>\n",
       "      <td>0.302101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>21.107482</td>\n",
       "      <td>31,313,485</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>3.595368</td>\n",
       "      <td>11,263,828</td>\n",
       "      <td>0.027802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3-haiku</td>\n",
       "      <td>7.802357</td>\n",
       "      <td>25,984,953</td>\n",
       "      <td>0.025852</td>\n",
       "      <td>2.104084</td>\n",
       "      <td>12,052,785</td>\n",
       "      <td>0.055682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>22.475947</td>\n",
       "      <td>42,333,131</td>\n",
       "      <td>0.393217</td>\n",
       "      <td>4.186894</td>\n",
       "      <td>16,760,202</td>\n",
       "      <td>0.846929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>7.858542</td>\n",
       "      <td>21,607,747</td>\n",
       "      <td>0.066760</td>\n",
       "      <td>2.550373</td>\n",
       "      <td>10,620,967</td>\n",
       "      <td>0.143792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>23.846701</td>\n",
       "      <td>28,879,599</td>\n",
       "      <td>0.466172</td>\n",
       "      <td>4.772467</td>\n",
       "      <td>12,670,959</td>\n",
       "      <td>1.004062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>9.070660</td>\n",
       "      <td>13,949,463</td>\n",
       "      <td>0.015868</td>\n",
       "      <td>1.595588</td>\n",
       "      <td>6,981,803</td>\n",
       "      <td>0.032224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LM  Agent Time (h) Agent Token Sum  Agent Avg. Cost /Try  \\\n",
       "0     gemini-1.5-pro       15.185187      14,078,739              0.140261   \n",
       "1        gpt-4o-mini       21.107482      31,313,485              0.012908   \n",
       "2     claude-3-haiku        7.802357      25,984,953              0.025852   \n",
       "3  claude-3.5-sonnet       22.475947      42,333,131              0.393217   \n",
       "4      Llama-3.1-70B        7.858542      21,607,747              0.066760   \n",
       "5             gpt-4o       23.846701      28,879,599              0.466172   \n",
       "6       mistral-nemo        9.070660      13,949,463              0.015868   \n",
       "\n",
       "   Agent65 Time (h) Agent65 Token Sum  Agent65 Avg. Cost /Try  \n",
       "0          3.708382         5,243,992                0.302101  \n",
       "1          3.595368        11,263,828                0.027802  \n",
       "2          2.104084        12,052,785                0.055682  \n",
       "3          4.186894        16,760,202                0.846929  \n",
       "4          2.550373        10,620,967                0.143792  \n",
       "5          4.772467        12,670,959                1.004062  \n",
       "6          1.595588         6,981,803                0.032224  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose and create DataFrame\n",
    "df = pd.DataFrame(duration_by_language_model).T\n",
    "\n",
    "# Convert columns to datetime\n",
    "# df['min_start'] = pd.to_datetime(df['min_start'])\n",
    "# df['max_end'] = pd.to_datetime(df['max_end'])\n",
    "\n",
    "# Give Index the name \"LM\"\n",
    "df.index.name = \"LM\"\n",
    "\n",
    "# Create a new DataFrame for subset duration\n",
    "subset_df = pd.DataFrame(subset_duration_by_language_model).T\n",
    "\n",
    "# Rename columns in subset_df to include \"Agent65\"\n",
    "subset_df.columns = [f\"Agent65 {col}\" for col in subset_df.columns]\n",
    "\n",
    "# Merge the two DataFrames\n",
    "df = df.merge(subset_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "print(df)\n",
    "\n",
    "df['total_tokens'] = df['total_input_token_count'] + df['total_output_token_count']\n",
    "df['Agent65 total_tokens'] = df['Agent65 total_input_token_count'] + df['Agent65 total_output_token_count']\n",
    "\n",
    "with open('model_prices.json', 'r') as f:\n",
    "    prices = json.load(f)\n",
    "\n",
    "\n",
    "def calculate_cost(row, overwrite_tries=None):\n",
    "    if isinstance(row.name, int):\n",
    "         model = raw_model_mapper(row[\"LM\"])\n",
    "    else:\n",
    "        model = raw_model_mapper(row.name)\n",
    "\n",
    "    print('-'*50)\n",
    "    print(model)\n",
    "    if \"Input Tokens DSPY\" in row:\n",
    "        input_tokens = row['Input Tokens DSPY'] / 1_000_000\n",
    "        output_tokens = row['Output Tokens DSPY'] / 1_000_000\n",
    "        print(\"DSPY\")\n",
    "    elif \"Agent65 total_tokens\" in row:\n",
    "        input_tokens = row['Agent65 total_input_token_count'] / 1_000_000\n",
    "        output_tokens = row['Agent65 total_output_token_count'] / 1_000_000\n",
    "        print(\"Agent65\")\n",
    "    else:\n",
    "        input_tokens = row['total_input_token_count'] / 1_000_000 \n",
    "        output_tokens = row['total_output_token_count']/ 1_000_000\n",
    "        print(\"Agent\")\n",
    "    input_cost = 0\n",
    "    output_cost = 0\n",
    "\n",
    "    \n",
    "    if 'combined' in prices[model]:\n",
    "        combined_cost = prices[model]['combined']\n",
    "        input_cost = input_tokens * combined_cost\n",
    "        output_cost = output_tokens * combined_cost\n",
    "    else:\n",
    "        if 'gemini' in model:\n",
    "            if 'Input Tokens Short DSPY' in row and row.get('Output Tokens Short DSPY', 0) > 0:\n",
    "                input_tokens_short = row['Input Tokens Short DSPY'] / 1_000_000\n",
    "                output_tokens_short = row['Output Tokens Short DSPY'] / 1_000_000\n",
    "                input_tokens_long = row['Input Tokens Long DSPY'] / 1_000_000\n",
    "                output_tokens_long = row['Output Tokens Long DSPY'] / 1_000_000\n",
    "\n",
    "                input_cost = input_tokens_short * prices[model][\"input_short\"]\n",
    "                input_cost += input_tokens_long * prices[model][\"input_long\"]\n",
    "                output_cost = output_tokens * prices[model][\"output_short\"]\n",
    "                output_cost += output_tokens_long * prices[model][\"output_long\"]\n",
    "            else:\n",
    "                input_cost = input_tokens * prices[model][\"input_short\"]\n",
    "                output_cost = output_tokens * prices[model][\"output_short\"]\n",
    "\n",
    "        elif 'input' in prices[model]:\n",
    "            print(\"input in prices\")\n",
    "            input_cost = input_tokens * prices[model]['input']\n",
    "            output_cost = output_tokens * prices[model]['output']\n",
    "\n",
    "\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    # Look up the number of attempts from success_df\n",
    "\n",
    "    attempts = -1\n",
    "    if isinstance(overwrite_tries, int) and overwrite_tries > 0:\n",
    "        attempts = overwrite_tries\n",
    "    elif row[\"Attempts\"] > 0:\n",
    "        attempts = row[\"Attempts\"]\n",
    "\n",
    "    \n",
    "    # Calculate cost per attempt\n",
    "    cost_per_attempt = total_cost / attempts if attempts > 0 else 0\n",
    "\n",
    "    print(total_cost, row[\"Attempts\"], cost_per_attempt)\n",
    "    \n",
    "    return cost_per_attempt\n",
    "\n",
    "\n",
    "\n",
    "df.index = df.index.map(raw_model_mapper)\n",
    "\n",
    "# df['LM'] = df.index.map(raw_model_mapper)\n",
    "\n",
    "df = df.merge(success_df[['LM', 'Attempts']], on='LM', how='left')\n",
    "\n",
    "print(df)\n",
    "\n",
    "df['cost_per_attempt'] = df.apply(lambda row: calculate_cost(row), axis=1, result_type=\"expand\")\n",
    "df['Agent65 cost_per_attempt'] = df.apply(lambda row: calculate_cost(row, 65), axis=1, result_type=\"expand\")\n",
    "\n",
    "\n",
    "# Calculate duration and add new column\n",
    "df['duration'] = pd.to_timedelta(df['duration'])\n",
    "df['duration_secs'] = df['duration'].dt.total_seconds()\n",
    "df['duration_hours'] = df['duration'].dt.total_seconds() / 3600\n",
    "\n",
    "# df['Agent65 duration'] = df['Agent65 max_end'] - df['Agent65 min_start']\n",
    "df['Agent65 duration'] = pd.to_timedelta(df['Agent65 duration'])\n",
    "df['Agent65 duration_secs'] = df['Agent65 duration'].dt.total_seconds()\n",
    "df['Agent65 duration_hours'] = df['Agent65 duration'].dt.total_seconds() / 3600\n",
    "\n",
    "# replace index by get_language_model\n",
    "df.index = df.index.map(raw_model_mapper)\n",
    "\n",
    "\n",
    "# Move index into a column \"LM\"\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# add decimal places sep to total_tokens\n",
    "df['total_tokens'] = df['total_tokens'].apply(lambda x: f\"{x:,}\")\n",
    "df['Agent65 total_tokens'] = df['Agent65 total_tokens'].apply(lambda x: f\"{x:,}\")\n",
    "\n",
    "\n",
    "final_df = df[['LM', 'duration_hours', 'total_tokens', 'cost_per_attempt', 'Agent65 duration_hours', 'Agent65 total_tokens', 'Agent65 cost_per_attempt']].rename(columns={\n",
    "    'duration_hours': 'Agent Time (h)', \n",
    "    'total_tokens': 'Agent Token Sum', \n",
    "    'cost_per_attempt': \"Agent Avg. Cost /Try\",\n",
    "    'Agent65 cost_per_attempt': \"Agent65 Avg. Cost /Try\",\n",
    "    'Agent65 duration_hours': 'Agent65 Time (h)',\n",
    "    'Agent65 total_tokens': 'Agent65 Token Sum'\n",
    "})\n",
    "\n",
    "\n",
    "# # LaTex Table with LM and duration_hours\n",
    "# latex_table = final_df.to_latex(\n",
    "#     index=False,\n",
    "#     float_format=\"%.2f\", \n",
    "#     caption=\"Duration of Augmented Prompt Execution by Language Model\", \n",
    "#     label=\"tab:augmented-prompt-duration\", \n",
    "#     position=\"H\"\n",
    "# )\n",
    "\n",
    "# print(latex_table)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "claude-3.5-sonnet\n",
      "DSPY\n",
      "input in prices\n",
      "128.780343 65 1.981236046153846\n",
      "--------------------------------------------------\n",
      "gemini-1.5-pro\n",
      "DSPY\n",
      "614.065739 65 9.447165215384615\n",
      "--------------------------------------------------\n",
      "gpt-4o\n",
      "DSPY\n",
      "input in prices\n",
      "165.437345 65 2.545189923076923\n",
      "--------------------------------------------------\n",
      "claude-3-haiku\n",
      "DSPY\n",
      "input in prices\n",
      "9.313432 65 0.14328356923076924\n",
      "--------------------------------------------------\n",
      "mistral-nemo\n",
      "DSPY\n",
      "input in prices\n",
      "8.2222221 65 0.1264957246153846\n",
      "--------------------------------------------------\n",
      "gpt-4o-mini\n",
      "DSPY\n",
      "input in prices\n",
      "4.110495449999999 65 0.06323839153846153\n",
      "--------------------------------------------------\n",
      "Llama-3.1-70B\n",
      "DSPY\n",
      "8.99868288 65 0.13844127507692308\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Attempts</th>\n",
       "      <th>DSPY Time (h)</th>\n",
       "      <th>DSPY Token Sum</th>\n",
       "      <th>DSPY Compile Success</th>\n",
       "      <th>DSPY Fixed</th>\n",
       "      <th>DSPY Errors</th>\n",
       "      <th>Input Tokens DSPY</th>\n",
       "      <th>Output Tokens DSPY</th>\n",
       "      <th>...</th>\n",
       "      <th>Output Tokens Short DSPY</th>\n",
       "      <th>Input Tokens Long DSPY</th>\n",
       "      <th>Output Tokens Long DSPY</th>\n",
       "      <th>DSPY Avg. Cost /Try</th>\n",
       "      <th>Agent Time (h)</th>\n",
       "      <th>Agent Token Sum</th>\n",
       "      <th>Agent Avg. Cost /Try</th>\n",
       "      <th>Agent65 Time (h)</th>\n",
       "      <th>Agent65 Token Sum</th>\n",
       "      <th>Agent65 Avg. Cost /Try</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>2024-06-23</td>\n",
       "      <td>65</td>\n",
       "      <td>2.108296</td>\n",
       "      <td>10225776</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>10116424</td>\n",
       "      <td>109352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138441</td>\n",
       "      <td>7.858542</td>\n",
       "      <td>21,607,747</td>\n",
       "      <td>0.066760</td>\n",
       "      <td>2.550373</td>\n",
       "      <td>10,620,967</td>\n",
       "      <td>0.143792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-3-haiku</td>\n",
       "      <td>2024-03-19</td>\n",
       "      <td>65</td>\n",
       "      <td>13.108757</td>\n",
       "      <td>33342196</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>32364313</td>\n",
       "      <td>977883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143284</td>\n",
       "      <td>7.802357</td>\n",
       "      <td>25,984,953</td>\n",
       "      <td>0.025852</td>\n",
       "      <td>2.104084</td>\n",
       "      <td>12,052,785</td>\n",
       "      <td>0.055682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>2024-06-20</td>\n",
       "      <td>65</td>\n",
       "      <td>12.623933</td>\n",
       "      <td>39102221</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>38146081</td>\n",
       "      <td>956140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.981236</td>\n",
       "      <td>22.475947</td>\n",
       "      <td>42,333,131</td>\n",
       "      <td>0.393217</td>\n",
       "      <td>4.186894</td>\n",
       "      <td>16,760,202</td>\n",
       "      <td>0.846929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>65</td>\n",
       "      <td>16.812150</td>\n",
       "      <td>120935424</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>119489811</td>\n",
       "      <td>1445613</td>\n",
       "      <td>...</td>\n",
       "      <td>1361327.0</td>\n",
       "      <td>51114988.0</td>\n",
       "      <td>84286.0</td>\n",
       "      <td>9.447165</td>\n",
       "      <td>15.185187</td>\n",
       "      <td>14,078,739</td>\n",
       "      <td>0.140261</td>\n",
       "      <td>3.708382</td>\n",
       "      <td>5,243,992</td>\n",
       "      <td>0.302101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>65</td>\n",
       "      <td>17.444548</td>\n",
       "      <td>31855785</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>31239943</td>\n",
       "      <td>615842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.545190</td>\n",
       "      <td>23.846701</td>\n",
       "      <td>28,879,599</td>\n",
       "      <td>0.466172</td>\n",
       "      <td>4.772467</td>\n",
       "      <td>12,670,959</td>\n",
       "      <td>1.004062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>65</td>\n",
       "      <td>12.653006</td>\n",
       "      <td>22533745</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>20910559</td>\n",
       "      <td>1623186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063238</td>\n",
       "      <td>21.107482</td>\n",
       "      <td>31,313,485</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>3.595368</td>\n",
       "      <td>11,263,828</td>\n",
       "      <td>0.027802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>65</td>\n",
       "      <td>5.011655</td>\n",
       "      <td>27407407</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>26502242</td>\n",
       "      <td>905165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126496</td>\n",
       "      <td>9.070660</td>\n",
       "      <td>13,949,463</td>\n",
       "      <td>0.015868</td>\n",
       "      <td>1.595588</td>\n",
       "      <td>6,981,803</td>\n",
       "      <td>0.032224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LM Release Date  Attempts  DSPY Time (h)  DSPY Token Sum  \\\n",
       "0      Llama-3.1-70B   2024-06-23        65       2.108296        10225776   \n",
       "1     claude-3-haiku   2024-03-19        65      13.108757        33342196   \n",
       "2  claude-3.5-sonnet   2024-06-20        65      12.623933        39102221   \n",
       "3     gemini-1.5-pro   2024-05-24        65      16.812150       120935424   \n",
       "4             gpt-4o   2024-05-13        65      17.444548        31855785   \n",
       "5        gpt-4o-mini   2024-06-18        65      12.653006        22533745   \n",
       "6       mistral-nemo   2024-06-18        65       5.011655        27407407   \n",
       "\n",
       "   DSPY Compile Success  DSPY Fixed  DSPY Errors  Input Tokens DSPY  \\\n",
       "0                     7           4           54           10116424   \n",
       "1                    22           7           36           32364313   \n",
       "2                    28          12           25           38146081   \n",
       "3                    24          10           31          119489811   \n",
       "4                    26           8           30           31239943   \n",
       "5                    11           4           50           20910559   \n",
       "6                    14           3           48           26502242   \n",
       "\n",
       "   Output Tokens DSPY  ...  Output Tokens Short DSPY  Input Tokens Long DSPY  \\\n",
       "0              109352  ...                       0.0                     0.0   \n",
       "1              977883  ...                       0.0                     0.0   \n",
       "2              956140  ...                       0.0                     0.0   \n",
       "3             1445613  ...                 1361327.0              51114988.0   \n",
       "4              615842  ...                       0.0                     0.0   \n",
       "5             1623186  ...                       0.0                     0.0   \n",
       "6              905165  ...                       0.0                     0.0   \n",
       "\n",
       "   Output Tokens Long DSPY  DSPY Avg. Cost /Try  Agent Time (h)  \\\n",
       "0                      0.0             0.138441        7.858542   \n",
       "1                      0.0             0.143284        7.802357   \n",
       "2                      0.0             1.981236       22.475947   \n",
       "3                  84286.0             9.447165       15.185187   \n",
       "4                      0.0             2.545190       23.846701   \n",
       "5                      0.0             0.063238       21.107482   \n",
       "6                      0.0             0.126496        9.070660   \n",
       "\n",
       "   Agent Token Sum Agent Avg. Cost /Try  Agent65 Time (h)  Agent65 Token Sum  \\\n",
       "0       21,607,747             0.066760          2.550373         10,620,967   \n",
       "1       25,984,953             0.025852          2.104084         12,052,785   \n",
       "2       42,333,131             0.393217          4.186894         16,760,202   \n",
       "3       14,078,739             0.140261          3.708382          5,243,992   \n",
       "4       28,879,599             0.466172          4.772467         12,670,959   \n",
       "5       31,313,485             0.012908          3.595368         11,263,828   \n",
       "6       13,949,463             0.015868          1.595588          6,981,803   \n",
       "\n",
       "  Agent65 Avg. Cost /Try  \n",
       "0               0.143792  \n",
       "1               0.055682  \n",
       "2               0.846929  \n",
       "3               0.302101  \n",
       "4               1.004062  \n",
       "5               0.027802  \n",
       "6               0.032224  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"dspy_data.json\", \"r\") as f:\n",
    "    dspy_data = json.load(f)\n",
    "\n",
    "dspy_df = pd.DataFrame(dspy_data)\n",
    "\n",
    "\n",
    "# dspy_df['DSPY Total Tokens'] = (dspy_df['Input Tokens DSPY'] + dspy_df['Output Tokens DSPY']).astype(int)\n",
    "dspy_df['DSPY Avg. Cost /Try'] = dspy_df.apply(lambda row: calculate_cost(row), axis=1, result_type=\"expand\")\n",
    "\n",
    "\n",
    "dspy_df = dspy_df.merge(final_df, on=\"LM\", how=\"outer\")\n",
    "\n",
    "with open(\"model_metadata.json\", \"r\") as f:\n",
    "    model_metadata = json.load(f)\n",
    "\n",
    "# add release date for each model\n",
    "model_metadata_df = pd.DataFrame(model_metadata[\"models\"])\n",
    "model_metadata_df[\"LM\"] = model_metadata_df[\"name\"]\n",
    "model_metadata_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "dspy_df = dspy_df.merge(model_metadata_df, on=\"LM\", how=\"outer\")\n",
    "# move to second column and rename to Release Date\n",
    "dspy_df.rename(columns={\"releaseDate\": \"Release Date\", \"DSPY Total Tokens\": \"DSPY Token Sum\", \"DSPY Test Success\": \"DSPY Fixed\", \"DSPY Duration (hours)\": \"DSPY Time (h)\"}, inplace=True)\n",
    "\n",
    "cols = list(dspy_df.columns)\n",
    "cols.insert(1, cols.pop(cols.index(\"Release Date\")))\n",
    "dspy_df = dspy_df[cols]\n",
    "\n",
    "\n",
    "dspy_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_65_columns = {\n",
    "    \"Compile Success\": \"Agent65 Test Errors\",\n",
    "    \"Errors\": \"Agent65 General Errors\",\n",
    "    \"Test Success\": \"Agent65 Fixed\", \n",
    "    \"Attempts\": \"Agent65 Attempts\",\n",
    "    \"Other Errors\": \"Agent65 General Errors\",\n",
    "    \"Test Errors\": \"Agent65 Test Errors\",\n",
    "}\n",
    "\n",
    "success_65_df_pre_merge = success_65_df.rename(columns=agent_65_columns)\n",
    "\n",
    "correlation_df_final = dspy_df.merge(success_df, on=\"LM\", how=\"outer\")\n",
    "\n",
    "correlation_df_final = correlation_df_final.merge(success_65_df_pre_merge, on=\"LM\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Cost --------------------\n",
      "Correlation between DSPY Fixed and DSPY Avg. Cost /Try: r = 0.602, p = 0.1529\n",
      "Correlation between Test Success and Agent Avg. Cost /Try: r = 0.816, p = 0.02507\n",
      "Correlation between Agent65 Fixed and Agent65 Avg. Cost /Try: r = 0.845, p = 0.01666\n",
      "-------------------- Time --------------------\n",
      "Correlation between DSPY Fixed and DSPY Time (h): r = 0.667, p = 0.1017\n",
      "Correlation between Test Success and Agent Time (h): r = 0.734, p = 0.06061\n",
      "Correlation between Agent65 Fixed and Agent65 Time (h): r = 0.885, p = 0.008103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# I need correlation between DSPY Fixed and DSPY Avg. Cost /Try\n",
    "# I need the correlation for Test Success and Agent Avg. Cost /Try\n",
    "# I need it for Agent65 Test Success and Agent65 Avg. Cost /Try\n",
    "\n",
    "# Assuming correlation_df_final is your DataFrame\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def get_correlation(col1, col2):\n",
    "    r, p = pearsonr(correlation_df_final[col1], correlation_df_final[col2])\n",
    "    print(f\"Correlation between {col1} and {col2}: r = {r:.3}, p = {p:.4}\")\n",
    "\n",
    "\n",
    "print('-'*20, \"Cost\", '-'*20)\n",
    "get_correlation('DSPY Fixed', 'DSPY Avg. Cost /Try')\n",
    "get_correlation('Test Success', 'Agent Avg. Cost /Try')\n",
    "get_correlation('Agent65 Fixed', 'Agent65 Avg. Cost /Try')\n",
    "\n",
    "print('-'*20, \"Time\", '-'*20)\n",
    "\n",
    "get_correlation('DSPY Fixed', 'DSPY Time (h)')\n",
    "get_correlation('Test Success', 'Agent Time (h)')\n",
    "get_correlation('Agent65 Fixed', 'Agent65 Time (h)')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LM', 'Agent65 Attempts', 'Agent65 Fixed', 'Agent65 Test Errors',\n",
      "       'Agent65 General Errors'],\n",
      "      dtype='object')\n",
      "Index(['LM', 'Release Date', 'Attempts_x', 'DSPY Time (h)', 'DSPY Token Sum',\n",
      "       'DSPY Test Errors', 'DSPY Fixed', 'DSPY General Errors',\n",
      "       'Input Tokens DSPY', 'Output Tokens DSPY', 'Input Tokens Short DSPY',\n",
      "       'Output Tokens Short DSPY', 'Input Tokens Long DSPY',\n",
      "       'Output Tokens Long DSPY', 'DSPY Avg. Cost /Try', 'Agent Time (h)',\n",
      "       'Agent Token Sum', 'Agent Avg. Cost /Try', 'Agent65 Time (h)',\n",
      "       'Agent65 Token Sum', 'Agent65 Avg. Cost /Try', 'Attempts_y',\n",
      "       'Agent Fixed', 'Agent Test Errors', 'Agent General Errors',\n",
      "       'Agent65 Attempts', 'Agent65 Fixed', 'Agent65 Test Errors',\n",
      "       'Agent65 General Errors'],\n",
      "      dtype='object')\n",
      "[('Metadata', 'LM'), ('Zero-Shot (n=65)', 'DSPY Fixed'), ('Zero-Shot (n=65)', 'DSPY Errors (Test, Other)'), ('Zero-Shot (n=65)', 'DSPY Time (h)'), ('Zero-Shot (n=65)', 'DSPY Token Sum'), ('Zero-Shot (n=65)', 'DSPY Avg. Cost /Try'), ('Agent (n=65)', 'Agent65 Fixed'), ('Agent (n=65)', 'Agent65 Errors (Test, Other)'), ('Agent (n=65)', 'Agent65 Time (h)'), ('Agent (n=65)', 'Agent65 Token Sum'), ('Agent (n=65)', 'Agent65 Avg. Cost /Try'), ('Agent (n=140)', 'Agent Fixed'), ('Agent (n=140)', 'Agent Errors (Test, Other)'), ('Agent (n=140)', 'Agent Time (h)'), ('Agent (n=140)', 'Agent Token Sum'), ('Agent (n=140)', 'Agent Avg. Cost /Try')]\n",
      "\n",
      "\\begin{table*}\n",
      "\\caption{Comparison of Language Models using the Zero-Shot and Agentic Approach}\n",
      "\\label{tab:lm-comparison}\n",
      "\\begin{minipage}{\\textwidth}\n",
      "\\begin{center}\n",
      "\\begin{tabular}{l|lrccc|lrccc|lrccc}\n",
      "\\toprule\n",
      "Metadata & \\multicolumn{5}{c}{Zero-Shot (n=65)} & \\multicolumn{5}{c}{Agent (n=65)} & \\multicolumn{5}{c}{Agent (n=140)} \\\\\n",
      "LM &\\begin{mlhead} \\\\ Fixed\\end{mlhead} & \\begin{mlhead}Errors \\\\ (Test, \\\\ Other)\\end{mlhead} & \\begin{mlhead}Time \\\\ (h)\\end{mlhead} & \\begin{mlhead}Token \\\\ Sum\\end{mlhead} & \\begin{mlhead}Avg. \\\\ Cost \\\\ /Try\\end{mlhead} & \\begin{mlhead} \\\\ Fixed\\end{mlhead} &  \\begin{mlhead}Errors \\\\ (Test, \\\\ Other)\\end{mlhead} &  \\begin{mlhead}Time \\\\ (h)\\end{mlhead} &  \\begin{mlhead}Token \\\\ Sum\\end{mlhead} &  \\begin{mlhead}Avg. \\\\ Cost \\\\ /Try\\end{mlhead} &\\begin{mlhead} \\\\ Fixed\\end{mlhead} & \\begin{mlhead}Errors \\\\ (Test, \\\\ Other)\\end{mlhead} & \\begin{mlhead}Time \\\\ (h)\\end{mlhead} & \\begin{mlhead}Token \\\\ Sum\\end{mlhead} & \\begin{mlhead}Avg. \\\\ Cost \\\\ /Try\\end{mlhead} \\\\\n",
      "\\midrule\n",
      "Sonnet 3.5 & 12 & 28, 25 & 12.6 & 39M & \\$1.98 & 12 & 10, 43 & 4.2 & 17M & \\$0.85 & 32 & 12, 96 & 22.5 & 42M & \\$0.39 \\\\\n",
      "gpt-4o & 8 & 26, 30 & 17.4 & 32M & \\$2.55 & 9 & 9, 47 & 4.8 & 13M & \\$1.00 & 17 & 11, 112 & 23.8 & 29M & \\$0.47 \\\\\n",
      "Gemini Pro & 10 & 24, 31 & 16.8 & 121M & \\$9.45 & 4 & 0, 61 & 3.7 & 5M & \\$0.30 & 7 & 2, 131 & 15.2 & 14M & \\$0.14 \\\\\n",
      "GPT4o mini & 4 & 11, 50 & 12.7 & 22M & \\$0.06 & 6 & 7, 52 & 3.6 & 11M & \\$0.03 & 9 & 8, 123 & 21.1 & 31M & \\$0.01 \\\\\n",
      "Haiku 3 & 7 & 22, 36 & 13.1 & 33M & \\$0.14 & 2 & 0, 63 & 2.1 & 12M & \\$0.06 & 6 & 1, 133 & 7.8 & 26M & \\$0.03 \\\\\n",
      "Llama 3.1 & 4 & 7, 54 & 2.1 & 10M & \\$0.14 & 2 & 1, 62 & 2.6 & 11M & \\$0.14 & 6 & 2, 132 & 7.9 & 22M & \\$0.07 \\\\\n",
      "NeMo \\textsuperscript{a} & 3 & 14, 48 & 5.0 & 27M & \\$0.13 & 0 & 1, 63 & 1.6 & 7M & \\$0.03 & 1 & 1, 130 & 9.1 & 14M & \\$0.02 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\footnotetext[1]{The models used are claude-3.5-sonnet and claude-3-haiku, mistral-nemo, llama-3.1-70B and gemini-1.5-pro respectively, with the full names omitted for brevity}\n",
      "\\end{center}\n",
      "\\end{minipage}\n",
      "\\end{table*}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metadata</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Zero-Shot (n=65)</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Agent (n=65)</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Agent (n=140)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>Fixed</th>\n",
       "      <th>Errors (Test, Other)</th>\n",
       "      <th>Time (h)</th>\n",
       "      <th>Token Sum</th>\n",
       "      <th>Avg. Cost /Try</th>\n",
       "      <th>Fixed</th>\n",
       "      <th>Errors (Test, Other)</th>\n",
       "      <th>Time (h)</th>\n",
       "      <th>Token Sum</th>\n",
       "      <th>Avg. Cost /Try</th>\n",
       "      <th>Fixed</th>\n",
       "      <th>Errors (Test, Other)</th>\n",
       "      <th>Time (h)</th>\n",
       "      <th>Token Sum</th>\n",
       "      <th>Avg. Cost /Try</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>12</td>\n",
       "      <td>28, 25</td>\n",
       "      <td>12.6</td>\n",
       "      <td>39M</td>\n",
       "      <td>$1.98</td>\n",
       "      <td>12</td>\n",
       "      <td>10, 43</td>\n",
       "      <td>4.2</td>\n",
       "      <td>17M</td>\n",
       "      <td>$0.85</td>\n",
       "      <td>32</td>\n",
       "      <td>12, 96</td>\n",
       "      <td>22.5</td>\n",
       "      <td>42M</td>\n",
       "      <td>$0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>8</td>\n",
       "      <td>26, 30</td>\n",
       "      <td>17.4</td>\n",
       "      <td>32M</td>\n",
       "      <td>$2.55</td>\n",
       "      <td>9</td>\n",
       "      <td>9, 47</td>\n",
       "      <td>4.8</td>\n",
       "      <td>13M</td>\n",
       "      <td>$1.00</td>\n",
       "      <td>17</td>\n",
       "      <td>11, 112</td>\n",
       "      <td>23.8</td>\n",
       "      <td>29M</td>\n",
       "      <td>$0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>10</td>\n",
       "      <td>24, 31</td>\n",
       "      <td>16.8</td>\n",
       "      <td>121M</td>\n",
       "      <td>$9.45</td>\n",
       "      <td>4</td>\n",
       "      <td>0, 61</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5M</td>\n",
       "      <td>$0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>2, 131</td>\n",
       "      <td>15.2</td>\n",
       "      <td>14M</td>\n",
       "      <td>$0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>4</td>\n",
       "      <td>11, 50</td>\n",
       "      <td>12.7</td>\n",
       "      <td>22M</td>\n",
       "      <td>$0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>7, 52</td>\n",
       "      <td>3.6</td>\n",
       "      <td>11M</td>\n",
       "      <td>$0.03</td>\n",
       "      <td>9</td>\n",
       "      <td>8, 123</td>\n",
       "      <td>21.1</td>\n",
       "      <td>31M</td>\n",
       "      <td>$0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-3-haiku</td>\n",
       "      <td>7</td>\n",
       "      <td>22, 36</td>\n",
       "      <td>13.1</td>\n",
       "      <td>33M</td>\n",
       "      <td>$0.14</td>\n",
       "      <td>2</td>\n",
       "      <td>0, 63</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12M</td>\n",
       "      <td>$0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>1, 133</td>\n",
       "      <td>7.8</td>\n",
       "      <td>26M</td>\n",
       "      <td>$0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>4</td>\n",
       "      <td>7, 54</td>\n",
       "      <td>2.1</td>\n",
       "      <td>10M</td>\n",
       "      <td>$0.14</td>\n",
       "      <td>2</td>\n",
       "      <td>1, 62</td>\n",
       "      <td>2.6</td>\n",
       "      <td>11M</td>\n",
       "      <td>$0.14</td>\n",
       "      <td>6</td>\n",
       "      <td>2, 132</td>\n",
       "      <td>7.9</td>\n",
       "      <td>22M</td>\n",
       "      <td>$0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>3</td>\n",
       "      <td>14, 48</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27M</td>\n",
       "      <td>$0.13</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 63</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7M</td>\n",
       "      <td>$0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1, 130</td>\n",
       "      <td>9.1</td>\n",
       "      <td>14M</td>\n",
       "      <td>$0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metadata Zero-Shot (n=65)                                          \\\n",
       "                  LM            Fixed Errors (Test, Other) Time (h) Token Sum   \n",
       "2  claude-3.5-sonnet               12               28, 25     12.6       39M   \n",
       "4             gpt-4o                8               26, 30     17.4       32M   \n",
       "3     gemini-1.5-pro               10               24, 31     16.8      121M   \n",
       "5        gpt-4o-mini                4               11, 50     12.7       22M   \n",
       "1     claude-3-haiku                7               22, 36     13.1       33M   \n",
       "0      Llama-3.1-70B                4                7, 54      2.1       10M   \n",
       "6       mistral-nemo                3               14, 48      5.0       27M   \n",
       "\n",
       "                 Agent (n=65)                                             \\\n",
       "  Avg. Cost /Try        Fixed  Errors (Test, Other)  Time (h)  Token Sum   \n",
       "2          $1.98           12                10, 43       4.2        17M   \n",
       "4          $2.55            9                 9, 47       4.8        13M   \n",
       "3          $9.45            4                 0, 61       3.7         5M   \n",
       "5          $0.06            6                 7, 52       3.6        11M   \n",
       "1          $0.14            2                 0, 63       2.1        12M   \n",
       "0          $0.14            2                 1, 62       2.6        11M   \n",
       "6          $0.13            0                 1, 63       1.6         7M   \n",
       "\n",
       "                  Agent (n=140)                                          \\\n",
       "   Avg. Cost /Try         Fixed Errors (Test, Other) Time (h) Token Sum   \n",
       "2           $0.85            32               12, 96     22.5       42M   \n",
       "4           $1.00            17              11, 112     23.8       29M   \n",
       "3           $0.30             7               2, 131     15.2       14M   \n",
       "5           $0.03             9               8, 123     21.1       31M   \n",
       "1           $0.06             6               1, 133      7.8       26M   \n",
       "0           $0.14             6               2, 132      7.9       22M   \n",
       "6           $0.03             1               1, 130      9.1       14M   \n",
       "\n",
       "                  \n",
       "  Avg. Cost /Try  \n",
       "2          $0.39  \n",
       "4          $0.47  \n",
       "3          $0.14  \n",
       "5          $0.01  \n",
       "1          $0.03  \n",
       "0          $0.07  \n",
       "6          $0.02  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Assuming dspy_df and success_df are already defined as per your input\n",
    "\n",
    "def format_number(x, round_to_millions=False, add_usd_sign=False):\n",
    "    if isinstance(x, pd.Series):\n",
    "        return x.apply(lambda val: format_single_number(val, round_to_millions, add_usd_sign))\n",
    "    else:\n",
    "        return format_single_number(x, round_to_millions, add_usd_sign)\n",
    "\n",
    "def format_single_number(x, round_to_millions=False, add_usd_sign=False):\n",
    "    if pd.isna(x) or x == 'nan' or x == '-' or x == '' or x is None:\n",
    "        return '-'\n",
    "    \n",
    "    try:\n",
    "        num = float(str(x).replace(',', ''))\n",
    "        \n",
    "        if round_to_millions:\n",
    "            millions = round(num / 1_000_000, 1)\n",
    "            if millions == 0:\n",
    "                return '-'\n",
    "            if millions.is_integer():\n",
    "                return f'{int(millions)}M'\n",
    "            return f'{millions:.0f}M'\n",
    "        \n",
    "        if np.isclose(num, round(num)):\n",
    "            return f'{int(round(num)):,}'\n",
    "        \n",
    "        if add_usd_sign:\n",
    "            return f'${num:.2f}'\n",
    "        return f'{num:.1f}'\n",
    "    except ValueError:\n",
    "        return '-'\n",
    "\n",
    "\n",
    "def safe_percentage_to_float(x):\n",
    "    if pd.isna(x) or x == '-':\n",
    "        return 0.0\n",
    "    return float(x.rstrip('%')) / 100 if isinstance(x, str) else x\n",
    "\n",
    "def change(x):\n",
    "    if isinstance(x, float):\n",
    "        return x\n",
    "    return float(x.split(\" \")[0])\n",
    "\n",
    "\n",
    "\n",
    "merged_df = dspy_df.merge(success_df, on=\"LM\", how=\"outer\")\n",
    "\n",
    "\n",
    "\n",
    "agent_columns = {\n",
    "    \"Compile Success\": \"Agent Test Errors\",\n",
    "    \"Errors\": \"Agent General Errors\",\n",
    "    \"Test Success\": \"Agent Fixed\",\n",
    "    \"Attempts\": \"Agent Attempts\",\n",
    "    \"Test Errors\": \"Agent Test Errors\",\n",
    "    \"Other Errors\": \"Agent General Errors\",\n",
    "}\n",
    "\n",
    "\n",
    "print(success_65_df_pre_merge.columns)\n",
    "merged_df = merged_df.merge(success_65_df_pre_merge, on=\"LM\", how=\"outer\")\n",
    "\n",
    "merged_df['Sum of Success'] = (\n",
    "    merged_df['Test Success'].fillna(0).astype(int) +\n",
    "    merged_df['Agent65 Fixed'].fillna(0).astype(int) +\n",
    "    merged_df['DSPY Fixed'].fillna(0).astype(int)\n",
    ")\n",
    "\n",
    "# Sort by Sum of Success\n",
    "merged_df = merged_df.sort_values('Sum of Success', ascending=False)\n",
    "merged_df = merged_df.drop('Sum of Success', axis=1)\n",
    "\n",
    "general_renames = {\n",
    "    'DSPY Compile Success': 'DSPY Test Errors',\n",
    "    \"DSPY Errors\": \"DSPY General Errors\",\n",
    "}\n",
    "\n",
    "# Combine all renaming dictionaries\n",
    "all_renames = {**general_renames, **agent_columns}\n",
    "# Rename columns\n",
    "merged_df.rename(columns=all_renames, inplace=True)\n",
    "\n",
    "# merged_df.drop(columns=['Compile Success'], inplace=True)\n",
    "\n",
    "print(merged_df.columns)\n",
    "\n",
    "\n",
    "# Apply the formatting\n",
    "for col in merged_df.columns:\n",
    "    if col != 'LM':\n",
    "        if 'Token Sum' in col:\n",
    "            merged_df[col] = merged_df[col].apply(lambda x: format_number(x, round_to_millions=True))\n",
    "        elif 'Success' in col:\n",
    "            merged_df[col] = merged_df[col].apply(lambda x: x if not pd.isna(x) else '-')\n",
    "        elif 'Avg. Cost /Try' in col:\n",
    "            merged_df[col] = merged_df[col].apply(lambda x: format_number(x, add_usd_sign=True))\n",
    "        elif 'Date' in col:\n",
    "            pass\n",
    "        else:\n",
    "            merged_df[col] = merged_df[col].apply(lambda x: format_number(x))\n",
    "\n",
    "\n",
    "def format_errors(test_errors, general_errors):\n",
    "    test = '-' if pd.isna(test_errors) else str(int(test_errors))\n",
    "    general = '-' if pd.isna(general_errors) else str(int(general_errors))\n",
    "    return f\"{test}, {general}\"\n",
    "\n",
    "error_suffix = 'Errors (Test, Other)'\n",
    "\n",
    "for prefix in ['DSPY', 'Agent65', 'Agent']:\n",
    "    merged_df[f'{prefix} {error_suffix}'] = merged_df.apply(\n",
    "        lambda row: format_errors(row[f'{prefix} Test Errors'], row[f'{prefix} General Errors']), \n",
    "        axis=1\n",
    "    )\n",
    "    merged_df = merged_df.drop(columns=[f'{prefix} Test Errors', f'{prefix} General Errors'])\n",
    "\n",
    "\n",
    "def custom_sort_key(col_name):\n",
    "    order = ['Fixed', error_suffix, 'Time (h)', 'Token Sum', 'Avg. Cost /Try']\n",
    "    try:\n",
    "        return order.index(col_name)\n",
    "    except ValueError:\n",
    "        return len(order)\n",
    "\n",
    "# Reorder columns\n",
    "forbidden_words = ['Attempts']\n",
    "\n",
    "dspy_columns = [col for col in merged_df.columns if col.startswith('DSPY') and not any(word in col for word in forbidden_words)]\n",
    "agent_65_columns = [col for col in merged_df.columns if col.startswith('Agent65') and not any(word in col for word in forbidden_words)]\n",
    "agent_columns = [col for col in merged_df.columns if col.startswith('Agent') and col not in agent_65_columns and not any(word in col for word in forbidden_words)]\n",
    "dspy_columns = sorted(dspy_columns, key=lambda x: custom_sort_key(x.replace('DSPY ', '')))\n",
    "agent_65_columns = sorted(agent_65_columns, key=lambda x: custom_sort_key(x.replace('Agent65 ', '')))\n",
    "agent_columns = sorted(agent_columns, key=lambda x: custom_sort_key(x.replace('Agent ', '')))\n",
    "\n",
    "\n",
    "merged_df.drop('Release Date', axis=1, inplace=True)\n",
    "\n",
    "metadata_columns = ['LM']\n",
    "\n",
    "column_order = metadata_columns + dspy_columns + agent_65_columns + agent_columns\n",
    "\n",
    "dspy_len = len(dspy_columns)-2\n",
    "agent_65_len = len(agent_65_columns)-2\n",
    "agent_len = len(agent_columns)-2\n",
    "\n",
    "columns_format = 'l' * len(metadata_columns) + '|' + 'lr' + 'c' * dspy_len + '|' + 'lr' + 'c' * agent_65_len + '|' +'lr'+ 'c' * agent_len\n",
    "\n",
    "merged_df = merged_df[column_order]\n",
    "\n",
    "column_tuples = (\n",
    "    [('Metadata', col) for col in metadata_columns] +\n",
    "    [('Zero-Shot (n=65)', col) for col in dspy_columns] +\n",
    "    [('Agent (n=65)', col) for col in agent_65_columns] +\n",
    "    [('Agent (n=140)', col) for col in agent_columns]\n",
    ")\n",
    "print(column_tuples)\n",
    "merged_df.columns = pd.MultiIndex.from_tuples(column_tuples)\n",
    "\n",
    "# Rename columns to remove prefixes\n",
    "merged_df = merged_df.rename(columns=lambda x: x.replace('DSPY ', '').replace('Agent ', '').replace('Agent65', '') if x not in metadata_columns else x, level=1)\n",
    "\n",
    "# merged_df.drop(columns=['Errors'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = merged_df.to_latex(\n",
    "    index=False,\n",
    "    multicolumn=True,\n",
    "    multicolumn_format='c',\n",
    "    column_format=columns_format,\n",
    "    escape=True,\n",
    "    bold_rows=True,\n",
    "    # caption='Comparison of Language Models for DSPY and Agent Tasks',\n",
    "\n",
    "    # label='tab:lm-comparison',\n",
    "    # position='H'\n",
    ")\n",
    "\n",
    "# latex_table = latex_table.replace('\\\\begin{table}[H]', '\\\\begin{table*}')\n",
    "# latex_table = latex_table.replace('\\\\end{table}', '\\\\end{table*}')\n",
    "\n",
    "for col in merged_df.columns.get_level_values(1):\n",
    "    if ' ' in col:\n",
    "        latex_table = latex_table.replace(col, '\\\\begin{mlhead}' + col.replace(' ', ' \\\\\\\\ ') + '\\\\end{mlhead}')\n",
    "\n",
    "footnotes = {\n",
    "    # \"claude-3.5-sonnet\": \"Due to budgetary limitations, this model could not be executed for DSPY\",\n",
    "    # \"gemini-1.5-pro\": \"Due to budgetary limitations, this model could not be executed for DSPY\",\n",
    "    \"NeMo\": \"The models used are claude-3.5-sonnet and claude-3-haiku, mistral-nemo, llama-3.1-70B and gemini-1.5-pro respectively, with the full names omitted for brevity\"\n",
    "    # \"Llama-3.1-70B\": \"Together.ai, which we use for Llama inference supports tool use via a custom setup, which was not supported by Langchain at the time of writing.\"\n",
    "}\n",
    "\n",
    "latex_table = latex_table.replace('claude-3.5-sonnet', 'Sonnet 3.5').replace('gemini-1.5-pro', 'Gemini Pro').replace('mistral-nemo', 'NeMo').replace('Llama-3.1-70B', 'Llama 3.1').replace('gpt-4o-mini', 'GPT4o mini').replace('claude-3-haiku', 'Haiku 3')\n",
    "\n",
    "# Extract model names from latex_table\n",
    "model_names = re.findall(r'^(\\S+)\\s+&', latex_table, re.MULTILINE)\n",
    "\n",
    "\n",
    "# Create an ordered list of unique footnote texts\n",
    "ordered_footnote_texts = []\n",
    "for model in model_names:\n",
    "    if model in footnotes and footnotes[model] not in ordered_footnote_texts:\n",
    "        ordered_footnote_texts.append(footnotes[model])\n",
    "\n",
    "# Create a mapping of footnote texts to footnote numbers\n",
    "footnote_numbering = {text: i for i, text in enumerate(ordered_footnote_texts, 1)}\n",
    "\n",
    "# Generate mapping for footnotes\n",
    "mapping = dict(zip(range(1, len(ordered_footnote_texts) + 1), string.ascii_lowercase))\n",
    "\n",
    "# Apply footnotes to the table content\n",
    "for model in model_names:\n",
    "    if model in footnotes:\n",
    "        footnote_num = footnote_numbering[footnotes[model]]\n",
    "        latex_table = latex_table.replace(\n",
    "            f\"{model} &\",\n",
    "            f\"{model} \\\\textsuperscript{{{mapping[footnote_num]}}} &\",\n",
    "            1  # Replace only the first occurrence to maintain order\n",
    "        )\n",
    "\n",
    "# Generate footnote text\n",
    "footnote_text = \"\\n\".join(\n",
    "    f\"\\\\footnotetext[{footnote_numbering[text]}]{{{text}}}\"\n",
    "    for text in ordered_footnote_texts\n",
    ")\n",
    "\n",
    "latex_table = f\"\"\"\n",
    "\\\\begin{{table*}}\n",
    "\\\\caption{{Comparison of Language Models using the Zero-Shot and Agentic Approach}}\n",
    "\\\\label{{tab:lm-comparison}}\n",
    "\\\\begin{{minipage}}{{\\\\textwidth}}\n",
    "\\\\begin{{center}}\n",
    "{latex_table}\n",
    "{footnote_text}\n",
    "\\\\end{{center}}\n",
    "\\\\end{{minipage}}\n",
    "\\\\end{{table*}}\n",
    "\"\"\"\n",
    "\n",
    "if generated_graphs_path.exists():\n",
    "    with open(generated_graphs_path / \"lm_comparison_approach_table.tex\", \"w\") as f:\n",
    "        f.write(latex_table)\n",
    "\n",
    "print(latex_table)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github Dependency Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\") \n",
    "\n",
    "# Cache to store stargazer counts\n",
    "stargazers_cache = {}\n",
    "\n",
    "# Function to get stargazers count using GitHub GraphQL API with caching\n",
    "def get_stargazers_count(repo_slug):\n",
    "    if repo_slug in stargazers_cache:\n",
    "        return stargazers_cache[repo_slug]\n",
    "\n",
    "    github_token = os.getenv('GITHUB_TOKEN')\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {github_token}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    if \"/\" not in repo_slug:\n",
    "        return -1\n",
    "    \n",
    "    owner, name = repo_slug.split('/')\n",
    "    \n",
    "    query = \"\"\"\n",
    "    query($owner: String!, $name: String!) {\n",
    "      repository(owner: $owner, name: $name) {\n",
    "        stargazerCount\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    variables = {\n",
    "        'owner': owner,\n",
    "        'name': name\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        'https://api.github.com/graphql',\n",
    "        json={'query': query, 'variables': variables},\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        stargazer_count = result['data']['repository']['stargazerCount']\n",
    "        stargazers_cache[repo_slug] = stargazer_count\n",
    "        return stargazer_count\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {repo_slug}: {response.json()}\")\n",
    "        return -1\n",
    "\n",
    "# Function to load JSON data for a given commit\n",
    "def load_json_data(commit):\n",
    "    file_path = Path(os.path.abspath(\"\")) / \"bump\" / \"data\" / \"benchmark\" / f\"{commit}.json\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/thesis/masterthesis-implementation-gpt/analysis/bump/data/benchmark/489aad6060454d0b7b34a144e0b345c5a3a199f5.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m commit_type, commits \u001b[38;5;129;01min\u001b[39;00m commit_types\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m commit \u001b[38;5;129;01min\u001b[39;00m commits:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# Load JSON data for the commit\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m         json_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_json_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Get the GitHub repo slug\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         github_repo_slug \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdatedDependency\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgithubRepoSlug\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[111], line 59\u001b[0m, in \u001b[0;36mload_json_data\u001b[0;34m(commit)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_json_data\u001b[39m(commit):\n\u001b[1;32m     58\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m Path(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbump\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(file)\n",
      "File \u001b[0;32m~/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/thesis/masterthesis-implementation-gpt/analysis/bump/data/benchmark/489aad6060454d0b7b34a144e0b345c5a3a199f5.json'"
     ]
    }
   ],
   "source": [
    "# Clone successes structure for storing stargazers counts\n",
    "stargazers = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "dependency_slugs = set()\n",
    "\n",
    "combined_results = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "# Process successes\n",
    "for agent, categories in successes.items():\n",
    "    for category, commits in categories.items():\n",
    "        for commit in commits:\n",
    "            combined_results[agent][category]['Successes'].append(commit)\n",
    "\n",
    "# Process non_successes\n",
    "for agent, categories in non_successes.items():\n",
    "    for category, commits in categories.items():\n",
    "        for commit in commits:\n",
    "            combined_results[agent][category]['Failures'].append(commit)\n",
    "\n",
    "# Process each commit in successes\n",
    "for agent, categories in combined_results.items():\n",
    "    for category, commit_types in categories.items():\n",
    "        dependency_slugs_for_category = set()\n",
    "        \n",
    "        for commit_type, commits in commit_types.items():\n",
    "            for commit in commits:\n",
    "                # Load JSON data for the commit\n",
    "                json_data = load_json_data(commit)\n",
    "                \n",
    "                # Get the GitHub repo slug\n",
    "                github_repo_slug = json_data['updatedDependency']['githubRepoSlug']\n",
    "                dependency_slugs.add(github_repo_slug)\n",
    "                dependency_slugs_for_category.add(github_repo_slug)\n",
    "                \n",
    "                # Get the stargazers count\n",
    "                stargazers_count = get_stargazers_count(github_repo_slug)\n",
    "                \n",
    "                # Store the stargazers count in the correct structure\n",
    "                stargazers[agent][category][\"stargazers\"][commit] = stargazers_count\n",
    "        \n",
    "        # Store metadata for unique projects per category\n",
    "        stargazers[agent][category][\"meta\"][\"Unique Projects\"] = len(dependency_slugs_for_category)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "# Print the updated successes structure with stargazers count\n",
    "print(json.dumps(stargazers, indent=4))\n",
    "print(\"Total unique dependency slugs:\", len(dependency_slugs))\n",
    "\n",
    "with open(\"stargazers.json\", \"w\") as f:\n",
    "    json.dump(stargazers, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import json\n",
    "\n",
    "agent_hashes = []\n",
    "data_path = Path(os.path.abspath(\"\")) / \"..\" /\"dataset\"\n",
    "for file in data_path.glob(\"*\"):\n",
    "    if file.is_dir():\n",
    "        agent_hashes.append(file.parts[-1])\n",
    "\n",
    "\n",
    "\n",
    "with open('dspy_hashes.json', 'r') as file:\n",
    "    dspy_hashes = json.load(file)\n",
    "\n",
    "# Sort the hashes\n",
    "agent_hashes = sorted(agent_hashes)\n",
    "dspy_hashes = sorted(dspy_hashes)\n",
    "\n",
    "\n",
    "# Create the Venn Diagram and adjust the 'Dspy Hashes' label with only a slight vertical offset\n",
    "plt.figure(figsize=(3.5, 3.5))\n",
    "venn = venn2([set(agent_hashes), set(dspy_hashes)], set_labels=None, set_colors=('#607D8B', '#CFD8DC'))\n",
    "\n",
    "# Set custom colors for the Venn diagram\n",
    "venn_colors = ['#8BC34A', '#03A9F4']  # Green and blue colors\n",
    "venn2_circles([set(agent_hashes), set(dspy_hashes)], linestyle='solid', linewidth=1, color='black')\n",
    "# for patch, color in zip(venn.patches, venn_colors):\n",
    "#     if patch:\n",
    "#         patch.set_color(color)\n",
    "#         # patch.set_edgecolor('black')\n",
    "#         # patch.set_alpha(0.6)\n",
    "\n",
    "\n",
    "\n",
    "original_agent_label = venn.get_label_by_id('10').get_text()\n",
    "\n",
    "venn.get_label_by_id('10').set_text(f'{original_agent_label}\\nFull\\nSlice')\n",
    "venn.get_label_by_id('10').set_fontsize(20)\n",
    "\n",
    "original_dspy_label = venn.get_label_by_id('11').get_text()\n",
    "venn.get_label_by_id('11').set_text(f'{original_dspy_label}\\nLight\\nSlice')\n",
    "venn.get_label_by_id('11').set_fontsize(20)\n",
    "\n",
    "\n",
    "venn.get_label_by_id('01').set_fontsize(20)\n",
    "\n",
    "\n",
    "# Apply tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('venn_dataset.pdf', bbox_inches='tight', pad_inches=0)\n",
    "# plt.show()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# # Load the JSON data\n",
    "# with open('path_to_your_file/stargazers.json', 'r') as file:\n",
    "#     stargazers = json.load(file)\n",
    "\n",
    "# Helper function to extract stargazers data\n",
    "def extract_stargazers(agent_data):\n",
    "    categories = ['Compilation', 'Test', 'Failures']\n",
    "    stargazers_data = {category: [] for category in categories}\n",
    "    \n",
    "    for category in categories:\n",
    "        if category in agent_data:\n",
    "            stargazers_data[category] = list(agent_data[category]['stargazers'].values())\n",
    "    \n",
    "    return stargazers_data\n",
    "\n",
    "# Prepare data for each agent\n",
    "agent_data = {}\n",
    "if len(agent_data) == 0:\n",
    "    for agent in stargazers:\n",
    "        agent_data[agent] = extract_stargazers(stargazers[agent])\n",
    "\n",
    "# Redefine the success variable with more granularity\n",
    "commit_data = []\n",
    "\n",
    "for agent, stargazers_data in agent_data.items():\n",
    "    for category, stargazers in stargazers_data.items():\n",
    "        for value in stargazers:\n",
    "            if category == 'Compilation':\n",
    "                commit_data.append({'agent': agent, 'category': category, 'stargazers': value, 'success': 1})\n",
    "            elif category == 'Test':\n",
    "                commit_data.append({'agent': agent, 'category': category, 'stargazers': value, 'success': 2})\n",
    "            else:\n",
    "                commit_data.append({'agent': agent, 'category': category, 'stargazers': value, 'success': 0})\n",
    "\n",
    "df = pd.DataFrame(commit_data)\n",
    "\n",
    "# Scatter Plot: Stargazers vs Success with new success values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='stargazers', y='success', hue='category', data=df)\n",
    "plt.title('Scatter Plot of Stargazers vs Success Levels')\n",
    "plt.xlabel('Stargazers')\n",
    "plt.ylabel('Success Level (0=Failed, 1=Compilation Success, 2=Test Success)')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot: Stargazers Distribution for different success levels\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='success', y='stargazers', data=df)\n",
    "plt.title('Box Plot of Stargazers Distribution by Success Level')\n",
    "plt.xlabel('Success Level (0=Failed, 1=Compilation Success, 2=Test Success)')\n",
    "plt.ylabel('Stargazers')\n",
    "plt.show()\n",
    "\n",
    "# Summary Table: Average, Median, and Standard Deviation with new success levels\n",
    "summary_table = df.groupby('success')['stargazers'].agg(['mean', 'median', 'std', 'count']).reset_index()\n",
    "summary_table.columns = ['Success Level (0=Failed, 1=Compilation Success, 2=Test Success)', 'Mean Stargazers', 'Median Stargazers', 'Std Dev of Stargazers', 'Count of Commits']\n",
    "\n",
    "# Correlation Analysis: Pearson Correlation with new success levels\n",
    "\n",
    "print(df['stargazers'], df['success'])\n",
    "correlation_split, p_value_split = pearsonr(df['stargazers'], df['success'])\n",
    "\n",
    "\n",
    "# Correlation Analysis: Pearson Correlation with combined success (binary: 0=Failed, 1=Any Success)\n",
    "df_combined = df.copy()\n",
    "df_combined['success_combined'] = df_combined['success'].apply(lambda x: 1 if x > 0 else 0)\n",
    "correlation_combined, p_value_combined = pearsonr(df_combined['stargazers'], df_combined['success_combined'])\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Summary Table of Stargazers by New Success Levels\")\n",
    "print(summary_table)\n",
    "print(f\"\\nPearson Correlation Coefficient (Split Success): {correlation_split:.4f}\")\n",
    "print(f\"P-value (Split Success): {p_value_split:.4f}\")\n",
    "print(f\"\\nPearson Correlation Coefficient (Combined Success): {correlation_combined:.4f}\")\n",
    "print(f\"P-value (Combined Success): {p_value_combined:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('-'*20, \"LaTeX\", '-'*20)\n",
    "print(f\"To quantify the linear relationship between the popularity of stargazers and these success levels, we calculated the Pearson correlation coefficient, yielding \\( r = {correlation_split:.4f} \\) with a p-value of \\( p = {p_value_split:.4f} \\).\")\n",
    "print(f\"Reanalyzing the correlation under this binary framework resulted in a Pearson correlation coefficient of \\( r = {correlation_combined:.4f} \\) with a p-value of \\( p = {p_value_combined:.4f} \\).\")\n",
    "\n",
    "# Optionally, you can save the summary table to a CSV file\n",
    "# summary_table.to_csv('summary_table.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
