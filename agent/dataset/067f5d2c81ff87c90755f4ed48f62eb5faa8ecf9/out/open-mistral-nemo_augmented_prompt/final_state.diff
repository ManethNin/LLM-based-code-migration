diff --git a/singer-commons/src/main/java/com/pinterest/singer/loggingaudit/client/AuditEventKafkaSender.java b/singer-commons/src/main/java/com/pinterest/singer/loggingaudit/client/AuditEventKafkaSender.java
index 58dabd4..acbc5c1 100644
--- a/singer-commons/src/main/java/com/pinterest/singer/loggingaudit/client/AuditEventKafkaSender.java
+++ b/singer-commons/src/main/java/com/pinterest/singer/loggingaudit/client/AuditEventKafkaSender.java
@@ -229,9 +229,9 @@ public class AuditEventKafkaSender implements LoggingAuditEventSender {
           LOG.warn("Change current partition of audit event topic from {} to {}", currentPartitionId,
               randomPartition);
           currentPartitionId = randomPartition;
-          OpenTsdbMetricConverter.incr(
+        OpenTsdbMetricConverter.incr(
               LoggingAuditClientMetrics.AUDIT_CLIENT_SENDER_KAFKA_CURRENT_PARTITION_RESET, 1,
-              "host=" + host, "stage=" + stage.toString());
+                "host=" + host, "stage=" + stage.toString());
           return;
         }
       }
@@ -281,7 +281,7 @@ public class AuditEventKafkaSender implements LoggingAuditEventSender {
         }
       } catch (InterruptedException e) {
         LOG.warn("[{}] got interrupted when polling the queue and while loop is ended!",
-            Thread.currentThread().getName(), e);
+                Thread.currentThread().getName(), e);
         OpenTsdbMetricConverter.incr(
             LoggingAuditClientMetrics.AUDIT_CLIENT_SENDER_DEQUEUE_INTERRUPTED_EXCEPTION, 1,
                 "host=" + host, "stage=" + stage.toString());
@@ -289,7 +289,7 @@ public class AuditEventKafkaSender implements LoggingAuditEventSender {
       } catch (Exception e) {
         LOG.warn("Exit the while loop and finish the thread execution due to exception: ", e);
         OpenTsdbMetricConverter.incr(LoggingAuditClientMetrics.AUDIT_CLIENT_SENDER_EXCEPTION, 1,
-            "host=" + host, "stage=" + stage.toString());
+                "host=" + host, "stage=" + stage.toString());
         break;
       }
     }
@@ -309,7 +309,7 @@ public class AuditEventKafkaSender implements LoggingAuditEventSender {
     public void checkAndEnqueueWhenSendFailed() {
       // if exception thrown (i.e. the send failed), the partition is added to badPartitions.
       badPartitions.add(this.partition);
-      OpenTsdbMetricConverter
+            OpenTsdbMetricConverter
           .incr(LoggingAuditClientMetrics.AUDIT_CLIENT_SENDER_KAFKA_PARTITION_ERROR, 1,
               "host=" + host, "stage=" + stage.toString(), "topic=" + topic,
               "partition=" + this.partition);
@@ -321,20 +321,20 @@ public class AuditEventKafkaSender implements LoggingAuditEventSender {
       if (count == null){
         eventTriedCount.put(event.getLoggingAuditHeaders(), 1);
         insertEvent(event);
-        OpenTsdbMetricConverter
+            OpenTsdbMetricConverter
             .gauge(LoggingAuditClientMetrics.AUDIT_CLIENT_SENDER_KAFKA_EVENTS_RETRIED,
                 eventTriedCount.size(), "host=" + host, "stage=" + stage.toString(),
                 "topic=" + topic);
       } else if (count >= NUM_OF_PARTITIONS_TO_TRY_SENDING) {
           LOG.debug("Failed to send audit event after trying {} partitions. Drop event.", count);
-          OpenTsdbMetricConverter
+            OpenTsdbMetricConverter
               .incr(LoggingAuditClientMetrics.AUDIT_CLIENT_SENDER_KAFKA_EVENTS_DROPPED, 1,
-                  "host=" + host, "stage=" + stage.toString(),
-                  "logName=" + event.getLoggingAuditHeaders().getLogName());
-          eventTriedCount.remove(event.getLoggingAuditHeaders());
+                    "host=" + host, "stage=" + stage.toString(),
+                    "logName=" + event.getLoggingAuditHeaders().getLogName());
+            eventTriedCount.remove(event.getLoggingAuditHeaders());
       } else {
           eventTriedCount.put(event.getLoggingAuditHeaders(), count + 1);
-          insertEvent(event);
+        insertEvent(event);
       }
     }
 
@@ -344,13 +344,13 @@ public class AuditEventKafkaSender implements LoggingAuditEventSender {
         if (!success) {
           LOG.debug("Failed to enqueue LoggingAuditEvent at head of the queue when executing "
               + "producer send callback. Drop this event.");
-          eventTriedCount.remove(event.getLoggingAuditHeaders());
+            eventTriedCount.remove(event.getLoggingAuditHeaders());
         }
       } catch (InterruptedException ex) {
         LOG.debug(
             "Enqueuing LoggingAuditEvent at head of the queue was interrupted in callback. "
                 + "Drop this event");
-        eventTriedCount.remove(event.getLoggingAuditHeaders());
+            eventTriedCount.remove(event.getLoggingAuditHeaders());
       }
     }
 
@@ -358,14 +358,14 @@ public class AuditEventKafkaSender implements LoggingAuditEventSender {
     public void onCompletion(RecordMetadata recordMetadata, Exception e) {
       try {
         if (e == null) {
-          OpenTsdbMetricConverter
+            OpenTsdbMetricConverter
               .incr(LoggingAuditClientMetrics.AUDIT_CLIENT_SENDER_KAFKA_EVENTS_ACKED, 1,
-                  "host=" + host, "stage=" + stage.toString(),
-                  "logName=" + event.getLoggingAuditHeaders().getLogName());
+                    "host=" + host, "stage=" + stage.toString(),
+                    "logName=" + event.getLoggingAuditHeaders().getLogName());
 
           // if send is successful, remove the event from the map eventTriedCount if it was added
           // LoggingAuditHeaders can uniquely identify an event.
-          eventTriedCount.remove(event.getLoggingAuditHeaders());
+            eventTriedCount.remove(event.getLoggingAuditHeaders());
           // if send out successfully, remove the partition from the badPartitions if it was added.
           badPartitions.remove(recordMetadata.partition());
         } else {
@@ -373,7 +373,7 @@ public class AuditEventKafkaSender implements LoggingAuditEventSender {
         }
       } catch (Throwable t) {
         LOG.warn("Exception throws in the callback. Drop this event {}", event, t);
-        OpenTsdbMetricConverter
+            OpenTsdbMetricConverter
             .incr(LoggingAuditClientMetrics.AUDIT_CLIENT_SENDER_KAFKA_CALLBACK_EXCEPTION, 1,
                 "host=" + host, "stage=" + stage.toString(), "topic=" + topic);
       }
@@ -424,11 +424,22 @@ public class AuditEventKafkaSender implements LoggingAuditEventSender {
     }
     try {
       this.kafkaProducer.close();
-    } catch (Throwable t) {
+      } catch (Throwable t) {
       LOG.warn("Exception is thrown while stopping {}.", name, t);
     }
     LOG.warn("[{}] is stopped and the number of LoggingAuditEvents left in the queue is {}.", name,
         queue.size());
   }
 
+@Override
+@Override
+@Override
+@Override
+@Override
+public void send(AuditEvent event) throws KafkaException {
+try {
+producer.send(new ProducerRecord<>(topic, serializedEvent));
+} catch (ProducerRecordMetadataException e) {
+throw new KafkaException(e);
 }
+}
\ No newline at end of file