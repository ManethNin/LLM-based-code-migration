{
    "validate_diffs": [],
    "compile_maven": [
        {
            "input": "```diff\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java\n@@ -20,7 +20,7 @@\n import com.hazelcast.core.HazelcastInstance;\n import com.hazelcast.core.IMap;\n import com.hazelcast.core.Member;\n-import com.hazelcast.config.MaxSizeConfig;\n+import com.hazelcast.config.MaxSizePolicy;\n import com.hazelcast.core.Cluster;\n \n // Other imports...\n@@ -149,7 +149,7 @@\n     public void someMethod() {\n         Cluster cluster = hazelcastInstance.getCluster();\n         for (Member member : cluster.getMembers()) {\n-            // Some logic...\n+            // Some logic...\n         }\n     }\n }\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java\n@@ -17,7 +17,7 @@\n import com.hazelcast.core.Cluster;\n import com.hazelcast.core.Member;\n import com.hazelcast.core.MemberAttributeEvent;\n-import com.hazelcast.core.MembershipEvent;\n+import com.hazelcast.cluster.MembershipEvent;\n import com.hazelcast.core.MembershipListener;\n \n // Other imports...\n@@ -60,7 +60,7 @@\n     public void memberAdded(MembershipEvent membershipEvent) {\n         Member member = membershipEvent.getMember();\n         // Some logic...\n     }\n }\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java\n@@ -19,7 +19,7 @@\n import com.hazelcast.core.IMap;\n import com.hazelcast.core.MapEvent;\n import com.hazelcast.monitor.LocalMemoryStats;\n-import com.hazelcast.monitor.Monitor;\n+import com.hazelcast.monitor.LocalMapStats;\n \n // Other imports...\n@@ -58,7 +58,7 @@\n     public void someMethod() {\n         IMap<K, V> map = hazelcastInstance.getMap(\"someMap\");\n         // Some logic...\n     }\n }\n--- src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java\n@@ -23,7 +23,7 @@\n import com.hazelcast.core.Member;\n \n // Other imports...\n \n public class HazelcastClusterNodeInfo {\n-    private Member member;\n+    private com.hazelcast.cluster.Member member;\n \n     // Other methods...\n }\n```",
            "output": {
                "compilation_has_succeeded": false,
                "test_has_succeeded": false,
                "error_text": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoMatch: hunk failed to apply!\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java!\nMake extra sure the indentation is correct.\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain these 6 exact lines in a row:\n```\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.monitor.LocalMemoryStats;\nimport com.hazelcast.monitor.Monitor;\n// Other imports...\n```\nUnifiedDiffNoMatch: hunk failed to apply!\nsrc/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java!\nMake extra sure the indentation is correct.\nsrc/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java does not contain these 9 exact lines in a row:\n```\nimport com.hazelcast.core.Member;\n// Other imports...\npublic class HazelcastClusterNodeInfo {\nprivate Member member;\n// Other methods...\n}\n```",
                "updated_files": {},
                "compile_error_details": {}
            },
            "error": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoMatch: hunk failed to apply!\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java!\nMake extra sure the indentation is correct.\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain these 6 exact lines in a row:\n```\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.monitor.LocalMemoryStats;\nimport com.hazelcast.monitor.Monitor;\n// Other imports...\n```\nUnifiedDiffNoMatch: hunk failed to apply!\nsrc/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java!\nMake extra sure the indentation is correct.\nsrc/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java does not contain these 9 exact lines in a row:\n```\nimport com.hazelcast.core.Member;\n// Other imports...\npublic class HazelcastClusterNodeInfo {\nprivate Member member;\n// Other methods...\n}\n```",
            "span_id": 4722236467718499032
        },
        {
            "input": "```diff\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java\n@@ -20,7 +20,7 @@\n import com.hazelcast.core.HazelcastInstance;\n import com.hazelcast.core.IMap;\n import com.hazelcast.core.Member;\n-import com.hazelcast.config.MaxSizeConfig;\n+import com.hazelcast.config.MaxSizePolicy;\n import com.hazelcast.core.Cluster;\n \n // Other imports...\n@@ -149,7 +149,7 @@\n     public void someMethod() {\n         Cluster cluster = hazelcastInstance.getCluster();\n         for (Member member : cluster.getMembers()) {\n-            // Some logic...\n+            // Some logic...\n         }\n     }\n }\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java\n@@ -17,7 +17,7 @@\n import com.hazelcast.core.Cluster;\n import com.hazelcast.core.Member;\n import com.hazelcast.core.MemberAttributeEvent;\n-import com.hazelcast.core.MembershipEvent;\n+import com.hazelcast.cluster.MembershipEvent;\n import com.hazelcast.core.MembershipListener;\n \n // Other imports...\n@@ -60,7 +60,7 @@\n     public void memberAdded(MembershipEvent membershipEvent) {\n         Member member = membershipEvent.getMember();\n         // Some logic...\n     }\n }\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java\n@@ -19,7 +19,7 @@\n import com.hazelcast.core.IMap;\n import com.hazelcast.core.MapEvent;\n import com.hazelcast.monitor.LocalMemoryStats;\n-import com.hazelcast.monitor.Monitor;\n+import com.hazelcast.monitor.LocalMapStats;\n \n // Other imports...\n@@ -41,20 +41,20 @@\n import java.util.Set;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.TimeUnit;\n \n /**\n  * Clustered implementation of the Cache interface using Hazelcast.\n  *\n  */\n public class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n \n     private final Logger logger;\n \n     private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n \n     /**\n      * The map is used for distributed operations such as get, put, etc.\n      */\n     final IMap<K, V> map;\n     private String name;\n     private long numberOfGets = 0;\n \n     /**\n      * Used to limit the amount of duplicate warnings logged.\n      */\n     private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n     private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n \n     /**\n      * Create a new cache using the supplied named cache as the actual cache implementation\n      *\n      * @param name a name for the cache, which should be unique per vm.\n      * @param cache the cache implementation\n      */\n     protected ClusteredCache(final String name, final IMap<K, V> cache) {\n         this.map = cache;\n         this.name = name;\n         logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n     }\n \n     void addEntryListener(final MapListener listener) {\n         listeners.add(map.addEntryListener(listener, false));\n     }\n \n     @Override\n     public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n     {\n         final EntryListener<K, V> listener = new EntryListener<K, V>() {\n             @Override\n             public void mapEvicted(MapEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                     clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                 }\n             }\n \n             @Override\n             public void mapCleared(MapEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                     clusteredCacheEntryListener.mapCleared(eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryUpdated(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryRemoved(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryEvicted(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryAdded(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                 }\n             }\n         };\n \n         final String listenerId = map.addEntryListener(listener, includeValues);\n         listeners.add(listenerId);\n         logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n         return listenerId;\n     }\n \n     @Override\n     public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n         logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n         map.removeEntryListener(listenerId);\n         listeners.remove(listenerId);\n     }\n \n     @Override\n     public String getName() {\n         return name;\n     }\n \n     @Override\n     public void setName(final String name) {\n         this.name = name;\n     }\n \n     @Override\n     public V put(final K key, final V object) {\n         if (object == null) { return null; }\n         checkForPluginClassLoader(key);\n         checkForPluginClassLoader(object);\n         return map.put(key, object);\n     }\n \n     @Override\n     public V get(final Object key) {\n         numberOfGets++;\n         return map.get(key);\n     }\n \n     @Override\n     public V remove(final Object key) {\n         return map.remove(key);\n     }\n \n     @Override\n     public void clear() {\n         map.clear();\n     }\n \n     @Override\n     public int size() {\n         final LocalMapStats stats = map.getLocalMapStats();\n         return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n     }\n \n     @Override\n     public boolean containsKey(final Object key) {\n         return map.containsKey(key);\n     }\n \n     @Override\n     public boolean containsValue(final Object value) {\n         return map.containsValue(value);\n     }\n \n     @Override\n     public Set<Map.Entry<K, V>> entrySet() {\n         return map.entrySet();\n     }\n \n     @Override\n     public boolean isEmpty() {\n         return map.isEmpty();\n     }\n \n     @Override\n     public Set<K> keySet() {\n         return map.keySet();\n     }\n \n     @Override\n     public void putAll(final Map<? extends K, ? extends V> entries) {\n         map.putAll(entries);\n \n         // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n         entries.entrySet().stream().findAny().ifPresent(\n             e -> {\n                 checkForPluginClassLoader(e.getKey());\n                 checkForPluginClassLoader(e.getValue());\n             }\n         );\n     }\n \n     @Override\n     public Collection<V> values() {\n         return map.values();\n     }\n \n     @Override\n     public long getCacheHits() {\n         return map.getLocalMapStats().getHits();\n     }\n \n     @Override\n     public long getCacheMisses() {\n         final long hits = map.getLocalMapStats().getHits();\n         return numberOfGets > hits ? numberOfGets - hits : 0;\n     }\n \n     @Override\n     public int getCacheSize() {\n         return (int) getLongCacheSize();\n     }\n \n     @Override\n     public long getLongCacheSize() {\n         final LocalMapStats stats = map.getLocalMapStats();\n         return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n     }\n \n     @Override\n     public long getMaxCacheSize() {\n         return CacheFactory.getMaxCacheSize(getName());\n     }\n \n     @Override\n     public void setMaxCacheSize(int i) {\n         setMaxCacheSize((long) i);\n     }\n \n     @Override\n     public void setMaxCacheSize(final long maxSize) {\n         CacheFactory.setMaxSizeProperty(getName(), maxSize);\n     }\n \n     @Override\n     public long getMaxLifetime() {\n         return CacheFactory.getMaxCacheLifetime(getName());\n     }\n \n     @Override\n     public void setMaxLifetime(final long maxLifetime) {\n         CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n     }\n \n     void destroy() {\n         listeners.forEach(map::removeEntryListener);\n         map.destroy();\n     }\n \n     boolean lock(final K key, final long timeout) {\n         boolean result = true;\n         if (timeout < 0) {\n             map.lock(key);\n         } else if (timeout == 0) {\n             result = map.tryLock(key);\n         } else {\n             try {\n                 result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n             } catch (final InterruptedException e) {\n                 logger.error(\"Failed to get cluster lock\", e);\n                 result = false;\n             }\n         }\n         return result;\n     }\n \n     void unlock(final K key) {\n         try {\n             map.unlock(key);\n         } catch (final IllegalMonitorStateException e) {\n             logger.error(\"Failed to release cluster lock\", e);\n         }\n     }\n \n     /**\n      * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n      * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n      * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n      * limited by a time interval.\n      *\n      * @param o the instance for which to verify the class loader\n      * @see <a href=\\\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\\\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n      */\n     protected void checkForPluginClassLoader(final Object o) {\n         if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n             && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n         {\n             // Try to determine what plugin loaded the offending class.\n             String pluginName = null;\n             try {\n                 final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                 for (final Plugin plugin : plugins) {\n                     final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                     if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                         pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                         break;\n                     }\n                 }\n             } catch (Exception e) {\n                 logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n             }\n             logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                 \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                 o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n             lastPluginClassLoaderWarning = Instant.now();\n         }\n     }\n }\n--- src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java\n@@ -21,7 +21,7 @@\n import org.jivesoftware.openfire.cluster.NodeID;\n import org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n \n import com.hazelcast.core.Member;\n \n /**\n  * Cluster Node information as provided by Hazelcast.\n  *\n  * @author Tom Evans\n  * @author Gaston Dombiak\n  */\n public class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n \n     public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n     public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n     private final String hostname;\n     private final NodeID nodeID;\n     private final long joinedTime;\n     private final boolean seniorMember;\n \n     public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n         this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n         this.nodeID = ClusteredCacheFactory.getNodeID(member);\n         this.joinedTime = joinedTime;\n         this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n     }\n \n     public String getHostName() {\n         return hostname;\n     }\n \n     public NodeID getNodeID() {\n         return nodeID;\n     }\n \n     public long getJoinedTime() {\n         return joinedTime;\n     }\n \n     public boolean isSeniorMember() {\n         return seniorMember;\n     }\n }\n```",
            "output": {
                "compilation_has_succeeded": false,
                "test_has_succeeded": false,
                "error_text": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoMatch: hunk failed to apply!\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java!\nMake extra sure the indentation is correct.\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain these 6 exact lines in a row:\n```\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.monitor.LocalMemoryStats;\nimport com.hazelcast.monitor.Monitor;\n// Other imports...\n```",
                "updated_files": {},
                "compile_error_details": {}
            },
            "error": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoMatch: hunk failed to apply!\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java!\nMake extra sure the indentation is correct.\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain these 6 exact lines in a row:\n```\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.monitor.LocalMemoryStats;\nimport com.hazelcast.monitor.Monitor;\n// Other imports...\n```",
            "span_id": 15714623286820000107
        },
        {
            "input": "```diff\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java\n@@ -81,60 +81,60 @@\n         listeners.add(map.addEntryListener(listener, false));\n     }\n \n     @Override\n     public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n     {\n         final EntryListener<K, V> listener = new EntryListener<K, V>() {\n             @Override\n             public void mapEvicted(MapEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                     clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                 }\n             }\n \n             @Override\n             public void mapCleared(MapEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                     clusteredCacheEntryListener.mapCleared(eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryUpdated(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryRemoved(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryEvicted(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryAdded(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                 }\n             }\n         };\n \n         final String listenerId = map.addEntryListener(listener, includeValues);\n         listeners.add(listenerId);\n         logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n         return listenerId;\n     }\n```",
            "output": {
                "compilation_has_succeeded": false,
                "test_has_succeeded": false,
                "error_text": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoEdits: no applicable hunks found!\nThe provided diff does not contain any hunks that can be applied to the files in the repository.\nEnsure that your diff correctly specifies the changes and try again.\nThe diff needs to apply to the existing lines in the files.",
                "updated_files": {},
                "compile_error_details": {}
            },
            "error": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoEdits: no applicable hunks found!\nThe provided diff does not contain any hunks that can be applied to the files in the repository.\nEnsure that your diff correctly specifies the changes and try again.\nThe diff needs to apply to the existing lines in the files.",
            "span_id": 1062855547426416534
        },
        {
            "input": "```diff\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java\n@@ -19,7 +19,7 @@\n import com.hazelcast.core.IMap;\n import com.hazelcast.core.MapEvent;\n import com.hazelcast.monitor.LocalMemoryStats;\n-import com.hazelcast.monitor.Monitor;\n+import com.hazelcast.monitor.LocalMapStats;\n \n // Other imports...\n@@ -41,7 +41,7 @@\n import java.util.Set;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.TimeUnit;\n \n /**\n  * Clustered implementation of the Cache interface using Hazelcast.\n  *\n  */\n public class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n \n     private final Logger logger;\n \n     private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n \n     /**\n      * The map is used for distributed operations such as get, put, etc.\n      */\n     final IMap<K, V> map;\n     private String name;\n     private long numberOfGets = 0;\n \n     /**\n      * Used to limit the amount of duplicate warnings logged.\n      */\n     private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n     private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n \n     /**\n      * Create a new cache using the supplied named cache as the actual cache implementation\n      *\n      * @param name a name for the cache, which should be unique per vm.\n      * @param cache the cache implementation\n      */\n     protected ClusteredCache(final String name, final IMap<K, V> cache) {\n         this.map = cache;\n         this.name = name;\n         logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n     }\n \n     void addEntryListener(final MapListener listener) {\n         listeners.add(map.addEntryListener(listener, false));\n     }\n \n     @Override\n     public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n     {\n         final EntryListener<K, V> listener = new EntryListener<K, V>() {\n             @Override\n             public void mapEvicted(MapEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                     clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                 }\n             }\n \n             @Override\n             public void mapCleared(MapEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                     clusteredCacheEntryListener.mapCleared(eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryUpdated(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryRemoved(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryEvicted(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                 }\n             }\n \n             @Override\n             public void entryAdded(EntryEvent event) {\n                 if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                     final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                     logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                     clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                 }\n             }\n         };\n \n         final String listenerId = map.addEntryListener(listener, includeValues);\n         listeners.add(listenerId);\n         logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n         return listenerId;\n     }\n \n     @Override\n     public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n         logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n         map.removeEntryListener(listenerId);\n         listeners.remove(listenerId);\n     }\n \n     @Override\n     public String getName() {\n         return name;\n     }\n \n     @Override\n     public void setName(final String name) {\n         this.name = name;\n     }\n \n     @Override\n     public V put(final K key, final V object) {\n         if (object == null) { return null; }\n         checkForPluginClassLoader(key);\n         checkForPluginClassLoader(object);\n         return map.put(key, object);\n     }\n \n     @Override\n     public V get(final Object key) {\n         numberOfGets++;\n         return map.get(key);\n     }\n \n     @Override\n     public V remove(final Object key) {\n         return map.remove(key);\n     }\n \n     @Override\n     public void clear() {\n         map.clear();\n     }\n \n     @Override\n     public int size() {\n         final LocalMapStats stats = map.getLocalMapStats();\n         return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n     }\n \n     @Override\n     public boolean containsKey(final Object key) {\n         return map.containsKey(key);\n     }\n \n     @Override\n     public boolean containsValue(final Object value) {\n         return map.containsValue(value);\n     }\n \n     @Override\n     public Set<Map.Entry<K, V>> entrySet() {\n         return map.entrySet();\n     }\n \n     @Override\n     public boolean isEmpty() {\n         return map.isEmpty();\n     }\n \n     @Override\n     public Set<K> keySet() {\n         return map.keySet();\n     }\n \n     @Override\n     public void putAll(final Map<? extends K, ? extends V> entries) {\n         map.putAll(entries);\n \n         // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n         entries.entrySet().stream().findAny().ifPresent(\n             e -> {\n                 checkForPluginClassLoader(e.getKey());\n                 checkForPluginClassLoader(e.getValue());\n             }\n         );\n     }\n \n     @Override\n     public Collection<V> values() {\n         return map.values();\n     }\n \n     @Override\n     public long getCacheHits() {\n         return map.getLocalMapStats().getHits();\n     }\n \n     @Override\n     public long getCacheMisses() {\n         final long hits = map.getLocalMapStats().getHits();\n         return numberOfGets > hits ? numberOfGets - hits : 0;\n     }\n \n     @Override\n     public int getCacheSize() {\n         return (int) getLongCacheSize();\n     }\n \n     @Override\n     public long getLongCacheSize() {\n         final LocalMapStats stats = map.getLocalMapStats();\n         return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n     }\n \n     @Override\n     public long getMaxCacheSize() {\n         return CacheFactory.getMaxCacheSize(getName());\n     }\n \n     @Override\n     public void setMaxCacheSize(int i) {\n         setMaxCacheSize((long) i);\n     }\n \n     @Override\n     public void setMaxCacheSize(final long maxSize) {\n         CacheFactory.setMaxSizeProperty(getName(), maxSize);\n     }\n \n     @Override\n     public long getMaxLifetime() {\n         return CacheFactory.getMaxCacheLifetime(getName());\n     }\n \n     @Override\n     public void setMaxLifetime(final long maxLifetime) {\n         CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n     }\n \n     void destroy() {\n         listeners.forEach(map::removeEntryListener);\n         map.destroy();\n     }\n \n     boolean lock(final K key, final long timeout) {\n         boolean result = true;\n         if (timeout < 0) {\n             map.lock(key);\n         } else if (timeout == 0) {\n             result = map.tryLock(key);\n         } else {\n             try {\n                 result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n             } catch (final InterruptedException e) {\n                 logger.error(\"Failed to get cluster lock\", e);\n                 result = false;\n             }\n         }\n         return result;\n     }\n \n     void unlock(final K key) {\n         try {\n             map.unlock(key);\n         } catch (final IllegalMonitorStateException e) {\n             logger.error(\"Failed to release cluster lock\", e);\n         }\n     }\n \n     /**\n      * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n      * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n      * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n      * limited by a time interval.\n      *\n      * @param o the instance for which to verify the class loader\n      * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n      */\n     protected void checkForPluginClassLoader(final Object o) {\n         if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n             && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n         {\n             // Try to determine what plugin loaded the offending class.\n             String pluginName = null;\n             try {\n                 final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                 for (final Plugin plugin : plugins) {\n                     final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                     if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                         pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                         break;\n                     }\n                 }\n             } catch (Exception e) {\n                 logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n             }\n             logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                 \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                 o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n             lastPluginClassLoaderWarning = Instant.now();\n         }\n     }\n }\n--- src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java\n@@ -21,7 +21,7 @@\n import org.jivesoftware.openfire.cluster.NodeID;\n import org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n \n import com.hazelcast.core.Member;\n \n /**\n  * Cluster Node information as provided by Hazelcast.\n  *\n  * @author Tom Evans\n  * @author Gaston Dombiak\n  */\n public class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n \n     public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n     public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n     private final String hostname;\n     private final NodeID nodeID;\n     private final long joinedTime;\n     private final boolean seniorMember;\n \n     public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n         this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n         this.nodeID = ClusteredCacheFactory.getNodeID(member);\n         this.joinedTime = joinedTime;\n         this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n     }\n \n     public String getHostName() {\n         return hostname;\n     }\n \n     public NodeID getNodeID() {\n         return nodeID;\n     }\n \n     public long getJoinedTime() {\n         return joinedTime;\n     }\n \n     public boolean isSeniorMember() {\n         return seniorMember;\n     }\n }\n```",
            "output": {
                "compilation_has_succeeded": false,
                "test_has_succeeded": false,
                "error_text": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoMatch: hunk failed to apply!\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java!\nMake extra sure the indentation is correct.\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain these 6 exact lines in a row:\n```\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.monitor.LocalMemoryStats;\nimport com.hazelcast.monitor.Monitor;\n// Other imports...\n```",
                "updated_files": {},
                "compile_error_details": {}
            },
            "error": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoMatch: hunk failed to apply!\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java!\nMake extra sure the indentation is correct.\nsrc/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java does not contain these 6 exact lines in a row:\n```\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.monitor.LocalMemoryStats;\nimport com.hazelcast.monitor.Monitor;\n// Other imports...\n```",
            "span_id": 2921837839107603572
        }
    ],
    "read_file": [
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 3345410936160148681
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 12922565059428266840
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 10811123380128362571
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 3824614336499964836
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 5407079342254110130
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 6253377417054005552
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 5413484327331761917
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 15039583337452117509
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 16835350558880996783
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 6260698170186171528
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 2482216734011214115
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 18425320108047645853
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 5891278899831407654
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 5641813771364124962
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 14684117801046230579
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 9576914895963677612
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 4521191431027166469
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 9467922840557524495
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.IMap;\nimport com.hazelcast.core.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.monitor.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n",
            "error": "",
            "span_id": 13959315547587834836
        },
        {
            "input": "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java",
            "output": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cluster;\n\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory;\n\nimport com.hazelcast.core.Member;\n\n/**\n * Cluster Node information as provided by Hazelcast.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class HazelcastClusterNodeInfo implements ClusterNodeInfo {\n\n    public static final String HOST_NAME_ATTRIBUTE = \"hostname\";\n    public static final String NODE_ID_ATTRIBUTE = \"node-id\";\n    private final String hostname;\n    private final NodeID nodeID;\n    private final long joinedTime;\n    private final boolean seniorMember;\n\n    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {\n        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";\n        this.nodeID = ClusteredCacheFactory.getNodeID(member);\n        this.joinedTime = joinedTime;\n        this.seniorMember = ClusterManager.getSeniorClusterMember().equals(nodeID);\n    }\n\n    public String getHostName() {\n        return hostname;\n    }\n\n    public NodeID getNodeID() {\n        return nodeID;\n    }\n\n    public long getJoinedTime() {\n        return joinedTime;\n    }\n\n    public boolean isSeniorMember() {\n        return seniorMember;\n    }\n}\n",
            "error": "",
            "span_id": 11845924140877801161
        }
    ],
    "get_directory_tree": [],
    "get_language_server_suggestions": [],
    "reset_repo": []
}