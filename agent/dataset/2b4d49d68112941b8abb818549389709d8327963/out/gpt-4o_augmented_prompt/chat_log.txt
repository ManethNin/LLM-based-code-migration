================================ System Message ================================

Act as an expert Java software developer.
The program has issues after a version upgrade of a dependency.
Try using minimal changes to the code to fix the issues. 
Do not explain your actions or ask questions, just provide diffs that always adhere to the rules.
When you think you are done, reply with the diff that fixes the issues, after that a final verification step will happen and the conversation will be ended if it was successful. If not you get the error back.

# File editing rules:
Return edits similar to unified diffs that `diff -U0` would produce.
The diff has to be in a markdown code block, like this: ```diff ```.

Make sure you include the first 2 lines with the file paths.
Don't include timestamps with the file paths.

Start each hunk of changes with a `@@ ... @@` line.
Don't include line numbers like `diff -U0` does.
The user's patch tool doesn't need them.

The user's patch tool needs CORRECT patches that apply cleanly against the current contents of the file!
Think carefully and make sure you include and mark all lines that need to be removed or changed as `-` lines.
Make sure you mark all new or modified lines with `+`.
Don't leave out any lines or the diff patch won't apply correctly.
Dont add in new comments or change existing comments.
Make sure the diff is minimal and only includes the changes needed to fix the issue plus at least one context line so the tool can apply the diff correctly.

Indentation matters in the diffs!

Start a new hunk for each section of the file that needs changes.
Dont include unnescessary context, but include at least one line of it.
If no context is included, the tool will try to apply the changes at the end of the line.

Only output hunks that specify changes with `+` or `-` lines.
Skip any hunks that are entirely unchanging ` ` lines.

Output hunks in whatever order makes the most sense.
Hunks don't need to be in any particular order.

When editing a function, method, loop, etc use a hunk to replace the *entire* code block.
Delete the entire existing version with `-` lines and then add a new, updated version with `+` lines.
This will help you generate correct code and correct diffs.

To make a new file, show a diff from `--- /dev/null` to `+++ path/to/new/file.ext`.


================================ Human Message =================================


Updated Dependency Details: com.hazelcast:hazelcast 3.12.5 -> 4.0.5

Initial Error: [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.8.0:compile (default-compile) on project hazelcast: Compilation failure: Compilation failure:
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java:[22,28] cannot find symbol
[ERROR]   symbol:   class MaxSizeConfig
[ERROR]   location: package com.hazelcast.config
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java:[27,26] cannot find symbol
[ERROR]   symbol:   class Cluster
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java:[30,26] cannot find symbol
[ERROR]   symbol:   class Member
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java:[149,20] cannot find symbol
[ERROR]   symbol:   class Cluster
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[18,26] cannot find symbol
[ERROR]   symbol:   class Cluster
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[23,26] cannot find symbol
[ERROR]   symbol:   class Member
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[24,26] cannot find symbol
[ERROR]   symbol:   class MemberAttributeEvent
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[25,26] cannot find symbol
[ERROR]   symbol:   class MembershipEvent
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[26,26] cannot find symbol
[ERROR]   symbol:   class MembershipListener
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[52,41] cannot find symbol
[ERROR]   symbol: class MembershipListener
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java:[501,13] cannot find symbol
[ERROR]   symbol:   class Member
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java:[655,42] cannot find symbol
[ERROR]   symbol:   class Member
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[60,19] cannot find symbol
[ERROR]   symbol:   class Cluster
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusterListener
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[75,27] cannot find symbol
[ERROR]   symbol:   class Cluster
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusterListener
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[155,35] cannot find symbol
[ERROR]   symbol:   class MembershipEvent
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusterListener
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[228,37] cannot find symbol
[ERROR]   symbol:   class MembershipEvent
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusterListener
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java:[271,46] cannot find symbol
[ERROR]   symbol:   class MemberAttributeEvent
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusterListener
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[20,26] cannot find symbol
[ERROR]   symbol:   class IMap
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[21,26] cannot find symbol
[ERROR]   symbol:   class MapEvent
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[23,29] package com.hazelcast.monitor does not exist
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[58,11] cannot find symbol
[ERROR]   symbol:   class IMap
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCache<K,V>
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[74,55] cannot find symbol
[ERROR]   symbol:   class IMap
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCache<K,V>
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java:[24,26] cannot find symbol
[ERROR]   symbol:   class Member
[ERROR]   location: package com.hazelcast.core
[ERROR] src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java:[41,43] cannot find symbol
[ERROR]   symbol:   class Member
[ERROR]   location: class org.jivesoftware.openfire.plugin.util.cluster.HazelcastClusterNodeInfo
[ERROR] -> [Help 1]

Revapi/japicmp API Changes, which describe changes in the APIs used by this project: {"japicmpResult": {}, "elementLines": {}, "revapiResult": {}, "allPotentialBreakingElements": [], "elementPatterns": {}, "project": "openfire-hazelcast-plugin"}


================================== Ai Message ==================================
Tool Calls:
  get_directory_tree_for_path (call_j7FzoYs6g4H9Jx1L6m4kol1q)
 Call ID: call_j7FzoYs6g4H9Jx1L6m4kol1q
  Args:
    relative_directory_path: src/java/org/jivesoftware/openfire/plugin/util/cache

================================= Tool Message =================================
Name: get_directory_tree_for_path

[
    {
        "name": "ClusterClassLoader.java",
        "type": "file"
    },
    {
        "name": "ClusteredCache.java",
        "type": "file"
    },
    {
        "name": "ClusterExternalizableUtil.java",
        "type": "file"
    },
    {
        "name": "ClusterListener.java",
        "type": "file"
    },
    {
        "name": "ClusteredCacheFactory.java",
        "type": "file"
    }
]

================================== Ai Message ==================================
Tool Calls:
  read_file (call_TbBO5XjusPziXoQMIJ3x6HLG)
 Call ID: call_TbBO5XjusPziXoQMIJ3x6HLG
  Args:
    file_path: src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java
  read_file (call_K2q0vppOglzdx8du5lewTzR1)
 Call ID: call_K2q0vppOglzdx8du5lewTzR1
  Args:
    file_path: src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java
  read_file (call_vMUhq30BLlIIjPMPnzDaVqzf)
 Call ID: call_vMUhq30BLlIIjPMPnzDaVqzf
  Args:
    file_path: src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java

================================= Tool Message =================================
Name: read_file

/*
 * Copyright (C) 2007-2009 Jive Software. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.jivesoftware.openfire.plugin.util.cache;

import com.hazelcast.config.ClasspathXmlConfig;
import com.hazelcast.config.Config;
import com.hazelcast.config.MapConfig;
import com.hazelcast.config.MaxSizeConfig;
import com.hazelcast.config.MemberAttributeConfig;
import com.hazelcast.config.MemcacheProtocolConfig;
import com.hazelcast.config.NetworkConfig;
import com.hazelcast.config.RestApiConfig;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.Hazelcast;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.Member;
import org.jivesoftware.openfire.JMXManager;
import org.jivesoftware.openfire.XMPPServer;
import org.jivesoftware.openfire.cluster.ClusterEventListener;
import org.jivesoftware.openfire.cluster.ClusterManager;
import org.jivesoftware.openfire.cluster.ClusterNodeInfo;
import org.jivesoftware.openfire.cluster.NodeID;
import org.jivesoftware.openfire.container.Plugin;
import org.jivesoftware.openfire.container.PluginClassLoader;
import org.jivesoftware.openfire.plugin.HazelcastPlugin;
import org.jivesoftware.openfire.plugin.util.cluster.HazelcastClusterNodeInfo;
import org.jivesoftware.util.StringUtils;
import org.jivesoftware.util.SystemProperty;
import org.jivesoftware.util.cache.Cache;
import org.jivesoftware.util.cache.CacheFactory;
import org.jivesoftware.util.cache.CacheFactoryStrategy;
import org.jivesoftware.util.cache.CacheWrapper;
import org.jivesoftware.util.cache.ClusterTask;
import org.jivesoftware.util.cache.ExternalizableUtil;
import org.jivesoftware.util.cache.ExternalizableUtilStrategy;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.Serializable;
import java.nio.charset.StandardCharsets;
import java.text.MessageFormat;
import java.time.Duration;
import java.time.Instant;
import java.time.temporal.ChronoUnit;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.Callable;
import java.util.concurrent.Future;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;

/**
 * CacheFactory implementation to use when using Hazelcast in cluster mode.
 *
 * @author Tom Evans
 * @author Gaston Dombiak
 */
public class ClusteredCacheFactory implements CacheFactoryStrategy {

    private static final SystemProperty<String> HAZELCAST_EXECUTOR_SERVICE_NAME = SystemProperty.Builder.ofType(String.class)
        .setKey("hazelcast.executor.service.name")
        .setDefaultValue("openfire::cluster::executor")
        .setDynamic(false)
        .setPlugin(HazelcastPlugin.PLUGIN_NAME)
        .build();
    private static final SystemProperty<Duration> MAX_CLUSTER_EXECUTION_TIME = SystemProperty.Builder.ofType(Duration.class)
        .setKey("hazelcast.max.execution.seconds")
        .setDefaultValue(Duration.ofSeconds(30))
        .setChronoUnit(ChronoUnit.SECONDS)
        .setDynamic(true)
        .setPlugin(HazelcastPlugin.PLUGIN_NAME)
        .build();
    private static final SystemProperty<Duration> CLUSTER_STARTUP_RETRY_TIME = SystemProperty.Builder.ofType(Duration.class)
        .setKey("hazelcast.startup.retry.seconds")
        .setDefaultValue(Duration.ofSeconds(10))
        .setChronoUnit(ChronoUnit.SECONDS)
        .setDynamic(true)
        .setPlugin(HazelcastPlugin.PLUGIN_NAME)
        .build();
    private static final SystemProperty<Integer> CLUSTER_STARTUP_RETRY_COUNT = SystemProperty.Builder.ofType(Integer.class)
        .setKey("hazelcast.startup.retry.count")
        .setDefaultValue(1)
        .setDynamic(true)
        .setPlugin(HazelcastPlugin.PLUGIN_NAME)
        .build();
    private static final SystemProperty<String> HAZELCAST_CONFIG_FILE = SystemProperty.Builder.ofType(String.class)
        .setKey("hazelcast.config.xml.filename")
        .setDefaultValue("hazelcast-cache-config.xml")
        .setDynamic(false)
        .setPlugin(HazelcastPlugin.PLUGIN_NAME)
        .build();
    private static final SystemProperty<Boolean> HAZELCAST_JMX_ENABLED = SystemProperty.Builder.ofType(Boolean.class)
        .setKey("hazelcast.config.jmx.enabled")
        .setDefaultValue(Boolean.FALSE)
        .setDynamic(false)
        .setPlugin(HazelcastPlugin.PLUGIN_NAME)
        .build();
    private static final SystemProperty<Boolean> HAZELCAST_REST_ENABLED = SystemProperty.Builder.ofType(Boolean.class)
        .setKey("hazelcast.config.rest.enabled")
        .setDefaultValue(Boolean.FALSE)
        .setDynamic(false)
        .setPlugin(HazelcastPlugin.PLUGIN_NAME)
        .build();
    private static final SystemProperty<Boolean> HAZELCAST_MEMCACHE_ENABLED = SystemProperty.Builder.ofType(Boolean.class)
        .setKey("hazelcast.config.memcache.enabled")
        .setDefaultValue(Boolean.FALSE)
        .setDynamic(false)
        .setPlugin(HazelcastPlugin.PLUGIN_NAME)
        .build();

    private static final Logger logger = LoggerFactory.getLogger(ClusteredCacheFactory.class);
    public static final String PLUGIN_NAME = "hazelcast";

    /**
     * Keep serialization strategy the server was using before we set our strategy. We will
     * restore old strategy when plugin is unloaded.
     */
    private ExternalizableUtilStrategy serializationStrategy;

    /**
     * Storage for cache statistics
     */
    private static Map<String, Map<String, long[]>> cacheStats;

    private static HazelcastInstance hazelcast = null;
    private static Cluster cluster = null;
    private ClusterListener clusterListener;
    private String lifecycleListener;
    private String membershipListener;

    /**
     * Keeps that running state. Initial state is stopped.
     */
    private State state = State.stopped;

    /**
     * Used to limit the amount of duplicate warnings logged.
     */
    private final Cache<String, Instant> pluginClassLoaderWarnings;

    public ClusteredCacheFactory() {
        pluginClassLoaderWarnings = CacheFactory.createLocalCache("PluginClassLoader Warnings for Clustered Tasks");
        pluginClassLoaderWarnings.setMaxLifetime(Duration.ofHours(1).toMillis()); // Minimum duration between logged warnings.
    }

    @Override
    public boolean startCluster() {
        logger.info("Starting hazelcast clustering");
        state = State.starting;

        // Set the serialization strategy to use for transmitting objects between node clusters
        serializationStrategy = ExternalizableUtil.getInstance().getStrategy();
        ExternalizableUtil.getInstance().setStrategy(new ClusterExternalizableUtil());

        // Store previous class loader (in case we change it)
        final ClassLoader oldLoader = Thread.currentThread().getContextClassLoader();
        final ClassLoader loader = new ClusterClassLoader();
        Thread.currentThread().setContextClassLoader(loader);
        int retry = 0;
        do {
            try {
                final Config config = new ClasspathXmlConfig(HAZELCAST_CONFIG_FILE.getValue());
                final NetworkConfig networkConfig = config.getNetworkConfig();
                if (!HAZELCAST_MEMCACHE_ENABLED.getValue()) {
                    networkConfig.setMemcacheProtocolConfig(new MemcacheProtocolConfig().setEnabled(false));
                }
                if (!HAZELCAST_REST_ENABLED.getValue()) {
                    networkConfig.setRestApiConfig(new RestApiConfig().setEnabled(false));
                }
                final MemberAttributeConfig memberAttributeConfig = config.getMemberAttributeConfig();
                memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.HOST_NAME_ATTRIBUTE, XMPPServer.getInstance().getServerInfo().getHostname());
                memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE, XMPPServer.getInstance().getNodeID().toString());
                config.setInstanceName("openfire");
                config.setClassLoader(loader);
                if (JMXManager.isEnabled() && HAZELCAST_JMX_ENABLED.getValue()) {
                    config.setProperty("hazelcast.jmx", "true");
                    config.setProperty("hazelcast.jmx.detailed", "true");
                }
                hazelcast = Hazelcast.newHazelcastInstance(config);
                cluster = hazelcast.getCluster();
                state = State.started;
                // CacheFactory is now using clustered caches. We can add our listeners.
                clusterListener = new ClusterListener(cluster);
                clusterListener.joinCluster();
                lifecycleListener = hazelcast.getLifecycleService().addLifecycleListener(clusterListener);
                membershipListener = cluster.addMembershipListener(clusterListener);
                logger.info("Hazelcast clustering started");
                break;
            } catch (final Exception e) {
                cluster = null;
                if (retry < CLUSTER_STARTUP_RETRY_COUNT.getValue()) {
                    logger.warn("Failed to start clustering (" + e.getMessage() + "); " +
                        "will retry in " + StringUtils.getFullElapsedTime(CLUSTER_STARTUP_RETRY_TIME.getValue()));
                    try {
                        Thread.sleep(CLUSTER_STARTUP_RETRY_TIME.getValue().toMillis());
                    } catch (final InterruptedException ignored) {
                        Thread.currentThread().interrupt();
                    }
                } else {
                    logger.error("Unable to start clustering - continuing in local mode", e);
                    state = State.stopped;
                }
            }
        } while (retry++ < CLUSTER_STARTUP_RETRY_COUNT.getValue() && !Thread.currentThread().isInterrupted());

        if (oldLoader != null) {
            // Restore previous class loader
            Thread.currentThread().setContextClassLoader(oldLoader);
        }
        return cluster != null;
    }

    @Override
    public void stopCluster() {
        // Stop the cache services.
        cacheStats = null;
        // Update the running state of the cluster
        state = State.stopped;

        // Fire the leftClusterEvent before we leave the cluster - we need to access the clustered data before the
        // cluster is shutdown so it can be copied in to the non-clustered, DefaultCache
        fireLeftClusterAndWaitToComplete(Duration.ofSeconds(30));
        // Stop the cluster
        hazelcast.getLifecycleService().removeLifecycleListener(lifecycleListener);
        cluster.removeMembershipListener(membershipListener);
        Hazelcast.shutdownAll();
        cluster = null;
        lifecycleListener = null;
        membershipListener = null;
        clusterListener = null;

        // Reset packet router to use to deliver packets to remote cluster nodes
        XMPPServer.getInstance().getRoutingTable().setRemotePacketRouter(null);
        // Reset the session locator to use
        XMPPServer.getInstance().setRemoteSessionLocator(null);
        // Set the old serialization strategy was using before clustering was loaded
        ExternalizableUtil.getInstance().setStrategy(serializationStrategy);
    }

    @Override
    public Cache createCache(final String name) {
        // Check if cluster is being started up
        while (state == State.starting) {
            // Wait until cluster is fully started (or failed)
            try {
                Thread.sleep(250);
            } catch (final InterruptedException e) {
                // Ignore
            }
        }
        if (state == State.stopped) {
            throw new IllegalStateException("Cannot create clustered cache when not in a cluster");
        }
        // Determine the time to live. Note that in Hazelcast 0 means "forever", not -1
        final long openfireLifetimeInMilliseconds = CacheFactory.getMaxCacheLifetime(name);
        final int hazelcastLifetimeInSeconds = openfireLifetimeInMilliseconds < 0 ? 0 : Math.max((int) (openfireLifetimeInMilliseconds / 1000), 1);
        // Determine the max cache size. Note that in Hazelcast the max cache size must be positive and is in megabytes
        final long openfireMaxCacheSizeInBytes = CacheFactory.getMaxCacheSize(name);
        final int hazelcastMaxCacheSizeInMegaBytes = openfireMaxCacheSizeInBytes < 0 ? Integer.MAX_VALUE : Math.max((int) openfireMaxCacheSizeInBytes / 1024 / 1024, 1);
        // It's only possible to create a dynamic config if a static one doesn't already exist
        final MapConfig staticConfig = hazelcast.getConfig().getMapConfigOrNull(name);
        if (staticConfig == null) {
            final MapConfig dynamicConfig = new MapConfig(name);
            dynamicConfig.setTimeToLiveSeconds(hazelcastLifetimeInSeconds);
            dynamicConfig.setMaxSizeConfig(new MaxSizeConfig(hazelcastMaxCacheSizeInMegaBytes, MaxSizeConfig.MaxSizePolicy.USED_HEAP_SIZE));
            logger.debug("Creating dynamic map config for cache={}, dynamicConfig={}", name, dynamicConfig);
            hazelcast.getConfig().addMapConfig(dynamicConfig);
        } else {
            logger.debug("Static configuration already exists for cache={}, staticConfig={}", name, staticConfig);
        }
        // TODO: Better genericize this method in CacheFactoryStrategy so we can stop suppressing this warning
        @SuppressWarnings("unchecked") final ClusteredCache clusteredCache = new ClusteredCache(name, hazelcast.getMap(name));
        return clusteredCache;
    }

    @Override
    public void destroyCache(Cache cache) {
        if (cache instanceof CacheWrapper) {
            cache = ((CacheWrapper) cache).getWrappedCache();
        }

        final ClusteredCache clustered = (ClusteredCache) cache;
        clustered.destroy();
    }

    @Override
    public boolean isSeniorClusterMember() {
        if (clusterListener == null || !clusterListener.isClusterMember()) {
            return false;
        }
        return clusterListener.isSeniorClusterMember();
    }

    @Override
    public List<ClusterNodeInfo> getClusterNodesInfo() {
        return clusterListener == null ? Collections.emptyList() : clusterListener.getClusterNodesInfo();
    }

    @Override
    public int getMaxClusterNodes() {
        // No longer depends on license code so just return a big number
        return 10000;
    }

    @Override
    public byte[] getSeniorClusterMemberID() {
        if (cluster != null && !cluster.getMembers().isEmpty()) {
            final Member oldest = cluster.getMembers().iterator().next();
            return getNodeID(oldest).toByteArray();
        } else {
            return null;
        }
    }

    @Override
    public byte[] getClusterMemberID() {
        if (cluster != null) {
            return getNodeID(cluster.getLocalMember()).toByteArray();
        } else {
            return null;
        }
    }

    /**
     * Gets the pseudo-synchronized time from the cluster. While the cluster members may
     * have varying system times, this method is expected to return a timestamp that is
     * synchronized (or nearly so; best effort) across the cluster.
     *
     * @return Synchronized time for all cluster members
     */
    @Override
    public long getClusterTime() {
        return cluster == null ? System.currentTimeMillis() : cluster.getClusterTime();
    }

    /*
     * Execute the given task on the other (non-local) cluster members.
     * Note that this method does not provide the result set for the given
     * task, as the task is run asynchronously across the cluster.
     */
    @Override
    public void doClusterTask(final ClusterTask<?> task) {

        if (cluster == null) {
            return;
        }
        final Set<Member> members = new HashSet<>();
        final Member current = cluster.getLocalMember();
        for (final Member member : cluster.getMembers()) {
            if (!member.getUuid().equals(current.getUuid())) {
                members.add(member);
            }
        }


        if (!members.isEmpty()) {
            // Asynchronously execute the task on the other cluster members
            logger.debug("Executing asynchronous MultiTask: " + task.getClass().getName());
            checkForPluginClassLoader(task);
            hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMembers(new CallableTask<>(task), members);
        } else {
            logger.debug("No cluster members selected for cluster task " + task.getClass().getName());
        }
    }

    /*
     * Execute the given task on the given cluster member.
     * Note that this method does not provide the result set for the given
     * task, as the task is run asynchronously across the cluster.
     */
    @Override
    public void doClusterTask(final ClusterTask<?> task, final byte[] nodeID) {
        if (cluster == null) {
            return;
        }
        final Member member = getMember(nodeID);
        // Check that the requested member was found
        if (member != null) {
            // Asynchronously execute the task on the target member
            logger.debug("Executing asynchronous DistributedTask: " + task.getClass().getName());
            checkForPluginClassLoader(task);
            hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMember(new CallableTask<>(task), member);
        } else {
            final String msg = MessageFormat.format("Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8));
            logger.warn(msg);
            throw new IllegalArgumentException(msg);
        }
    }

    /*
     * Execute the given task on the designated cluster members.
     * Note that this method blocks for up to MAX_CLUSTER_EXECUTION_TIME
     * (seconds) per member until the task is run on all members.
     */
    @Override
    public <T> Collection<T> doSynchronousClusterTask(final ClusterTask<T> task, final boolean includeLocalMember) {
        if (cluster == null) {
            return Collections.emptyList();
        }
        final Set<Member> members = new HashSet<>();
        final Member current = cluster.getLocalMember();
        for (final Member member : cluster.getMembers()) {
            if (includeLocalMember || (!member.getUuid().equals(current.getUuid()))) {
                members.add(member);
            }
        }
        final Collection<T> result = new ArrayList<>();
        if (!members.isEmpty()) {
            // Asynchronously execute the task on the other cluster members
            try {
                logger.debug("Executing MultiTask: " + task.getClass().getName());
                checkForPluginClassLoader(task);
                final Map<Member, ? extends Future<T>> futures = hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMembers(new CallableTask<>(task), members);
                long nanosLeft = TimeUnit.SECONDS.toNanos(MAX_CLUSTER_EXECUTION_TIME.getValue().getSeconds() * members.size());
                for (final Future<T> future : futures.values()) {
                    final long start = System.nanoTime();
                    result.add(future.get(nanosLeft, TimeUnit.NANOSECONDS));
                    nanosLeft = nanosLeft - (System.nanoTime() - start);
                }
            } catch (final TimeoutException te) {
                logger.error("Failed to execute cluster task within " + StringUtils.getFullElapsedTime(MAX_CLUSTER_EXECUTION_TIME.getValue()), te);
            } catch (final Exception e) {
                logger.error("Failed to execute cluster task", e);
            }
        } else {
            logger.debug("No cluster members selected for cluster task " + task.getClass().getName());
        }
        return result;
    }

    /*
     * Execute the given task on the designated cluster member.
     * Note that this method blocks for up to MAX_CLUSTER_EXECUTION_TIME
     * (seconds) until the task is run on the given member.
     */
    @Override
    public <T> T doSynchronousClusterTask(final ClusterTask<T> task, final byte[] nodeID) {
        if (cluster == null) {
            return null;
        }
        final Member member = getMember(nodeID);
        T result = null;
        // Check that the requested member was found
        if (member != null) {
            // Asynchronously execute the task on the target member
            logger.debug("Executing DistributedTask: " + task.getClass().getName());
            checkForPluginClassLoader(task);
            try {
                final Future<T> future = hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMember(new CallableTask<>(task), member);
                result = future.get(MAX_CLUSTER_EXECUTION_TIME.getValue().getSeconds(), TimeUnit.SECONDS);
                logger.trace("DistributedTask result: {}", result);
            } catch (final TimeoutException te) {
                logger.error("Failed to execute cluster task within " + MAX_CLUSTER_EXECUTION_TIME + " seconds", te);
            } catch (final Exception e) {
                logger.error("Failed to execute cluster task", e);
            }
        } else {
            final String msg = MessageFormat.format("Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8));
            logger.warn(msg);
            throw new IllegalArgumentException(msg);
        }
        return result;
    }

    @Override
    public ClusterNodeInfo getClusterNodeInfo(final byte[] nodeID) {
        if (cluster == null) {
            return null;
        }
        ClusterNodeInfo result = null;
        final Member member = getMember(nodeID);
        if (member != null) {
            result = new HazelcastClusterNodeInfo(member, cluster.getClusterTime());
        }
        return result;
    }

    private Member getMember(final byte[] nodeID) {
        final NodeID memberToFind = NodeID.getInstance(nodeID);
        for (final Member member : cluster.getMembers()) {
            if (memberToFind.equals(getNodeID(member))) {
                return member;
            }
        }
        return null;
    }

    @Override
    public void updateCacheStats(final Map<String, Cache> caches) {
        if (!caches.isEmpty() && cluster != null) {
            // Create the cacheStats map if necessary.
            if (cacheStats == null) {
                cacheStats = hazelcast.getMap("opt-$cacheStats");
            }
            final String uid = getNodeID(cluster.getLocalMember()).toString();
            final Map<String, long[]> stats = new HashMap<>();
            for (final String cacheName : caches.keySet()) {
                final Cache cache = caches.get(cacheName);
                // The following information is published:
                // current size, max size, num elements, cache
                // hits, cache misses.
                final long[] info = new long[5];
                info[0] = cache.getLongCacheSize();
                info[1] = cache.getMaxCacheSize();
                info[2] = cache.size();
                info[3] = cache.getCacheHits();
                info[4] = cache.getCacheMisses();
                stats.put(cacheName, info);
            }
            // Publish message
            cacheStats.put(uid, stats);
        }
    }

    @Override
    public String getPluginName() {
        return PLUGIN_NAME;
    }

    @Override
    public Lock getLock(final Object key, Cache cache) {
        if (cache instanceof CacheWrapper) {
            cache = ((CacheWrapper) cache).getWrappedCache();
        }
        // TODO: Update CacheFactoryStrategy so the signature is getLock(final Serializable key, Cache<Serializable, Serializable> cache)
        @SuppressWarnings("unchecked") final ClusterLock clusterLock = new ClusterLock((Serializable) key, (ClusteredCache<Serializable, ?>) cache);
        return clusterLock;
    }

    /**
     * ClusterTasks that are executed should not be provided by a plugin. These will cause issues related to class
     * loading when the providing plugin is reloaded. This method verifies if an instance of a task is
     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is
     * limited by a time interval.
     *
     * @param o the instance for which to verify the class loader
     * @see <a href="https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>
     */
    protected <T extends ClusterTask<?>> void checkForPluginClassLoader(final T o) {
        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader
            && !pluginClassLoaderWarnings.containsKey(o.getClass().getName()) )
        {
            // Try to determine what plugin loaded the offending class.
            String pluginName = null;
            try {
                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();
                for (final Plugin plugin : plugins) {
                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);
                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {
                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);
                        break;
                    }
                }
            } catch (Exception e) {
                logger.debug("An exception occurred while trying to determine the plugin class loader that loaded an instance of {}", o.getClass(), e);
            }
            logger.warn("An instance of {} that is executed as a cluster task. This will cause issues when reloading " +
                    "the plugin that provides this class. The plugin implementation should be modified.",
                pluginName != null ? o.getClass() + " (provided by plugin " + pluginName + ")" : o.getClass());
            pluginClassLoaderWarnings.put(o.getClass().getName(), Instant.now()); // Note that this Instant is unused.
        }
    }

    private static class ClusterLock implements Lock {

        private final Serializable key;
        private final ClusteredCache<Serializable, ?> cache;

        ClusterLock(final Serializable key, final ClusteredCache<Serializable, ?> cache) {
            this.key = key;
            this.cache = cache;
        }

        @Override
        public void lock() {
            cache.lock(key, -1);
        }

        @Override
        public void lockInterruptibly() {
            cache.lock(key, -1);
        }

        @Override
        public boolean tryLock() {
            return cache.lock(key, 0);
        }

        @Override
        public boolean tryLock(final long time, final TimeUnit unit) {
            return cache.lock(key, unit.toMillis(time));
        }

        @Override
        public void unlock() {
            cache.unlock(key);
        }

        @Override
        public Condition newCondition() {
            throw new UnsupportedOperationException();
        }
    }

    private static class CallableTask<V> implements Callable<V>, Serializable {
        private static final long serialVersionUID = -8761271979427214681L;
        private final ClusterTask<V> task;

        CallableTask(final ClusterTask<V> task) {
            this.task = task;
        }

        @Override
        public V call() {
            try {
                task.run();
                logger.trace("CallableTask[{}] result: {}", task.getClass().getName(), task.getResult());
                return task.getResult();
            } catch (final Exception e) {
                logger.error("Unexpected exception running CallableTask[{}]", task.getClass().getName(), e);
                throw e;
            }
        }
    }

    private enum State {
        stopped,
        starting,
        started
    }

    public static NodeID getNodeID(final Member member) {
        return NodeID.getInstance(member.getStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));
    }

    static void fireLeftClusterAndWaitToComplete(final Duration timeout) {
        final Semaphore leftClusterSemaphore = new Semaphore(0);
        final ClusterEventListener clusterEventListener = new ClusterEventListener() {
            @Override
            public void joinedCluster() {
            }

            @Override
            public void joinedCluster(final byte[] bytes) {
            }

            @Override
            public void leftCluster() {
                leftClusterSemaphore.release();
            }

            @Override
            public void leftCluster(final byte[] bytes) {
            }

            @Override
            public void markedAsSeniorClusterMember() {
            }
        };
        try {
            // Add a listener at the ultimate end of the list of all listeners, to detect that left-cluster event handling
            // has been invoked for all before proceeding.
            ClusterManager.addListener(clusterEventListener, Integer.MAX_VALUE);
            logger.debug("Firing leftCluster() event");
            ClusterManager.fireLeftCluster();
            logger.debug("Waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout));
            if (!leftClusterSemaphore.tryAcquire(timeout.toMillis(), TimeUnit.MILLISECONDS)) {
                logger.warn("Timeout waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout));
            }
        } catch (final Exception e) {
            logger.error("Unexpected exception waiting for clustering to shut down", e);
        } finally {
            ClusterManager.removeListener(clusterEventListener);
        }
    }

}





================================= Tool Message =================================
Name: read_file

/*
 * Copyright (C) 1999-2009 Jive Software. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.jivesoftware.openfire.plugin.util.cache;

import com.hazelcast.core.Cluster;
import com.hazelcast.core.EntryListener;
import com.hazelcast.core.LifecycleEvent;
import com.hazelcast.core.LifecycleEvent.LifecycleState;
import com.hazelcast.core.LifecycleListener;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberAttributeEvent;
import com.hazelcast.core.MembershipEvent;
import com.hazelcast.core.MembershipListener;
import org.jivesoftware.openfire.XMPPServer;
import org.jivesoftware.openfire.cluster.ClusterManager;
import org.jivesoftware.openfire.cluster.ClusterNodeInfo;
import org.jivesoftware.openfire.cluster.NodeID;
import org.jivesoftware.openfire.muc.cluster.NewClusterMemberJoinedTask;
import org.jivesoftware.openfire.plugin.util.cluster.HazelcastClusterNodeInfo;
import org.jivesoftware.util.cache.Cache;
import org.jivesoftware.util.cache.CacheFactory;
import org.jivesoftware.util.cache.CacheWrapper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.time.Duration;
import java.time.LocalTime;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * ClusterListener reacts to membership changes in the cluster. It takes care of cleaning up the state
 * of the routing table and the sessions within it when a node which manages those sessions goes down.
 */
public class ClusterListener implements MembershipListener, LifecycleListener {

    private static final Logger logger = LoggerFactory.getLogger(ClusterListener.class);

    private boolean seniorClusterMember = false;

    private final Map<Cache<?,?>, EntryListener> entryListeners = new HashMap<>();
    
    private final Cluster cluster;
    private final Map<NodeID, ClusterNodeInfo> clusterNodesInfo = new ConcurrentHashMap<>();
    
    /**
     * Flag that indicates if the listener has done all clean up work when noticed that the
     * cluster has been stopped. This will force Openfire to wait until all clean
     * up (e.g. changing caches implementations) is done before destroying the plugin.
     */
    private boolean done = true;
    /**
     * Flag that indicates if we've joined a cluster or not
     */
    private boolean clusterMember = false;
    private boolean isSenior;

    ClusterListener(final Cluster cluster) {

        this.cluster = cluster;
        for (final Member member : cluster.getMembers()) {
            clusterNodesInfo.put(ClusteredCacheFactory.getNodeID(member),
                    new HazelcastClusterNodeInfo(member, cluster.getClusterTime()));
        }
    }

    private void addEntryListener(final Cache<?, ?> cache, final EntryListener listener) {
        if (cache instanceof CacheWrapper) {
            final Cache wrapped = ((CacheWrapper)cache).getWrappedCache();
            if (wrapped instanceof ClusteredCache) {
                ((ClusteredCache)wrapped).addEntryListener(listener);
                // Keep track of the listener that we added to the cache
                entryListeners.put(cache, listener);
            }
        }
    }

    @SuppressWarnings("unchecked")
    private boolean isDone() {
        return done;
    }

    synchronized void joinCluster() {
        if (!isDone()) { // already joined
            return;
        }

        // Trigger events
        clusterMember = true;
        seniorClusterMember = isSeniorClusterMember();

        ClusterManager.fireJoinedCluster(false);

        if (seniorClusterMember) {
            ClusterManager.fireMarkedAsSeniorClusterMember();
        }

        waitForClusterCacheToBeInstalled();

        // Let the other nodes know that we joined the cluster
        logger.debug("Done joining the cluster. Now proceed informing other nodes that we joined the cluster.");
        CacheFactory.doClusterTask(new NewClusterMemberJoinedTask());

        logger.info("Joined cluster. XMPPServer node={}, Hazelcast UUID={}, seniorClusterMember={}",
            new Object[]{ClusteredCacheFactory.getNodeID(cluster.getLocalMember()), cluster.getLocalMember().getUuid(), seniorClusterMember});
        done = false;
    }

    boolean isSeniorClusterMember() {
        // first cluster member is the oldest
        final Iterator<Member> members = cluster.getMembers().iterator();
        return members.next().getUuid().equals(cluster.getLocalMember().getUuid());
    }

    private synchronized void leaveCluster() {
        if (isDone()) { // not a cluster member
            return;
        }
        clusterMember = false;
        final boolean wasSeniorClusterMember = seniorClusterMember;
        seniorClusterMember = false;

        // Trigger event. Wait until the listeners have processed the event. Caches will be populated
        // again with local content.
        ClusterManager.fireLeftCluster();

        if (!XMPPServer.getInstance().isShuttingDown()) {
            // Remove traces of directed presences sent from local entities to handlers that no longer exist
            // At this point c2s sessions are gone from the routing table so we can identify expired sessions
            XMPPServer.getInstance().getPresenceUpdateHandler().removedExpiredPresences();
        }
        logger.info("Left cluster. XMPPServer node={}, Hazelcast UUID={}, wasSeniorClusterMember={}",
            new Object[]{ClusteredCacheFactory.getNodeID(cluster.getLocalMember()), cluster.getLocalMember().getUuid(), wasSeniorClusterMember});
        done = true;
    }

    @Override
    public void memberAdded(final MembershipEvent event) {
        logger.info("Received a Hazelcast memberAdded event {}", event);

        final boolean wasSenior = isSenior;
        isSenior = isSeniorClusterMember();
        // local member only
        final NodeID nodeID = ClusteredCacheFactory.getNodeID(event.getMember());
        if (event.getMember().localMember()) { // We left and re-joined the cluster
            joinCluster();

        } else {
            if (wasSenior && !isSenior) {
                logger.warn("Recovering from split-brain; firing leftCluster()/joinedCluster() events");
                ClusteredCacheFactory.fireLeftClusterAndWaitToComplete(Duration.ofSeconds(30));
                logger.debug("Firing joinedCluster() event");
                ClusterManager.fireJoinedCluster(false);

                try {
                    logger.debug("Postponing notification of other nodes for 30 seconds. This allows all local leave/join processing to be finished and local cache backups to be stabilized before receiving events from other nodes.");
                    Thread.sleep(30000L);
                } catch (InterruptedException e) {
                    logger.warn("30 Second wait was interrupted.", e);
                }

                // The following line was intended to wait until all local handling finishes before informing other
                // nodes. However that proved to be insufficient. Hence the 30 second default wait in the lines above.
                // TODO Instead of the 30 second wait, we should look (and then wait) for some trigger or event that signifies that local handling has completed and caches have stabilized.
                waitForClusterCacheToBeInstalled();

                // Let the other nodes know that we joined the cluster
                logger.debug("Done joining the cluster in split brain recovery. Now proceed informing other nodes that we joined the cluster.");
                CacheFactory.doClusterTask(new NewClusterMemberJoinedTask());
            }
        }
        clusterNodesInfo.put(nodeID,
                new HazelcastClusterNodeInfo(event.getMember(), cluster.getClusterTime()));
    }

    /**
     * Blocks the current thread until the cluster cache is guaranteed to support clustering. This is especially useful
     * for executing cluster tasks immediately after joining. If this wait is not performed, the cache factory may still
     * be using the 'default' strategy instead of the 'hazelcast' strategy, which leads to cluster tasks being silently
     * discarded.
     *
     * The method will keep trying this for 10 minutes. After that the thread is released regardless of the result.
     *
     * @return Boolean indicating whether the clustered cache was actually observed to be installed.
     */
    private boolean waitForClusterCacheToBeInstalled() {
        boolean failed = false;
        if (!ClusteredCacheFactory.PLUGIN_NAME.equals(CacheFactory.getPluginName())) {
            logger.debug("This node now joined a cluster, but the cache factory has not been swapped to '{}' yet. Waiting for that to happen.", ClusteredCacheFactory.PLUGIN_NAME);
            LocalTime deadLine = LocalTime.now().plusMinutes(10L);
            while (!ClusteredCacheFactory.PLUGIN_NAME.equals(CacheFactory.getPluginName()) && deadLine.isAfter(LocalTime.now())) {
                try {
                    Thread.sleep(200);
                } catch (InterruptedException e) {
                    logger.trace("Thread was interrupted while waiting for cache strategy to change.");
                    failed = true;
                    break;
                }
            }
            if (!deadLine.isAfter(LocalTime.now())) {
                failed = true;
                logger.warn("Cache factory was not swapped to '{}', but still remains '{}' after a 10 minute wait. Cluster join is not guaranteed to have completed.", ClusteredCacheFactory.PLUGIN_NAME, CacheFactory.getPluginName());
            }
            logger.debug("Cache factory has been swapped to '{}'. Cluster join is considered complete.", ClusteredCacheFactory.PLUGIN_NAME);
        }

        return !failed;
    }

    @Override
    public void memberRemoved(final MembershipEvent event) {
        logger.info("Received a Hazelcast memberRemoved event {}", event);

        isSenior = isSeniorClusterMember();
        final NodeID nodeID = ClusteredCacheFactory.getNodeID(event.getMember());

        if (event.getMember().localMember()) {
            logger.info("Leaving cluster: " + nodeID);
            // This node may have realized that it got kicked out of the cluster
            leaveCluster();
        } else {
            // Trigger event that a node left the cluster
            ClusterManager.fireLeftCluster(nodeID.toByteArray());

            if (!seniorClusterMember && isSeniorClusterMember()) {
                seniorClusterMember = true;
                ClusterManager.fireMarkedAsSeniorClusterMember();
            }

            // Remove traces of directed presences sent from local entities to handlers that no longer exist.
            // At this point c2s sessions are gone from the routing table so we can identify expired sessions
            XMPPServer.getInstance().getPresenceUpdateHandler().removedExpiredPresences();
        }
        // Delete nodeID instance (release from memory)
        NodeID.deleteInstance(nodeID.toByteArray());
        clusterNodesInfo.remove(nodeID);
    }
    
    @SuppressWarnings("WeakerAccess")
    public List<ClusterNodeInfo> getClusterNodesInfo() {
        return new ArrayList<>(clusterNodesInfo.values());
    }

    @Override
    public void stateChanged(final LifecycleEvent event) {
        if (event.getState().equals(LifecycleState.SHUTDOWN)) {
            leaveCluster();
        } else if (event.getState().equals(LifecycleState.STARTED)) {
            joinCluster();
        }
    }

    @Override
    public void memberAttributeChanged(final MemberAttributeEvent event) {
        logger.info("Received a Hazelcast memberAttributeChanged event {}", event);
        isSenior = isSeniorClusterMember();
        final ClusterNodeInfo priorNodeInfo = clusterNodesInfo.get(ClusteredCacheFactory.getNodeID(event.getMember()));
        clusterNodesInfo.put(ClusteredCacheFactory.getNodeID(event.getMember()),
                new HazelcastClusterNodeInfo(event.getMember(), priorNodeInfo.getJoinedTime()));
    }

    boolean isClusterMember() {
        return clusterMember;
    }
}


================================= Tool Message =================================
Name: read_file

/*
 * Copyright (C) 1999-2009 Jive Software. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.jivesoftware.openfire.plugin.util.cache;

import com.hazelcast.core.EntryEvent;
import com.hazelcast.core.EntryListener;
import com.hazelcast.core.IMap;
import com.hazelcast.core.MapEvent;
import com.hazelcast.map.listener.MapListener;
import com.hazelcast.monitor.LocalMapStats;
import org.jivesoftware.openfire.XMPPServer;
import org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;
import org.jivesoftware.openfire.cluster.NodeID;
import org.jivesoftware.openfire.container.Plugin;
import org.jivesoftware.openfire.container.PluginClassLoader;
import org.jivesoftware.openfire.container.PluginManager;
import org.jivesoftware.util.cache.Cache;
import org.jivesoftware.util.cache.CacheFactory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.annotation.Nonnull;
import java.io.Serializable;
import java.time.Duration;
import java.time.Instant;
import java.util.Collection;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.TimeUnit;

/**
 * Clustered implementation of the Cache interface using Hazelcast.
 *
 */
public class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {

    private final Logger logger;

    private final Set<String> listeners = ConcurrentHashMap.newKeySet();

    /**
     * The map is used for distributed operations such as get, put, etc.
     */
    final IMap<K, V> map;
    private String name;
    private long numberOfGets = 0;

    /**
     * Used to limit the amount of duplicate warnings logged.
     */
    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;
    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);

    /**
     * Create a new cache using the supplied named cache as the actual cache implementation
     *
     * @param name a name for the cache, which should be unique per vm.
     * @param cache the cache implementation
     */
    protected ClusteredCache(final String name, final IMap<K, V> cache) {
        this.map = cache;
        this.name = name;
        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + "[cache: "+name+"]");
    }

    void addEntryListener(final MapListener listener) {
        listeners.add(map.addEntryListener(listener, false));
    }

    @Override
    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)
    {
        final EntryListener<K, V> listener = new EntryListener<K, V>() {
            @Override
            public void mapEvicted(MapEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing map evicted event of node '{}'", eventNodeId);
                    clusteredCacheEntryListener.mapEvicted(eventNodeId);
                }
            }

            @Override
            public void mapCleared(MapEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing map cleared event of node '{}'", eventNodeId);
                    clusteredCacheEntryListener.mapCleared(eventNodeId);
                }
            }

            @Override
            public void entryUpdated(EntryEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing entry update event of node '{}' for key '{}'", eventNodeId, event.getKey());
                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);
                }
            }

            @Override
            public void entryRemoved(EntryEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing entry removed event of node '{}' for key '{}'", eventNodeId, event.getKey());
                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);
                }
            }

            @Override
            public void entryEvicted(EntryEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing entry evicted event of node '{}' for key '{}'", eventNodeId, event.getKey());
                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);
                }
            }

            @Override
            public void entryAdded(EntryEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing entry added event of node '{}' for key '{}'", eventNodeId, event.getKey());
                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);
                }
            }
        };

        final String listenerId = map.addEntryListener(listener, includeValues);
        listeners.add(listenerId);
        logger.debug("Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'", includeValues, includeEventsFromLocalNode, listenerId);
        return listenerId;
    }

    @Override
    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {
        logger.debug("Removing clustered cache entry listener: '{}'", listenerId);
        map.removeEntryListener(listenerId);
        listeners.remove(listenerId);
    }

    @Override
    public String getName() {
        return name;
    }

    @Override
    public void setName(final String name) {
        this.name = name;
    }

    @Override
    public V put(final K key, final V object) {
        if (object == null) { return null; }
        checkForPluginClassLoader(key);
        checkForPluginClassLoader(object);
        return map.put(key, object);
    }

    @Override
    public V get(final Object key) {
        numberOfGets++;
        return map.get(key);
    }

    @Override
    public V remove(final Object key) {
        return map.remove(key);
    }

    @Override
    public void clear() {
        map.clear();
    }

    @Override
    public int size() {
        final LocalMapStats stats = map.getLocalMapStats();
        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());
    }

    @Override
    public boolean containsKey(final Object key) {
        return map.containsKey(key);
    }

    @Override
    public boolean containsValue(final Object value) {
        return map.containsValue(value);
    }

    @Override
    public Set<Map.Entry<K, V>> entrySet() {
        return map.entrySet();
    }

    @Override
    public boolean isEmpty() {
        return map.isEmpty();
    }

    @Override
    public Set<K> keySet() {
        return map.keySet();
    }

    @Override
    public void putAll(final Map<? extends K, ? extends V> entries) {
        map.putAll(entries);

        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.
        entries.entrySet().stream().findAny().ifPresent(
            e -> {
                checkForPluginClassLoader(e.getKey());
                checkForPluginClassLoader(e.getValue());
            }
        );
    }

    @Override
    public Collection<V> values() {
        return map.values();
    }

    @Override
    public long getCacheHits() {
        return map.getLocalMapStats().getHits();
    }

    @Override
    public long getCacheMisses() {
        final long hits = map.getLocalMapStats().getHits();
        return numberOfGets > hits ? numberOfGets - hits : 0;
    }

    @Override
    public int getCacheSize() {
        return (int) getLongCacheSize();
    }

    @Override
    public long getLongCacheSize() {
        final LocalMapStats stats = map.getLocalMapStats();
        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();
    }

    @Override
    public long getMaxCacheSize() {
        return CacheFactory.getMaxCacheSize(getName());
    }

    @Override
    public void setMaxCacheSize(int i) {
        setMaxCacheSize((long) i);
    }

    @Override
    public void setMaxCacheSize(final long maxSize) {
        CacheFactory.setMaxSizeProperty(getName(), maxSize);
    }

    @Override
    public long getMaxLifetime() {
        return CacheFactory.getMaxCacheLifetime(getName());
    }

    @Override
    public void setMaxLifetime(final long maxLifetime) {
        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);
    }

    void destroy() {
        listeners.forEach(map::removeEntryListener);
        map.destroy();
    }

    boolean lock(final K key, final long timeout) {
        boolean result = true;
        if (timeout < 0) {
            map.lock(key);
        } else if (timeout == 0) {
            result = map.tryLock(key);
        } else {
            try {
                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);
            } catch (final InterruptedException e) {
                logger.error("Failed to get cluster lock", e);
                result = false;
            }
        }
        return result;
    }

    void unlock(final K key) {
        try {
            map.unlock(key);
        } catch (final IllegalMonitorStateException e) {
            logger.error("Failed to release cluster lock", e);
        }
    }

    /**
     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause
     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is
     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is
     * limited by a time interval.
     *
     * @param o the instance for which to verify the class loader
     * @see <a href="https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>
     */
    protected void checkForPluginClassLoader(final Object o) {
        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader
            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )
        {
            // Try to determine what plugin loaded the offending class.
            String pluginName = null;
            try {
                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();
                for (final Plugin plugin : plugins) {
                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);
                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {
                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);
                        break;
                    }
                }
            } catch (Exception e) {
                logger.debug("An exception occurred while trying to determine the plugin class loader that loaded an instance of {}", o.getClass(), e);
            }
            logger.warn("An instance of {} that is loaded by {} has been added to the cache. " +
                "This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.",
                o.getClass(), pluginName != null ? pluginName : "a PluginClassLoader");
            lastPluginClassLoaderWarning = Instant.now();
        }
    }
}


================================== Ai Message ==================================

```diff
--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java
+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java
@@ -22,7 +22,6 @@
 import com.hazelcast.config.MapConfig;
-import com.hazelcast.config.MaxSizeConfig;
 import com.hazelcast.config.MemberAttributeConfig;
 import com.hazelcast.config.MemcacheProtocolConfig;
 import com.hazelcast.config.NetworkConfig;
@@ -27,7 +26,6 @@
 import com.hazelcast.config.RestApiConfig;
-import com.hazelcast.core.Cluster;
 import com.hazelcast.core.Hazelcast;
 import com.hazelcast.core.HazelcastInstance;
-import com.hazelcast.core.Member;
@@ -149,7 +147,6 @@
     private static HazelcastInstance hazelcast = null;
-    private static Cluster cluster = null;
     private ClusterListener clusterListener;
     private String lifecycleListener;
     private String membershipListener;
@@ -201,7 +198,7 @@
                 }
                 hazelcast = Hazelcast.newHazelcastInstance(config);
-                cluster = hazelcast.getCluster();
+                Cluster cluster = hazelcast.getCluster();
                 state = State.started;
                 // CacheFactory is now using clustered caches. We can add our listeners.
                 clusterListener = new ClusterListener(cluster);
@@ -501,7 +498,7 @@
     public byte[] getSeniorClusterMemberID() {
-        if (cluster != null && !cluster.getMembers().isEmpty()) {
-            final Member oldest = cluster.getMembers().iterator().next();
+        Cluster cluster = hazelcast.getCluster();
+        if (cluster != null && !cluster.getMembers().isEmpty()) {
+            final com.hazelcast.cluster.Member oldest = cluster.getMembers().iterator().next();
             return getNodeID(oldest).toByteArray();
         } else {
             return null;
@@ -655,7 +652,7 @@
     public byte[] getClusterMemberID() {
-        if (cluster != null) {
+        Cluster cluster = hazelcast.getCluster();
+        if (cluster != null) {
             return getNodeID(cluster.getLocalMember()).toByteArray();
         } else {
             return null;
@@ -688,7 +685,7 @@
     @Override
     public long getClusterTime() {
-        return cluster == null ? System.currentTimeMillis() : cluster.getClusterTime();
+        Cluster cluster = hazelcast.getCluster();
+        return cluster == null ? System.currentTimeMillis() : cluster.getClusterTime();
     }
 
@@ -727,7 +724,7 @@
         if (cluster == null) {
             return;
         }
-        final Set<Member> members = new HashSet<>();
-        final Member current = cluster.getLocalMember();
-        for (final Member member : cluster.getMembers()) {
+        final Set<com.hazelcast.cluster.Member> members = new HashSet<>();
+        final com.hazelcast.cluster.Member current = cluster.getLocalMember();
+        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {
             if (!member.getUuid().equals(current.getUuid())) {
                 members.add(member);
             }
@@ -754,7 +751,7 @@
         if (cluster == null) {
             return;
         }
-        final Member member = getMember(nodeID);
+        final com.hazelcast.cluster.Member member = getMember(nodeID);
         // Check that the requested member was found
         if (member != null) {
             // Asynchronously execute the task on the target member
@@ -783,7 +780,7 @@
         if (cluster == null) {
             return Collections.emptyList();
         }
-        final Set<Member> members = new HashSet<>();
-        final Member current = cluster.getLocalMember();
-        for (final Member member : cluster.getMembers()) {
+        final Set<com.hazelcast.cluster.Member> members = new HashSet<>();
+        final com.hazelcast.cluster.Member current = cluster.getLocalMember();
+        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {
             if (includeLocalMember || (!member.getUuid().equals(current.getUuid()))) {
                 members.add(member);
             }
@@ -819,7 +816,7 @@
         if (cluster == null) {
             return null;
         }
-        final Member member = getMember(nodeID);
+        final com.hazelcast.cluster.Member member = getMember(nodeID);
         T result = null;
         // Check that the requested member was found
         if (member != null) {
@@ -841,7 +838,7 @@
         if (cluster == null) {
             return null;
         }
-        final Member member = getMember(nodeID);
+        final com.hazelcast.cluster.Member member = getMember(nodeID);
         if (member != null) {
             result = new HazelcastClusterNodeInfo(member, cluster.getClusterTime());
         }
@@ -850,7 +847,7 @@
     }
 
     private Member getMember(final byte[] nodeID) {
         final NodeID memberToFind = NodeID.getInstance(nodeID);
-        for (final Member member : cluster.getMembers()) {
+        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {
             if (memberToFind.equals(getNodeID(member))) {
                 return member;
             }
@@ -1007,7 +1004,7 @@
     }
 
     public static NodeID getNodeID(final Member member) {
-        return NodeID.getInstance(member.getStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));
+        return NodeID.getInstance(member.getAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));
     }
 
     static void fireLeftClusterAndWaitToComplete(final Duration timeout) {
--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java
+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java
@@ -18,7 +18,7 @@
 import com.hazelcast.core.Cluster;
 import com.hazelcast.core.EntryListener;
 import com.hazelcast.core.LifecycleEvent;
 import com.hazelcast.core.LifecycleEvent.LifecycleState;
 import com.hazelcast.core.LifecycleListener;
-import com.hazelcast.core.Member;
-import com.hazelcast.core.MemberAttributeEvent;
-import com.hazelcast.core.MembershipEvent;
-import com.hazelcast.core.MembershipListener;
+import com.hazelcast.cluster.Member;
+import com.hazelcast.cluster.MemberAttributeEvent;
+import com.hazelcast.cluster.MembershipEvent;
+import com.hazelcast.cluster.MembershipListener;
 import org.jivesoftware.openfire.XMPPServer;
 import org.jivesoftware.openfire.cluster.ClusterManager;
 import org.jivesoftware.openfire.cluster.ClusterNodeInfo;
 import org.jivesoftware.openfire.cluster.NodeID;
 import org.jivesoftware.openfire.muc.cluster.NewClusterMemberJoinedTask;
 import org.jivesoftware.openfire.plugin.util.cluster.HazelcastClusterNodeInfo;
 import org.jivesoftware.util.cache.Cache;
 import org.jivesoftware.util.cache.CacheFactory;
 import org.jivesoftware.util.cache.CacheWrapper;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import java.time.Duration;
 import java.time.LocalTime;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
 /**
  * ClusterListener reacts to membership changes in the cluster. It takes care of cleaning up the state
  * of the routing table and the sessions within it when a node which manages those sessions goes down.
  */
 public class ClusterListener implements MembershipListener, LifecycleListener {
 
     private static final Logger logger = LoggerFactory.getLogger(ClusterListener.class);
 
     private boolean seniorClusterMember = false;
 
     private final Map<Cache<?,?>, EntryListener> entryListeners = new HashMap<>();
     
     private final Cluster cluster;
     private final Map<NodeID, ClusterNodeInfo> clusterNodesInfo = new ConcurrentHashMap<>();
     
     /**
      * Flag that indicates if the listener has done all clean up work when noticed that the
      * cluster has been stopped. This will force Openfire to wait until all clean
      * up (e.g. changing caches implementations) is done before destroying the plugin.
      */
     private boolean done = true;
     /**
      * Flag that indicates if we've joined a cluster or not
      */
     private boolean clusterMember = false;
     private boolean isSenior;
 
     ClusterListener(final Cluster cluster) {
 
         this.cluster = cluster;
         for (final Member member : cluster.getMembers()) {
             clusterNodesInfo.put(ClusteredCacheFactory.getNodeID(member),
                     new HazelcastClusterNodeInfo(member, cluster.getClusterTime()));
         }
     }
 
     private void addEntryListener(final Cache<?, ?> cache, final EntryListener listener) {
         if (cache instanceof CacheWrapper) {
             final Cache wrapped = ((CacheWrapper)cache).getWrappedCache();
             if (wrapped instanceof ClusteredCache) {
                 ((ClusteredCache)wrapped).addEntryListener(listener);
                 // Keep track of the listener that we added to the cache
                 entryListeners.put(cache, listener);
             }
         }
     }
 
     @SuppressWarnings("unchecked")
     private boolean isDone() {
         return done;
     }
 
     synchronized void joinCluster() {
         if (!isDone()) { // already joined
             return;
         }
 
         // Trigger events
         clusterMember = true;
         seniorClusterMember = isSeniorClusterMember();
 
         ClusterManager.fireJoinedCluster(false);
 
         if (seniorClusterMember) {
             ClusterManager.fireMarkedAsSeniorClusterMember();
         }
 
         waitForClusterCacheToBeInstalled();
 
         // Let the other nodes know that we joined the cluster
         logger.debug("Done joining the cluster. Now proceed informing other nodes that we joined the cluster.");
         CacheFactory.doClusterTask(new NewClusterMemberJoinedTask());
 
         logger.info("Joined cluster. XMPPServer node={}, Hazelcast UUID={}, seniorClusterMember={}",
             new Object[]{ClusteredCacheFactory.getNodeID(cluster.getLocalMember()), cluster.getLocalMember().getUuid(), seniorClusterMember});
         done = false;
     }
 
     boolean isSeniorClusterMember() {
         // first cluster member is the oldest
         final Iterator<Member> members = cluster.getMembers().iterator();
         return members.next().getUuid().equals(cluster.getLocalMember().getUuid());
     }
 
     private synchronized void leaveCluster() {
         if (isDone()) { // not a cluster member
             return;
         }
         clusterMember = false;
         final boolean wasSeniorClusterMember = seniorClusterMember;
         seniorClusterMember = false;
 
         // Trigger event. Wait until the listeners have processed the event. Caches will be populated
         // again with local content.
         ClusterManager.fireLeftCluster();
 
         if (!XMPPServer.getInstance().isShuttingDown()) {
             // Remove traces of directed presences sent from local entities to handlers that no longer exist
             // At this point c2s sessions are gone from the routing table so we can identify expired sessions
             XMPPServer.getInstance().getPresenceUpdateHandler().removedExpiredPresences();
         }
         logger.info("Left cluster. XMPPServer node={}, Hazelcast UUID={}, wasSeniorClusterMember={}",
             new Object[]{ClusteredCacheFactory.getNodeID(cluster.getLocalMember()), cluster.getLocalMember().getUuid(), wasSeniorClusterMember});
         done = true;
     }
 
     @Override
     public void memberAdded(final MembershipEvent event) {
         logger.info("Received a Hazelcast memberAdded event {}", event);
 
         final boolean wasSenior = isSenior;
         isSenior = isSeniorClusterMember();
         // local member only
         final NodeID nodeID = ClusteredCacheFactory.getNodeID(event.getMember());
         if (event.getMember().localMember()) { // We left and re-joined the cluster
             joinCluster();
 
         } else {
             if (wasSenior && !isSenior) {
                 logger.warn("Recovering from split-brain; firing leftCluster()/joinedCluster() events");
                 ClusteredCacheFactory.fireLeftClusterAndWaitToComplete(Duration.ofSeconds(30));
                 logger.debug("Firing joinedCluster() event");
                 ClusterManager.fireJoinedCluster(false);
 
                 try {
                     logger.debug("Postponing notification of other nodes for 30 seconds. This allows all local leave/join processing to be finished and local cache backups to be stabilized before receiving events from other nodes.");
                     Thread.sleep(30000L);
                 } catch (InterruptedException e) {
                     logger.warn("30 Second wait was interrupted.", e);
                 }
 
                 // The following line was intended to wait until all local handling finishes before informing other
                 // nodes. However that proved to be insufficient. Hence the 30 second default wait in the lines above.
                 // TODO Instead of the 30 second wait, we should look (and then wait) for some trigger or event that signifies that local handling has completed and caches have stabilized.
                 waitForClusterCacheToBeInstalled();
 
                 // Let the other nodes know that we joined the cluster
                 logger.debug("Done joining the cluster in split brain recovery. Now proceed informing other nodes that we joined the cluster.");
                 CacheFactory.doClusterTask(new NewClusterMemberJoinedTask());
             }
         }
         clusterNodesInfo.put(nodeID,
                 new HazelcastClusterNodeInfo(event.getMember(), cluster.getClusterTime()));
     }
 
     /**
      * Blocks the current thread until the cluster cache is guaranteed to support clustering. This is especially useful
      * for executing cluster tasks immediately after joining. If this wait is not performed, the cache factory may still
      * be using the 'default' strategy instead of the 'hazelcast' strategy, which leads to cluster tasks being silently
      * discarded.
      *
      * The method will keep trying this for 10 minutes. After that the thread is released regardless of the result.
      *
      * @return Boolean indicating whether the clustered cache was actually observed to be installed.
      */
     private boolean waitForClusterCacheToBeInstalled() {
         boolean failed = false;
         if (!ClusteredCacheFactory.PLUGIN_NAME.equals(CacheFactory.getPluginName())) {
             logger.debug("This node now joined a cluster, but the cache factory has not been swapped to '{}' yet. Waiting for that to happen.", ClusteredCacheFactory.PLUGIN_NAME);
             LocalTime deadLine = LocalTime.now().plusMinutes(10L);
             while (!ClusteredCacheFactory.PLUGIN_NAME.equals(CacheFactory.getPluginName()) && deadLine.isAfter(LocalTime.now())) {
                 try {
                     Thread.sleep(200);
                 } catch (InterruptedException e) {
                     logger.trace("Thread was interrupted while waiting for cache strategy to change.");
                     failed = true;
                     break;
                 }
             }
             if (!deadLine.isAfter(LocalTime.now())) {
                 failed = true;
                 logger.warn("Cache factory was not swapped to '{}', but still remains '{}' after a 10 minute wait. Cluster join is not guaranteed to have completed.", ClusteredCacheFactory.PLUGIN_NAME, CacheFactory.getPluginName());
             }
             logger.debug("Cache factory has been swapped to '{}'. Cluster join is considered complete.", ClusteredCacheFactory.PLUGIN_NAME);
         }
 
         return !failed;
     }
 
     @Override
     public void memberRemoved(final MembershipEvent event) {
         logger.info("Received a Hazelcast memberRemoved event {}", event);
 
         isSenior = isSeniorClusterMember();
         final NodeID nodeID = ClusteredCacheFactory.getNodeID(event.getMember());
 
         if (event.getMember().localMember()) {
             logger.info("Leaving cluster: " + nodeID);
             // This node may have realized that it got kicked out of the cluster
             leaveCluster();
         } else {
             // Trigger event that a node left the cluster
             ClusterManager.fireLeftCluster(nodeID.toByteArray());
 
             if (!seniorClusterMember && isSeniorClusterMember()) {
                 seniorClusterMember = true;
                 ClusterManager.fireMarkedAsSeniorClusterMember();
             }
 
             // Remove traces of directed presences sent from local entities to handlers that no longer exist.
             // At this point c2s sessions are gone from the routing table so we can identify expired sessions
             XMPPServer.getInstance().getPresenceUpdateHandler().removedExpiredPresences();
         }
         // Delete nodeID instance (release from memory)
         NodeID.deleteInstance(nodeID.toByteArray());
         clusterNodesInfo.remove(nodeID);
     }
     
     @SuppressWarnings("WeakerAccess")
     public List<ClusterNodeInfo> getClusterNodesInfo() {
         return new ArrayList<>(clusterNodesInfo.values());
     }
 
     @Override
     public void stateChanged(final LifecycleEvent event) {
         if (event.getState().equals(LifecycleState.SHUTDOWN)) {
             leaveCluster();
         } else if (event.getState().equals(LifecycleState.STARTED)) {
             joinCluster();
         }
     }
 
     @Override
     public void memberAttributeChanged(final MemberAttributeEvent event) {
         logger.info("Received a Hazelcast memberAttributeChanged event {}", event);
         isSenior = isSeniorClusterMember();
         final ClusterNodeInfo priorNodeInfo = clusterNodesInfo.get(ClusteredCacheFactory.getNodeID(event.getMember()));
         clusterNodesInfo.put(ClusteredCacheFactory.getNodeID(event.getMember()),
                 new HazelcastClusterNodeInfo(event.getMember(), priorNodeInfo.getJoinedTime()));
     }
 
     boolean isClusterMember() {
         return clusterMember;
     }
 }
--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java
+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java
@@ -20,7 +20,7 @@
 import com.hazelcast.core.EntryEvent;
 import com.hazelcast.core.EntryListener;
-import com.hazelcast.core.IMap;
-import com.hazelcast.core.MapEvent;
+import com.hazelcast.map.IMap;
+import com.hazelcast.map.MapEvent;
 import com.hazelcast.map.listener.MapListener;
-import com.hazelcast.monitor.LocalMapStats;
+import com.hazelcast.map.LocalMapStats;
 import org.jivesoftware.openfire.XMPPServer;
 import org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;
 import org.jivesoftware.openfire.cluster.NodeID;
```
Tool Calls:
  compile_maven_stateful (Q83ITC7BZ)
 Call ID: Q83ITC7BZ
  Args:
    diff: ```diff
--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java
+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java
@@ -22,7 +22,6 @@
 import com.hazelcast.config.MapConfig;
-import com.hazelcast.config.MaxSizeConfig;
 import com.hazelcast.config.MemberAttributeConfig;
 import com.hazelcast.config.MemcacheProtocolConfig;
 import com.hazelcast.config.NetworkConfig;
@@ -27,7 +26,6 @@
 import com.hazelcast.config.RestApiConfig;
-import com.hazelcast.core.Cluster;
 import com.hazelcast.core.Hazelcast;
 import com.hazelcast.core.HazelcastInstance;
-import com.hazelcast.core.Member;
@@ -149,7 +147,6 @@
     private static HazelcastInstance hazelcast = null;
-    private static Cluster cluster = null;
     private ClusterListener clusterListener;
     private String lifecycleListener;
     private String membershipListener;
@@ -201,7 +198,7 @@
                 }
                 hazelcast = Hazelcast.newHazelcastInstance(config);
-                cluster = hazelcast.getCluster();
+                Cluster cluster = hazelcast.getCluster();
                 state = State.started;
                 // CacheFactory is now using clustered caches. We can add our listeners.
                 clusterListener = new ClusterListener(cluster);
@@ -501,7 +498,7 @@
     public byte[] getSeniorClusterMemberID() {
-        if (cluster != null && !cluster.getMembers().isEmpty()) {
-            final Member oldest = cluster.getMembers().iterator().next();
+        Cluster cluster = hazelcast.getCluster();
+        if (cluster != null && !cluster.getMembers().isEmpty()) {
+            final com.hazelcast.cluster.Member oldest = cluster.getMembers().iterator().next();
             return getNodeID(oldest).toByteArray();
         } else {
             return null;
@@ -655,7 +652,7 @@
     public byte[] getClusterMemberID() {
-        if (cluster != null) {
+        Cluster cluster = hazelcast.getCluster();
+        if (cluster != null) {
             return getNodeID(cluster.getLocalMember()).toByteArray();
         } else {
             return null;
@@ -688,7 +685,7 @@
     @Override
     public long getClusterTime() {
-        return cluster == null ? System.currentTimeMillis() : cluster.getClusterTime();
+        Cluster cluster = hazelcast.getCluster();
+        return cluster == null ? System.currentTimeMillis() : cluster.getClusterTime();
     }
 
@@ -727,7 +724,7 @@
         if (cluster == null) {
             return;
         }
-        final Set<Member> members = new HashSet<>();
-        final Member current = cluster.getLocalMember();
-        for (final Member member : cluster.getMembers()) {
+        final Set<com.hazelcast.cluster.Member> members = new HashSet<>();
+        final com.hazelcast.cluster.Member current = cluster.getLocalMember();
+        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {
             if (!member.getUuid().equals(current.getUuid())) {
                 members.add(member);
             }
@@ -754,7 +751,7 @@
         if (cluster == null) {
             return;
         }
-        final Member member = getMember(nodeID);
+        final com.hazelcast.cluster.Member member = getMember(nodeID);
         // Check that the requested member was found
         if (member != null) {
             // Asynchronously execute the task on the target member
@@ -783,7 +780,7 @@
         if (cluster == null) {
             return Collections.emptyList();
         }
-        final Set<Member> members = new HashSet<>();
-        final Member current = cluster.getLocalMember();
-        for (final Member member : cluster.getMembers()) {
+        final Set<com.hazelcast.cluster.Member> members = new HashSet<>();
+        final com.hazelcast.cluster.Member current = cluster.getLocalMember();
+        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {
             if (includeLocalMember || (!member.getUuid().equals(current.getUuid()))) {
                 members.add(member);
             }
@@ -819,7 +816,7 @@
         if (cluster == null) {
             return null;
         }
-        final Member member = getMember(nodeID);
+        final com.hazelcast.cluster.Member member = getMember(nodeID);
         T result = null;
         // Check that the requested member was found
         if (member != null) {
@@ -841,7 +838,7 @@
         if (cluster == null) {
             return null;
         }
-        final Member member = getMember(nodeID);
+        final com.hazelcast.cluster.Member member = getMember(nodeID);
         if (member != null) {
             result = new HazelcastClusterNodeInfo(member, cluster.getClusterTime());
         }
@@ -850,7 +847,7 @@
     }
 
     private Member getMember(final byte[] nodeID) {
         final NodeID memberToFind = NodeID.getInstance(nodeID);
-        for (final Member member : cluster.getMembers()) {
+        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {
             if (memberToFind.equals(getNodeID(member))) {
                 return member;
             }
@@ -1007,7 +1004,7 @@
     }
 
     public static NodeID getNodeID(final Member member) {
-        return NodeID.getInstance(member.getStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));
+        return NodeID.getInstance(member.getAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));
     }
 
     static void fireLeftClusterAndWaitToComplete(final Duration timeout) {
--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java
+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java
@@ -18,7 +18,7 @@
 import com.hazelcast.core.Cluster;
 import com.hazelcast.core.EntryListener;
 import com.hazelcast.core.LifecycleEvent;
 import com.hazelcast.core.LifecycleEvent.LifecycleState;
 import com.hazelcast.core.LifecycleListener;
-import com.hazelcast.core.Member;
-import com.hazelcast.core.MemberAttributeEvent;
-import com.hazelcast.core.MembershipEvent;
-import com.hazelcast.core.MembershipListener;
+import com.hazelcast.cluster.Member;
+import com.hazelcast.cluster.MemberAttributeEvent;
+import com.hazelcast.cluster.MembershipEvent;
+import com.hazelcast.cluster.MembershipListener;
 import org.jivesoftware.openfire.XMPPServer;
 import org.jivesoftware.openfire.cluster.ClusterManager;
 import org.jivesoftware.openfire.cluster.ClusterNodeInfo;
 import org.jivesoftware.openfire.cluster.NodeID;
 import org.jivesoftware.openfire.muc.cluster.NewClusterMemberJoinedTask;
 import org.jivesoftware.openfire.plugin.util.cluster.HazelcastClusterNodeInfo;
 import org.jivesoftware.util.cache.Cache;
 import org.jivesoftware.util.cache.CacheFactory;
 import org.jivesoftware.util.cache.CacheWrapper;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import java.time.Duration;
 import java.time.LocalTime;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
 /**
  * ClusterListener reacts to membership changes in the cluster. It takes care of cleaning up the state
  * of the routing table and the sessions within it when a node which manages those sessions goes down.
  */
 public class ClusterListener implements MembershipListener, LifecycleListener {
 
     private static final Logger logger = LoggerFactory.getLogger(ClusterListener.class);
 
     private boolean seniorClusterMember = false;
 
     private final Map<Cache<?,?>, EntryListener> entryListeners = new HashMap<>();
     
     private final Cluster cluster;
     private final Map<NodeID, ClusterNodeInfo> clusterNodesInfo = new ConcurrentHashMap<>();
     
     /**
      * Flag that indicates if the listener has done all clean up work when noticed that the
      * cluster has been stopped. This will force Openfire to wait until all clean
      * up (e.g. changing caches implementations) is done before destroying the plugin.
      */
     private boolean done = true;
     /**
      * Flag that indicates if we've joined a cluster or not
      */
     private boolean clusterMember = false;
     private boolean isSenior;
 
     ClusterListener(final Cluster cluster) {
 
         this.cluster = cluster;
         for (final Member member : cluster.getMembers()) {
             clusterNodesInfo.put(ClusteredCacheFactory.getNodeID(member),
                     new HazelcastClusterNodeInfo(member, cluster.getClusterTime()));
         }
     }
 
     private void addEntryListener(final Cache<?, ?> cache, final EntryListener listener) {
         if (cache instanceof CacheWrapper) {
             final Cache wrapped = ((CacheWrapper)cache).getWrappedCache();
             if (wrapped instanceof ClusteredCache) {
                 ((ClusteredCache)wrapped).addEntryListener(listener);
                 // Keep track of the listener that we added to the cache
                 entryListeners.put(cache, listener);
             }
         }
     }
 
     @SuppressWarnings("unchecked")
     private boolean isDone() {
         return done;
     }
 
     synchronized void joinCluster() {
         if (!isDone()) { // already joined
             return;
         }
 
         // Trigger events
         clusterMember = true;
         seniorClusterMember = isSeniorClusterMember();
 
         ClusterManager.fireJoinedCluster(false);
 
         if (seniorClusterMember) {
             ClusterManager.fireMarkedAsSeniorClusterMember();
         }
 
         waitForClusterCacheToBeInstalled();
 
         // Let the other nodes know that we joined the cluster
         logger.debug("Done joining the cluster. Now proceed informing other nodes that we joined the cluster.");
         CacheFactory.doClusterTask(new NewClusterMemberJoinedTask());
 
         logger.info("Joined cluster. XMPPServer node={}, Hazelcast UUID={}, seniorClusterMember={}",
             new Object[]{ClusteredCacheFactory.getNodeID(cluster.getLocalMember()), cluster.getLocalMember().getUuid(), seniorClusterMember});
         done = false;
     }
 
     boolean isSeniorClusterMember() {
         // first cluster member is the oldest
         final Iterator<Member> members = cluster.getMembers().iterator();
         return members.next().getUuid().equals(cluster.getLocalMember().getUuid());
     }
 
     private synchronized void leaveCluster() {
         if (isDone()) { // not a cluster member
             return;
         }
         clusterMember = false;
         final boolean wasSeniorClusterMember = seniorClusterMember;
         seniorClusterMember = false;
 
         // Trigger event. Wait until the listeners have processed the event. Caches will be populated
         // again with local content.
         ClusterManager.fireLeftCluster();
 
         if (!XMPPServer.getInstance().isShuttingDown()) {
             // Remove traces of directed presences sent from local entities to handlers that no longer exist
             // At this point c2s sessions are gone from the routing table so we can identify expired sessions
             XMPPServer.getInstance().getPresenceUpdateHandler().removedExpiredPresences();
         }
         logger.info("Left cluster. XMPPServer node={}, Hazelcast UUID={}, wasSeniorClusterMember={}",
             new Object[]{ClusteredCacheFactory.getNodeID(cluster.getLocalMember()), cluster.getLocalMember().getUuid(), wasSeniorClusterMember});
         done = true;
     }
 
     @Override
     public void memberAdded(final MembershipEvent event) {
         logger.info("Received a Hazelcast memberAdded event {}", event);
 
         final boolean wasSenior = isSenior;
         isSenior = isSeniorClusterMember();
         // local member only
         final NodeID nodeID = ClusteredCacheFactory.getNodeID(event.getMember());
         if (event.getMember().localMember()) { // We left and re-joined the cluster
             joinCluster();
 
         } else {
             if (wasSenior && !isSenior) {
                 logger.warn("Recovering from split-brain; firing leftCluster()/joinedCluster() events");
                 ClusteredCacheFactory.fireLeftClusterAndWaitToComplete(Duration.ofSeconds(30));
                 logger.debug("Firing joinedCluster() event");
                 ClusterManager.fireJoinedCluster(false);
 
                 try {
                     logger.debug("Postponing notification of other nodes for 30 seconds. This allows all local leave/join processing to be finished and local cache backups to be stabilized before receiving events from other nodes.");
                     Thread.sleep(30000L);
                 } catch (InterruptedException e) {
                     logger.warn("30 Second wait was interrupted.", e);
                 }
 
                 // The following line was intended to wait until all local handling finishes before informing other
                 // nodes. However that proved to be insufficient. Hence the 30 second default wait in the lines above.
                 // TODO Instead of the 30 second wait, we should look (and then wait) for some trigger or event that signifies that local handling has completed and caches have stabilized.
                 waitForClusterCacheToBeInstalled();
 
                 // Let the other nodes know that we joined the cluster
                 logger.debug("Done joining the cluster in split brain recovery. Now proceed informing other nodes that we joined the cluster.");
                 CacheFactory.doClusterTask(new NewClusterMemberJoinedTask());
             }
         }
         clusterNodesInfo.put(nodeID,
                 new HazelcastClusterNodeInfo(event.getMember(), cluster.getClusterTime()));
     }
 
     /**
      * Blocks the current thread until the cluster cache is guaranteed to support clustering. This is especially useful
      * for executing cluster tasks immediately after joining. If this wait is not performed, the cache factory may still
      * be using the 'default' strategy instead of the 'hazelcast' strategy, which leads to cluster tasks being silently
      * discarded.
      *
      * The method will keep trying this for 10 minutes. After that the thread is released regardless of the result.
      *
      * @return Boolean indicating whether the clustered cache was actually observed to be installed.
      */
     private boolean waitForClusterCacheToBeInstalled() {
         boolean failed = false;
         if (!ClusteredCacheFactory.PLUGIN_NAME.equals(CacheFactory.getPluginName())) {
             logger.debug("This node now joined a cluster, but the cache factory has not been swapped to '{}' yet. Waiting for that to happen.", ClusteredCacheFactory.PLUGIN_NAME);
             LocalTime deadLine = LocalTime.now().plusMinutes(10L);
             while (!ClusteredCacheFactory.PLUGIN_NAME.equals(CacheFactory.getPluginName()) && deadLine.isAfter(LocalTime.now())) {
                 try {
                     Thread.sleep(200);
                 } catch (InterruptedException e) {
                     logger.trace("Thread was interrupted while waiting for cache strategy to change.");
                     failed = true;
                     break;
                 }
             }
             if (!deadLine.isAfter(LocalTime.now())) {
                 failed = true;
                 logger.warn("Cache factory was not swapped to '{}', but still remains '{}' after a 10 minute wait. Cluster join is not guaranteed to have completed.", ClusteredCacheFactory.PLUGIN_NAME, CacheFactory.getPluginName());
             }
             logger.debug("Cache factory has been swapped to '{}'. Cluster join is considered complete.", ClusteredCacheFactory.PLUGIN_NAME);
         }
 
         return !failed;
     }
 
     @Override
     public void memberRemoved(final MembershipEvent event) {
         logger.info("Received a Hazelcast memberRemoved event {}", event);
 
         isSenior = isSeniorClusterMember();
         final NodeID nodeID = ClusteredCacheFactory.getNodeID(event.getMember());
 
         if (event.getMember().localMember()) {
             logger.info("Leaving cluster: " + nodeID);
             // This node may have realized that it got kicked out of the cluster
             leaveCluster();
         } else {
             // Trigger event that a node left the cluster
             ClusterManager.fireLeftCluster(nodeID.toByteArray());
 
             if (!seniorClusterMember && isSeniorClusterMember()) {
                 seniorClusterMember = true;
                 ClusterManager.fireMarkedAsSeniorClusterMember();
             }
 
             // Remove traces of directed presences sent from local entities to handlers that no longer exist.
             // At this point c2s sessions are gone from the routing table so we can identify expired sessions
             XMPPServer.getInstance().getPresenceUpdateHandler().removedExpiredPresences();
         }
         // Delete nodeID instance (release from memory)
         NodeID.deleteInstance(nodeID.toByteArray());
         clusterNodesInfo.remove(nodeID);
     }
     
     @SuppressWarnings("WeakerAccess")
     public List<ClusterNodeInfo> getClusterNodesInfo() {
         return new ArrayList<>(clusterNodesInfo.values());
     }
 
     @Override
     public void stateChanged(final LifecycleEvent event) {
         if (event.getState().equals(LifecycleState.SHUTDOWN)) {
             leaveCluster();
         } else if (event.getState().equals(LifecycleState.STARTED)) {
             joinCluster();
         }
     }
 
     @Override
     public void memberAttributeChanged(final MemberAttributeEvent event) {
         logger.info("Received a Hazelcast memberAttributeChanged event {}", event);
         isSenior = isSeniorClusterMember();
         final ClusterNodeInfo priorNodeInfo = clusterNodesInfo.get(ClusteredCacheFactory.getNodeID(event.getMember()));
         clusterNodesInfo.put(ClusteredCacheFactory.getNodeID(event.getMember()),
                 new HazelcastClusterNodeInfo(event.getMember(), priorNodeInfo.getJoinedTime()));
     }
 
     boolean isClusterMember() {
         return clusterMember;
     }
 }
--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java
+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java
@@ -20,7 +20,7 @@
 import com.hazelcast.core.EntryEvent;
 import com.hazelcast.core.EntryListener;
-import com.hazelcast.core.IMap;
-import com.hazelcast.core.MapEvent;
+import com.hazelcast.map.IMap;
+import com.hazelcast.map.MapEvent;
 import com.hazelcast.map.listener.MapListener;
-import com.hazelcast.monitor.LocalMapStats;
+import com.hazelcast.map.LocalMapStats;
 import org.jivesoftware.openfire.XMPPServer;
 import org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;
 import org.jivesoftware.openfire.cluster.NodeID;
```
Invalid Tool Calls:
  validate_diffs (call_04xQpaHCncGtjrl5he5Ejg4w)
 Call ID: call_04xQpaHCncGtjrl5he5Ejg4w
  Error: Function validate_diffs arguments:

{"diff":"```diff\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java\n@@ -22,7 +22,6 @@\n import com.hazelcast.config.MapConfig;\n-import com.hazelcast.config.MaxSizeConfig;\n import com.hazelcast.config.MemberAttributeConfig;\n import com.hazelcast.config.MemcacheProtocolConfig;\n import com.hazelcast.config.NetworkConfig;\n@@ -27,7 +26,6 @@\n import com.hazelcast.config.RestApiConfig;\n-import com.hazelcast.core.Cluster;\n import com.hazelcast.core.Hazelcast;\n import com.hazelcast.core.HazelcastInstance;\n-import com.hazel

are not valid JSON. Received JSONDecodeError Unterminated string starting at: line 1 column 9 (char 8)
  Args:
    {"diff":"```diff\n--- src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java\n+++ src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java\n@@ -22,7 +22,6 @@\n import com.hazelcast.config.MapConfig;\n-import com.hazelcast.config.MaxSizeConfig;\n import com.hazelcast.config.MemberAttributeConfig;\n import com.hazelcast.config.MemcacheProtocolConfig;\n import com.hazelcast.config.NetworkConfig;\n@@ -27,7 +26,6 @@\n import com.hazelcast.config.RestApiConfig;\n-import com.hazelcast.core.Cluster;\n import com.hazelcast.core.Hazelcast;\n import com.hazelcast.core.HazelcastInstance;\n-import com.hazel

================================= Tool Message =================================
Name: compile_maven_stateful

{"compilation_has_succeeded": false, "test_has_succeeded": false, "error_text": "incompatible types: invalid method reference\n", "updated_files": {"src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java": "/*\n * Copyright (C) 2007-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.config.ClasspathXmlConfig;\nimport com.hazelcast.config.Config;\nimport com.hazelcast.config.MapConfig;\nimport com.hazelcast.config.MemberAttributeConfig;\nimport com.hazelcast.config.MemcacheProtocolConfig;\nimport com.hazelcast.config.NetworkConfig;\nimport com.hazelcast.config.RestApiConfig;\nimport com.hazelcast.core.Hazelcast;\nimport com.hazelcast.core.HazelcastInstance;\nimport org.jivesoftware.openfire.JMXManager;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusterEventListener;\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.plugin.HazelcastPlugin;\nimport org.jivesoftware.openfire.plugin.util.cluster.HazelcastClusterNodeInfo;\nimport org.jivesoftware.util.StringUtils;\nimport org.jivesoftware.util.SystemProperty;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.jivesoftware.util.cache.CacheFactoryStrategy;\nimport org.jivesoftware.util.cache.CacheWrapper;\nimport org.jivesoftware.util.cache.ClusterTask;\nimport org.jivesoftware.util.cache.ExternalizableUtil;\nimport org.jivesoftware.util.cache.ExternalizableUtilStrategy;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.Serializable;\nimport java.nio.charset.StandardCharsets;\nimport java.text.MessageFormat;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.time.temporal.ChronoUnit;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.Callable;\nimport java.util.concurrent.Future;\nimport java.util.concurrent.Semaphore;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.TimeoutException;\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\n\n/**\n * CacheFactory implementation to use when using Hazelcast in cluster mode.\n *\n * @author Tom Evans\n * @author Gaston Dombiak\n */\npublic class ClusteredCacheFactory implements CacheFactoryStrategy {\n\n    private static final SystemProperty<String> HAZELCAST_EXECUTOR_SERVICE_NAME = SystemProperty.Builder.ofType(String.class)\n        .setKey(\"hazelcast.executor.service.name\")\n        .setDefaultValue(\"openfire::cluster::executor\")\n        .setDynamic(false)\n        .setPlugin(HazelcastPlugin.PLUGIN_NAME)\n        .build();\n    private static final SystemProperty<Duration> MAX_CLUSTER_EXECUTION_TIME = SystemProperty.Builder.ofType(Duration.class)\n        .setKey(\"hazelcast.max.execution.seconds\")\n        .setDefaultValue(Duration.ofSeconds(30))\n        .setChronoUnit(ChronoUnit.SECONDS)\n        .setDynamic(true)\n        .setPlugin(HazelcastPlugin.PLUGIN_NAME)\n        .build();\n    private static final SystemProperty<Duration> CLUSTER_STARTUP_RETRY_TIME = SystemProperty.Builder.ofType(Duration.class)\n        .setKey(\"hazelcast.startup.retry.seconds\")\n        .setDefaultValue(Duration.ofSeconds(10))\n        .setChronoUnit(ChronoUnit.SECONDS)\n        .setDynamic(true)\n        .setPlugin(HazelcastPlugin.PLUGIN_NAME)\n        .build();\n    private static final SystemProperty<Integer> CLUSTER_STARTUP_RETRY_COUNT = SystemProperty.Builder.ofType(Integer.class)\n        .setKey(\"hazelcast.startup.retry.count\")\n        .setDefaultValue(1)\n        .setDynamic(true)\n        .setPlugin(HazelcastPlugin.PLUGIN_NAME)\n        .build();\n    private static final SystemProperty<String> HAZELCAST_CONFIG_FILE = SystemProperty.Builder.ofType(String.class)\n        .setKey(\"hazelcast.config.xml.filename\")\n        .setDefaultValue(\"hazelcast-cache-config.xml\")\n        .setDynamic(false)\n        .setPlugin(HazelcastPlugin.PLUGIN_NAME)\n        .build();\n    private static final SystemProperty<Boolean> HAZELCAST_JMX_ENABLED = SystemProperty.Builder.ofType(Boolean.class)\n        .setKey(\"hazelcast.config.jmx.enabled\")\n        .setDefaultValue(Boolean.FALSE)\n        .setDynamic(false)\n        .setPlugin(HazelcastPlugin.PLUGIN_NAME)\n        .build();\n    private static final SystemProperty<Boolean> HAZELCAST_REST_ENABLED = SystemProperty.Builder.ofType(Boolean.class)\n        .setKey(\"hazelcast.config.rest.enabled\")\n        .setDefaultValue(Boolean.FALSE)\n        .setDynamic(false)\n        .setPlugin(HazelcastPlugin.PLUGIN_NAME)\n        .build();\n    private static final SystemProperty<Boolean> HAZELCAST_MEMCACHE_ENABLED = SystemProperty.Builder.ofType(Boolean.class)\n        .setKey(\"hazelcast.config.memcache.enabled\")\n        .setDefaultValue(Boolean.FALSE)\n        .setDynamic(false)\n        .setPlugin(HazelcastPlugin.PLUGIN_NAME)\n        .build();\n\n    private static final Logger logger = LoggerFactory.getLogger(ClusteredCacheFactory.class);\n    public static final String PLUGIN_NAME = \"hazelcast\";\n\n    /**\n     * Keep serialization strategy the server was using before we set our strategy. We will\n     * restore old strategy when plugin is unloaded.\n     */\n    private ExternalizableUtilStrategy serializationStrategy;\n\n    /**\n     * Storage for cache statistics\n     */\n    private static Map<String, Map<String, long[]>> cacheStats;\n\n    private static HazelcastInstance hazelcast = null;\n    private ClusterListener clusterListener;\n    private String lifecycleListener;\n    private String membershipListener;\n\n    /**\n     * Keeps that running state. Initial state is stopped.\n     */\n    private State state = State.stopped;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private final Cache<String, Instant> pluginClassLoaderWarnings;\n\n    public ClusteredCacheFactory() {\n        pluginClassLoaderWarnings = CacheFactory.createLocalCache(\"PluginClassLoader Warnings for Clustered Tasks\");\n        pluginClassLoaderWarnings.setMaxLifetime(Duration.ofHours(1).toMillis()); // Minimum duration between logged warnings.\n    }\n\n    @Override\n    public boolean startCluster() {\n        logger.info(\"Starting hazelcast clustering\");\n        state = State.starting;\n\n        // Set the serialization strategy to use for transmitting objects between node clusters\n        serializationStrategy = ExternalizableUtil.getInstance().getStrategy();\n        ExternalizableUtil.getInstance().setStrategy(new ClusterExternalizableUtil());\n\n        // Store previous class loader (in case we change it)\n        final ClassLoader oldLoader = Thread.currentThread().getContextClassLoader();\n        final ClassLoader loader = new ClusterClassLoader();\n        Thread.currentThread().setContextClassLoader(loader);\n        int retry = 0;\n        do {\n            try {\n                final Config config = new ClasspathXmlConfig(HAZELCAST_CONFIG_FILE.getValue());\n                final NetworkConfig networkConfig = config.getNetworkConfig();\n                if (!HAZELCAST_MEMCACHE_ENABLED.getValue()) {\n                    networkConfig.setMemcacheProtocolConfig(new MemcacheProtocolConfig().setEnabled(false));\n                }\n                if (!HAZELCAST_REST_ENABLED.getValue()) {\n                    networkConfig.setRestApiConfig(new RestApiConfig().setEnabled(false));\n                }\n                final MemberAttributeConfig memberAttributeConfig = config.getMemberAttributeConfig();\n                memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.HOST_NAME_ATTRIBUTE, XMPPServer.getInstance().getServerInfo().getHostname());\n                memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE, XMPPServer.getInstance().getNodeID().toString());\n                config.setInstanceName(\"openfire\");\n                config.setClassLoader(loader);\n                if (JMXManager.isEnabled() && HAZELCAST_JMX_ENABLED.getValue()) {\n                    config.setProperty(\"hazelcast.jmx\", \"true\");\n                    config.setProperty(\"hazelcast.jmx.detailed\", \"true\");\n                }\n                hazelcast = Hazelcast.newHazelcastInstance(config);\n                Cluster cluster = hazelcast.getCluster();\n                state = State.started;\n                // CacheFactory is now using clustered caches. We can add our listeners.\n                clusterListener = new ClusterListener(cluster);\n                clusterListener.joinCluster();\n                lifecycleListener = hazelcast.getLifecycleService().addLifecycleListener(clusterListener);\n                membershipListener = cluster.addMembershipListener(clusterListener);\n                logger.info(\"Hazelcast clustering started\");\n                break;\n            } catch (final Exception e) {\n                cluster = null;\n                if (retry < CLUSTER_STARTUP_RETRY_COUNT.getValue()) {\n                    logger.warn(\"Failed to start clustering (\" + e.getMessage() + \"); \" +\n                        \"will retry in \" + StringUtils.getFullElapsedTime(CLUSTER_STARTUP_RETRY_TIME.getValue()));\n                    try {\n                        Thread.sleep(CLUSTER_STARTUP_RETRY_TIME.getValue().toMillis());\n                    } catch (final InterruptedException ignored) {\n                        Thread.currentThread().interrupt();\n                    }\n                } else {\n                    logger.error(\"Unable to start clustering - continuing in local mode\", e);\n                    state = State.stopped;\n                }\n            }\n        } while (retry++ < CLUSTER_STARTUP_RETRY_COUNT.getValue() && !Thread.currentThread().isInterrupted());\n\n        if (oldLoader != null) {\n            // Restore previous class loader\n            Thread.currentThread().setContextClassLoader(oldLoader);\n        }\n        return cluster != null;\n    }\n\n    @Override\n    public void stopCluster() {\n        // Stop the cache services.\n        cacheStats = null;\n        // Update the running state of the cluster\n        state = State.stopped;\n\n        // Fire the leftClusterEvent before we leave the cluster - we need to access the clustered data before the\n        // cluster is shutdown so it can be copied in to the non-clustered, DefaultCache\n        fireLeftClusterAndWaitToComplete(Duration.ofSeconds(30));\n        // Stop the cluster\n        hazelcast.getLifecycleService().removeLifecycleListener(lifecycleListener);\n        cluster.removeMembershipListener(membershipListener);\n        Hazelcast.shutdownAll();\n        cluster = null;\n        lifecycleListener = null;\n        membershipListener = null;\n        clusterListener = null;\n\n        // Reset packet router to use to deliver packets to remote cluster nodes\n        XMPPServer.getInstance().getRoutingTable().setRemotePacketRouter(null);\n        // Reset the session locator to use\n        XMPPServer.getInstance().setRemoteSessionLocator(null);\n        // Set the old serialization strategy was using before clustering was loaded\n        ExternalizableUtil.getInstance().setStrategy(serializationStrategy);\n    }\n\n    @Override\n    public Cache createCache(final String name) {\n        // Check if cluster is being started up\n        while (state == State.starting) {\n            // Wait until cluster is fully started (or failed)\n            try {\n                Thread.sleep(250);\n            } catch (final InterruptedException e) {\n                // Ignore\n            }\n        }\n        if (state == State.stopped) {\n            throw new IllegalStateException(\"Cannot create clustered cache when not in a cluster\");\n        }\n        // Determine the time to live. Note that in Hazelcast 0 means \"forever\", not -1\n        final long openfireLifetimeInMilliseconds = CacheFactory.getMaxCacheLifetime(name);\n        final int hazelcastLifetimeInSeconds = openfireLifetimeInMilliseconds < 0 ? 0 : Math.max((int) (openfireLifetimeInMilliseconds / 1000), 1);\n        // Determine the max cache size. Note that in Hazelcast the max cache size must be positive and is in megabytes\n        final long openfireMaxCacheSizeInBytes = CacheFactory.getMaxCacheSize(name);\n        final int hazelcastMaxCacheSizeInMegaBytes = openfireMaxCacheSizeInBytes < 0 ? Integer.MAX_VALUE : Math.max((int) openfireMaxCacheSizeInBytes / 1024 / 1024, 1);\n        // It's only possible to create a dynamic config if a static one doesn't already exist\n        final MapConfig staticConfig = hazelcast.getConfig().getMapConfigOrNull(name);\n        if (staticConfig == null) {\n            final MapConfig dynamicConfig = new MapConfig(name);\n            dynamicConfig.setTimeToLiveSeconds(hazelcastLifetimeInSeconds);\n            dynamicConfig.setMaxSizeConfig(new MaxSizeConfig(hazelcastMaxCacheSizeInMegaBytes, MaxSizeConfig.MaxSizePolicy.USED_HEAP_SIZE));\n            logger.debug(\"Creating dynamic map config for cache={}, dynamicConfig={}\", name, dynamicConfig);\n            hazelcast.getConfig().addMapConfig(dynamicConfig);\n        } else {\n            logger.debug(\"Static configuration already exists for cache={}, staticConfig={}\", name, staticConfig);\n        }\n        // TODO: Better genericize this method in CacheFactoryStrategy so we can stop suppressing this warning\n        @SuppressWarnings(\"unchecked\") final ClusteredCache clusteredCache = new ClusteredCache(name, hazelcast.getMap(name));\n        return clusteredCache;\n    }\n\n    @Override\n    public void destroyCache(Cache cache) {\n        if (cache instanceof CacheWrapper) {\n            cache = ((CacheWrapper) cache).getWrappedCache();\n        }\n\n        final ClusteredCache clustered = (ClusteredCache) cache;\n        clustered.destroy();\n    }\n\n    @Override\n    public boolean isSeniorClusterMember() {\n        if (clusterListener == null || !clusterListener.isClusterMember()) {\n            return false;\n        }\n        return clusterListener.isSeniorClusterMember();\n    }\n\n    @Override\n    public List<ClusterNodeInfo> getClusterNodesInfo() {\n        return clusterListener == null ? Collections.emptyList() : clusterListener.getClusterNodesInfo();\n    }\n\n    @Override\n    public int getMaxClusterNodes() {\n        // No longer depends on license code so just return a big number\n        return 10000;\n    }\n\n    @Override\n    public byte[] getSeniorClusterMemberID() {\n        Cluster cluster = hazelcast.getCluster();\n        if (cluster != null && !cluster.getMembers().isEmpty()) {\n            final com.hazelcast.cluster.Member oldest = cluster.getMembers().iterator().next();\n            return getNodeID(oldest).toByteArray();\n        } else {\n            return null;\n        }\n    }\n\n    @Override\n    public byte[] getClusterMemberID() {\n        Cluster cluster = hazelcast.getCluster();\n        if (cluster != null) {\n            return getNodeID(cluster.getLocalMember()).toByteArray();\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Gets the pseudo-synchronized time from the cluster. While the cluster members may\n     * have varying system times, this method is expected to return a timestamp that is\n     * synchronized (or nearly so; best effort) across the cluster.\n     *\n     * @return Synchronized time for all cluster members\n     */\n    @Override\n    public long getClusterTime() {\n        Cluster cluster = hazelcast.getCluster();\n        return cluster == null ? System.currentTimeMillis() : cluster.getClusterTime();\n    }\n\n    /*\n     * Execute the given task on the other (non-local) cluster members.\n     * Note that this method does not provide the result set for the given\n     * task, as the task is run asynchronously across the cluster.\n     */\n    @Override\n    public void doClusterTask(final ClusterTask<?> task) {\n\n        if (cluster == null) {\n            return;\n        }\n        final Set<com.hazelcast.cluster.Member> members = new HashSet<>();\n        final com.hazelcast.cluster.Member current = cluster.getLocalMember();\n        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {\n            if (!member.getUuid().equals(current.getUuid())) {\n                members.add(member);\n            }\n        }\n\n\n        if (!members.isEmpty()) {\n            // Asynchronously execute the task on the other cluster members\n            logger.debug(\"Executing asynchronous MultiTask: \" + task.getClass().getName());\n            checkForPluginClassLoader(task);\n            hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMembers(new CallableTask<>(task), members);\n        } else {\n            logger.debug(\"No cluster members selected for cluster task \" + task.getClass().getName());\n        }\n    }\n\n    /*\n     * Execute the given task on the given cluster member.\n     * Note that this method does not provide the result set for the given\n     * task, as the task is run asynchronously across the cluster.\n     */\n    @Override\n    public void doClusterTask(final ClusterTask<?> task, final byte[] nodeID) {\n        if (cluster == null) {\n            return;\n        }\n        final com.hazelcast.cluster.Member member = getMember(nodeID);\n        // Check that the requested member was found\n        if (member != null) {\n            // Asynchronously execute the task on the target member\n            logger.debug(\"Executing asynchronous DistributedTask: \" + task.getClass().getName());\n            checkForPluginClassLoader(task);\n            hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMember(new CallableTask<>(task), member);\n        } else {\n            final String msg = MessageFormat.format(\"Requested node {0} not found in cluster\", new String(nodeID, StandardCharsets.UTF_8));\n            logger.warn(msg);\n            throw new IllegalArgumentException(msg);\n        }\n    }\n\n    /*\n     * Execute the given task on the designated cluster members.\n     * Note that this method blocks for up to MAX_CLUSTER_EXECUTION_TIME\n     * (seconds) per member until the task is run on all members.\n     */\n    @Override\n    public <T> Collection<T> doSynchronousClusterTask(final ClusterTask<T> task, final boolean includeLocalMember) {\n        if (cluster == null) {\n            return Collections.emptyList();\n        }\n        final Set<com.hazelcast.cluster.Member> members = new HashSet<>();\n        final com.hazelcast.cluster.Member current = cluster.getLocalMember();\n        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {\n            if (includeLocalMember || (!member.getUuid().equals(current.getUuid()))) {\n                members.add(member);\n            }\n        }\n        final Collection<T> result = new ArrayList<>();\n        if (!members.isEmpty()) {\n            // Asynchronously execute the task on the other cluster members\n            try {\n                logger.debug(\"Executing MultiTask: \" + task.getClass().getName());\n                checkForPluginClassLoader(task);\n                final Map<Member, ? extends Future<T>> futures = hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMembers(new CallableTask<>(task), members);\n                long nanosLeft = TimeUnit.SECONDS.toNanos(MAX_CLUSTER_EXECUTION_TIME.getValue().getSeconds() * members.size());\n                for (final Future<T> future : futures.values()) {\n                    final long start = System.nanoTime();\n                    result.add(future.get(nanosLeft, TimeUnit.NANOSECONDS));\n                    nanosLeft = nanosLeft - (System.nanoTime() - start);\n                }\n            } catch (final TimeoutException te) {\n                logger.error(\"Failed to execute cluster task within \" + StringUtils.getFullElapsedTime(MAX_CLUSTER_EXECUTION_TIME.getValue()), te);\n            } catch (final Exception e) {\n                logger.error(\"Failed to execute cluster task\", e);\n            }\n        } else {\n            logger.debug(\"No cluster members selected for cluster task \" + task.getClass().getName());\n        }\n        return result;\n    }\n\n    /*\n     * Execute the given task on the designated cluster member.\n     * Note that this method blocks for up to MAX_CLUSTER_EXECUTION_TIME\n     * (seconds) until the task is run on the given member.\n     */\n    @Override\n    public <T> T doSynchronousClusterTask(final ClusterTask<T> task, final byte[] nodeID) {\n        if (cluster == null) {\n            return null;\n        }\n        final com.hazelcast.cluster.Member member = getMember(nodeID);\n        T result = null;\n        // Check that the requested member was found\n        if (member != null) {\n            // Asynchronously execute the task on the target member\n            logger.debug(\"Executing DistributedTask: \" + task.getClass().getName());\n            checkForPluginClassLoader(task);\n            try {\n                final Future<T> future = hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMember(new CallableTask<>(task), member);\n                result = future.get(MAX_CLUSTER_EXECUTION_TIME.getValue().getSeconds(), TimeUnit.SECONDS);\n                logger.trace(\"DistributedTask result: {}\", result);\n            } catch (final TimeoutException te) {\n                logger.error(\"Failed to execute cluster task within \" + MAX_CLUSTER_EXECUTION_TIME + \" seconds\", te);\n            } catch (final Exception e) {\n                logger.error(\"Failed to execute cluster task\", e);\n            }\n        } else {\n            final String msg = MessageFormat.format(\"Requested node {0} not found in cluster\", new String(nodeID, StandardCharsets.UTF_8));\n            logger.warn(msg);\n            throw new IllegalArgumentException(msg);\n        }\n        return result;\n    }\n\n    @Override\n    public ClusterNodeInfo getClusterNodeInfo(final byte[] nodeID) {\n        if (cluster == null) {\n            return null;\n        }\n        ClusterNodeInfo result = null;\n        final com.hazelcast.cluster.Member member = getMember(nodeID);\n        if (member != null) {\n            result = new HazelcastClusterNodeInfo(member, cluster.getClusterTime());\n        }\n        return result;\n    }\n\n    private Member getMember(final byte[] nodeID) {\n        final NodeID memberToFind = NodeID.getInstance(nodeID);\n        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {\n            if (memberToFind.equals(getNodeID(member))) {\n                return member;\n            }\n        }\n        return null;\n    }\n\n    @Override\n    public void updateCacheStats(final Map<String, Cache> caches) {\n        if (!caches.isEmpty() && cluster != null) {\n            // Create the cacheStats map if necessary.\n            if (cacheStats == null) {\n                cacheStats = hazelcast.getMap(\"opt-$cacheStats\");\n            }\n            final String uid = getNodeID(cluster.getLocalMember()).toString();\n            final Map<String, long[]> stats = new HashMap<>();\n            for (final String cacheName : caches.keySet()) {\n                final Cache cache = caches.get(cacheName);\n                // The following information is published:\n                // current size, max size, num elements, cache\n                // hits, cache misses.\n                final long[] info = new long[5];\n                info[0] = cache.getLongCacheSize();\n                info[1] = cache.getMaxCacheSize();\n                info[2] = cache.size();\n                info[3] = cache.getCacheHits();\n                info[4] = cache.getCacheMisses();\n                stats.put(cacheName, info);\n            }\n            // Publish message\n            cacheStats.put(uid, stats);\n        }\n    }\n\n    @Override\n    public String getPluginName() {\n        return PLUGIN_NAME;\n    }\n\n    @Override\n    public Lock getLock(final Object key, Cache cache) {\n        if (cache instanceof CacheWrapper) {\n            cache = ((CacheWrapper) cache).getWrappedCache();\n        }\n        // TODO: Update CacheFactoryStrategy so the signature is getLock(final Serializable key, Cache<Serializable, Serializable> cache)\n        @SuppressWarnings(\"unchecked\") final ClusterLock clusterLock = new ClusterLock((Serializable) key, (ClusteredCache<Serializable, ?>) cache);\n        return clusterLock;\n    }\n\n    /**\n     * ClusterTasks that are executed should not be provided by a plugin. These will cause issues related to class\n     * loading when the providing plugin is reloaded. This method verifies if an instance of a task is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected <T extends ClusterTask<?>> void checkForPluginClassLoader(final T o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && !pluginClassLoaderWarnings.containsKey(o.getClass().getName()) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is executed as a cluster task. This will cause issues when reloading \" +\n                    \"the plugin that provides this class. The plugin implementation should be modified.\",\n                pluginName != null ? o.getClass() + \" (provided by plugin \" + pluginName + \")\" : o.getClass());\n            pluginClassLoaderWarnings.put(o.getClass().getName(), Instant.now()); // Note that this Instant is unused.\n        }\n    }\n\n    private static class ClusterLock implements Lock {\n\n        private final Serializable key;\n        private final ClusteredCache<Serializable, ?> cache;\n\n        ClusterLock(final Serializable key, final ClusteredCache<Serializable, ?> cache) {\n            this.key = key;\n            this.cache = cache;\n        }\n\n        @Override\n        public void lock() {\n            cache.lock(key, -1);\n        }\n\n        @Override\n        public void lockInterruptibly() {\n            cache.lock(key, -1);\n        }\n\n        @Override\n        public boolean tryLock() {\n            return cache.lock(key, 0);\n        }\n\n        @Override\n        public boolean tryLock(final long time, final TimeUnit unit) {\n            return cache.lock(key, unit.toMillis(time));\n        }\n\n        @Override\n        public void unlock() {\n            cache.unlock(key);\n        }\n\n        @Override\n        public Condition newCondition() {\n            throw new UnsupportedOperationException();\n        }\n    }\n\n    private static class CallableTask<V> implements Callable<V>, Serializable {\n        private static final long serialVersionUID = -8761271979427214681L;\n        private final ClusterTask<V> task;\n\n        CallableTask(final ClusterTask<V> task) {\n            this.task = task;\n        }\n\n        @Override\n        public V call() {\n            try {\n                task.run();\n                logger.trace(\"CallableTask[{}] result: {}\", task.getClass().getName(), task.getResult());\n                return task.getResult();\n            } catch (final Exception e) {\n                logger.error(\"Unexpected exception running CallableTask[{}]\", task.getClass().getName(), e);\n                throw e;\n            }\n        }\n    }\n\n    private enum State {\n        stopped,\n        starting,\n        started\n    }\n\n    public static NodeID getNodeID(final Member member) {\n        return NodeID.getInstance(member.getAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));\n    }\n\n    static void fireLeftClusterAndWaitToComplete(final Duration timeout) {\n        final Semaphore leftClusterSemaphore = new Semaphore(0);\n        final ClusterEventListener clusterEventListener = new ClusterEventListener() {\n            @Override\n            public void joinedCluster() {\n            }\n\n            @Override\n            public void joinedCluster(final byte[] bytes) {\n            }\n\n            @Override\n            public void leftCluster() {\n                leftClusterSemaphore.release();\n            }\n\n            @Override\n            public void leftCluster(final byte[] bytes) {\n            }\n\n            @Override\n            public void markedAsSeniorClusterMember() {\n            }\n        };\n        try {\n            // Add a listener at the ultimate end of the list of all listeners, to detect that left-cluster event handling\n            // has been invoked for all before proceeding.\n            ClusterManager.addListener(clusterEventListener, Integer.MAX_VALUE);\n            logger.debug(\"Firing leftCluster() event\");\n            ClusterManager.fireLeftCluster();\n            logger.debug(\"Waiting for leftCluster() event to be called [timeout={}]\", StringUtils.getFullElapsedTime(timeout));\n            if (!leftClusterSemaphore.tryAcquire(timeout.toMillis(), TimeUnit.MILLISECONDS)) {\n                logger.warn(\"Timeout waiting for leftCluster() event to be called [timeout={}]\", StringUtils.getFullElapsedTime(timeout));\n            }\n        } catch (final Exception e) {\n            logger.error(\"Unexpected exception waiting for clustering to shut down\", e);\n        } finally {\n            ClusterManager.removeListener(clusterEventListener);\n        }\n    }\n\n}\n\n\n\n", "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.Cluster;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.core.LifecycleEvent;\nimport com.hazelcast.core.LifecycleEvent.LifecycleState;\nimport com.hazelcast.core.LifecycleListener;\nimport com.hazelcast.cluster.Member;\nimport com.hazelcast.cluster.MemberAttributeEvent;\nimport com.hazelcast.cluster.MembershipEvent;\nimport com.hazelcast.cluster.MembershipListener;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusterManager;\nimport org.jivesoftware.openfire.cluster.ClusterNodeInfo;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.muc.cluster.NewClusterMemberJoinedTask;\nimport org.jivesoftware.openfire.plugin.util.cluster.HazelcastClusterNodeInfo;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.jivesoftware.util.cache.CacheWrapper;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.time.Duration;\nimport java.time.LocalTime;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\n\n/**\n * ClusterListener reacts to membership changes in the cluster. It takes care of cleaning up the state\n * of the routing table and the sessions within it when a node which manages those sessions goes down.\n */\npublic class ClusterListener implements MembershipListener, LifecycleListener {\n\n    private static final Logger logger = LoggerFactory.getLogger(ClusterListener.class);\n\n    private boolean seniorClusterMember = false;\n\n    private final Map<Cache<?,?>, EntryListener> entryListeners = new HashMap<>();\n    \n    private final Cluster cluster;\n    private final Map<NodeID, ClusterNodeInfo> clusterNodesInfo = new ConcurrentHashMap<>();\n    \n\n    private final Cluster cluster;\n    private final Map<NodeID, ClusterNodeInfo> clusterNodesInfo = new ConcurrentHashMap<>();\n\n    /**\n     * Flag that indicates if the listener has done all clean up work when noticed that the\n     * cluster has been stopped. This will force Openfire to wait until all clean\n     * up (e.g. changing caches implementations) is done before destroying the plugin.\n     */\n    private boolean done = true;\n    /**\n     * Flag that indicates if we've joined a cluster or not\n     */\n    private boolean clusterMember = false;\n    private boolean isSenior;\n\n    ClusterListener(final Cluster cluster) {\n\n        this.cluster = cluster;\n        for (final Member member : cluster.getMembers()) {\n            clusterNodesInfo.put(ClusteredCacheFactory.getNodeID(member),\n                    new HazelcastClusterNodeInfo(member, cluster.getClusterTime()));\n        }\n    }\n\n    private void addEntryListener(final Cache<?, ?> cache, final EntryListener listener) {\n        if (cache instanceof CacheWrapper) {\n            final Cache wrapped = ((CacheWrapper)cache).getWrappedCache();\n            if (wrapped instanceof ClusteredCache) {\n                ((ClusteredCache)wrapped).addEntryListener(listener);\n                // Keep track of the listener that we added to the cache\n                entryListeners.put(cache, listener);\n            }\n        }\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    private boolean isDone() {\n        return done;\n    }\n\n    synchronized void joinCluster() {\n        if (!isDone()) { // already joined\n            return;\n        }\n\n        // Trigger events\n        clusterMember = true;\n        seniorClusterMember = isSeniorClusterMember();\n\n        ClusterManager.fireJoinedCluster(false);\n\n        if (seniorClusterMember) {\n            ClusterManager.fireMarkedAsSeniorClusterMember();\n        }\n\n        waitForClusterCacheToBeInstalled();\n\n        // Let the other nodes know that we joined the cluster\n        logger.debug(\"Done joining the cluster. Now proceed informing other nodes that we joined the cluster.\");\n        CacheFactory.doClusterTask(new NewClusterMemberJoinedTask());\n\n        logger.info(\"Joined cluster. XMPPServer node={}, Hazelcast UUID={}, seniorClusterMember={}\",\n            new Object[]{ClusteredCacheFactory.getNodeID(cluster.getLocalMember()), cluster.getLocalMember().getUuid(), seniorClusterMember});\n        done = false;\n    }\n\n    boolean isSeniorClusterMember() {\n        // first cluster member is the oldest\n        final Iterator<Member> members = cluster.getMembers().iterator();\n        return members.next().getUuid().equals(cluster.getLocalMember().getUuid());\n    }\n\n    private synchronized void leaveCluster() {\n        if (isDone()) { // not a cluster member\n            return;\n        }\n        clusterMember = false;\n        final boolean wasSeniorClusterMember = seniorClusterMember;\n        seniorClusterMember = false;\n\n        // Trigger event. Wait until the listeners have processed the event. Caches will be populated\n        // again with local content.\n        ClusterManager.fireLeftCluster();\n\n        if (!XMPPServer.getInstance().isShuttingDown()) {\n            // Remove traces of directed presences sent from local entities to handlers that no longer exist\n            // At this point c2s sessions are gone from the routing table so we can identify expired sessions\n            XMPPServer.getInstance().getPresenceUpdateHandler().removedExpiredPresences();\n        }\n        logger.info(\"Left cluster. XMPPServer node={}, Hazelcast UUID={}, wasSeniorClusterMember={}\",\n            new Object[]{ClusteredCacheFactory.getNodeID(cluster.getLocalMember()), cluster.getLocalMember().getUuid(), wasSeniorClusterMember});\n        done = true;\n    }\n\n    @Override\n    public void memberAdded(final MembershipEvent event) {\n        logger.info(\"Received a Hazelcast memberAdded event {}\", event);\n\n        final boolean wasSenior = isSenior;\n        isSenior = isSeniorClusterMember();\n        // local member only\n        final NodeID nodeID = ClusteredCacheFactory.getNodeID(event.getMember());\n        if (event.getMember().localMember()) { // We left and re-joined the cluster\n            joinCluster();\n\n        } else {\n            if (wasSenior && !isSenior) {\n                logger.warn(\"Recovering from split-brain; firing leftCluster()/joinedCluster() events\");\n                ClusteredCacheFactory.fireLeftClusterAndWaitToComplete(Duration.ofSeconds(30));\n                logger.debug(\"Firing joinedCluster() event\");\n                ClusterManager.fireJoinedCluster(false);\n\n                try {\n                    logger.debug(\"Postponing notification of other nodes for 30 seconds. This allows all local leave/join processing to be finished and local cache backups to be stabilized before receiving events from other nodes.\");\n                    Thread.sleep(30000L);\n                } catch (InterruptedException e) {\n                    logger.warn(\"30 Second wait was interrupted.\", e);\n                }\n\n                // The following line was intended to wait until all local handling finishes before informing other\n                // nodes. However that proved to be insufficient. Hence the 30 second default wait in the lines above.\n                // TODO Instead of the 30 second wait, we should look (and then wait) for some trigger or event that signifies that local handling has completed and caches have stabilized.\n                waitForClusterCacheToBeInstalled();\n\n                // Let the other nodes know that we joined the cluster\n                logger.debug(\"Done joining the cluster in split brain recovery. Now proceed informing other nodes that we joined the cluster.\");\n                CacheFactory.doClusterTask(new NewClusterMemberJoinedTask());\n            }\n        }\n        clusterNodesInfo.put(nodeID,\n                new HazelcastClusterNodeInfo(event.getMember(), cluster.getClusterTime()));\n    }\n\n    /**\n     * Blocks the current thread until the cluster cache is guaranteed to support clustering. This is especially useful\n     * for executing cluster tasks immediately after joining. If this wait is not performed, the cache factory may still\n     * be using the 'default' strategy instead of the 'hazelcast' strategy, which leads to cluster tasks being silently\n     * discarded.\n     *\n     * The method will keep trying this for 10 minutes. After that the thread is released regardless of the result.\n     *\n     * @return Boolean indicating whether the clustered cache was actually observed to be installed.\n     */\n    private boolean waitForClusterCacheToBeInstalled() {\n        boolean failed = false;\n        if (!ClusteredCacheFactory.PLUGIN_NAME.equals(CacheFactory.getPluginName())) {\n            logger.debug(\"This node now joined a cluster, but the cache factory has not been swapped to '{}' yet. Waiting for that to happen.\", ClusteredCacheFactory.PLUGIN_NAME);\n            LocalTime deadLine = LocalTime.now().plusMinutes(10L);\n            while (!ClusteredCacheFactory.PLUGIN_NAME.equals(CacheFactory.getPluginName()) && deadLine.isAfter(LocalTime.now())) {\n                try {\n                    Thread.sleep(200);\n                } catch (InterruptedException e) {\n                    logger.trace(\"Thread was interrupted while waiting for cache strategy to change.\");\n                    failed = true;\n                    break;\n                }\n            }\n            if (!deadLine.isAfter(LocalTime.now())) {\n                failed = true;\n                logger.warn(\"Cache factory was not swapped to '{}', but still remains '{}' after a 10 minute wait. Cluster join is not guaranteed to have completed.\", ClusteredCacheFactory.PLUGIN_NAME, CacheFactory.getPluginName());\n            }\n            logger.debug(\"Cache factory has been swapped to '{}'. Cluster join is considered complete.\", ClusteredCacheFactory.PLUGIN_NAME);\n        }\n\n        return !failed;\n    }\n\n    @Override\n    public void memberRemoved(final MembershipEvent event) {\n        logger.info(\"Received a Hazelcast memberRemoved event {}\", event);\n\n        isSenior = isSeniorClusterMember();\n        final NodeID nodeID = ClusteredCacheFactory.getNodeID(event.getMember());\n\n        if (event.getMember().localMember()) {\n            logger.info(\"Leaving cluster: \" + nodeID);\n            // This node may have realized that it got kicked out of the cluster\n            leaveCluster();\n        } else {\n            // Trigger event that a node left the cluster\n            ClusterManager.fireLeftCluster(nodeID.toByteArray());\n\n            if (!seniorClusterMember && isSeniorClusterMember()) {\n                seniorClusterMember = true;\n                ClusterManager.fireMarkedAsSeniorClusterMember();\n            }\n\n            // Remove traces of directed presences sent from local entities to handlers that no longer exist.\n            // At this point c2s sessions are gone from the routing table so we can identify expired sessions\n            XMPPServer.getInstance().getPresenceUpdateHandler().removedExpiredPresences();\n        }\n        // Delete nodeID instance (release from memory)\n        NodeID.deleteInstance(nodeID.toByteArray());\n        clusterNodesInfo.remove(nodeID);\n    }\n\n    \n    @SuppressWarnings(\"WeakerAccess\")\n    public List<ClusterNodeInfo> getClusterNodesInfo() {\n        return new ArrayList<>(clusterNodesInfo.values());\n    }\n\n    @Override\n    public void stateChanged(final LifecycleEvent event) {\n        if (event.getState().equals(LifecycleState.SHUTDOWN)) {\n            leaveCluster();\n        } else if (event.getState().equals(LifecycleState.STARTED)) {\n            joinCluster();\n        }\n    }\n\n    @Override\n    public void memberAttributeChanged(final MemberAttributeEvent event) {\n        logger.info(\"Received a Hazelcast memberAttributeChanged event {}\", event);\n        isSenior = isSeniorClusterMember();\n        final ClusterNodeInfo priorNodeInfo = clusterNodesInfo.get(ClusteredCacheFactory.getNodeID(event.getMember()));\n        clusterNodesInfo.put(ClusteredCacheFactory.getNodeID(event.getMember()),\n                new HazelcastClusterNodeInfo(event.getMember(), priorNodeInfo.getJoinedTime()));\n    }\n\n    boolean isClusterMember() {\n        return clusterMember;\n    }\n}\n", "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java": "/*\n * Copyright (C) 1999-2009 Jive Software. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jivesoftware.openfire.plugin.util.cache;\n\nimport com.hazelcast.core.EntryEvent;\nimport com.hazelcast.core.EntryListener;\nimport com.hazelcast.map.IMap;\nimport com.hazelcast.map.MapEvent;\nimport com.hazelcast.map.listener.MapListener;\nimport com.hazelcast.map.LocalMapStats;\nimport org.jivesoftware.openfire.XMPPServer;\nimport org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;\nimport org.jivesoftware.openfire.cluster.NodeID;\nimport org.jivesoftware.openfire.container.Plugin;\nimport org.jivesoftware.openfire.container.PluginClassLoader;\nimport org.jivesoftware.openfire.container.PluginManager;\nimport org.jivesoftware.util.cache.Cache;\nimport org.jivesoftware.util.cache.CacheFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\nimport java.io.Serializable;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Clustered implementation of the Cache interface using Hazelcast.\n *\n */\npublic class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {\n\n    private final Logger logger;\n\n    private final Set<String> listeners = ConcurrentHashMap.newKeySet();\n\n    /**\n     * The map is used for distributed operations such as get, put, etc.\n     */\n    final IMap<K, V> map;\n    private String name;\n    private long numberOfGets = 0;\n\n    /**\n     * Used to limit the amount of duplicate warnings logged.\n     */\n    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;\n    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);\n\n    /**\n     * Create a new cache using the supplied named cache as the actual cache implementation\n     *\n     * @param name a name for the cache, which should be unique per vm.\n     * @param cache the cache implementation\n     */\n    protected ClusteredCache(final String name, final IMap<K, V> cache) {\n        this.map = cache;\n        this.name = name;\n        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + \"[cache: \"+name+\"]\");\n    }\n\n    void addEntryListener(final MapListener listener) {\n        listeners.add(map.addEntryListener(listener, false));\n    }\n\n    @Override\n    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)\n    {\n        final EntryListener<K, V> listener = new EntryListener<K, V>() {\n            @Override\n            public void mapEvicted(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map evicted event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapEvicted(eventNodeId);\n                }\n            }\n\n            @Override\n            public void mapCleared(MapEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing map cleared event of node '{}'\", eventNodeId);\n                    clusteredCacheEntryListener.mapCleared(eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryUpdated(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry update event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryRemoved(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry removed event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryEvicted(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry evicted event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);\n                }\n            }\n\n            @Override\n            public void entryAdded(EntryEvent event) {\n                if (includeEventsFromLocalNode || !event.getMember().localMember()) {\n                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());\n                    logger.trace(\"Processing entry added event of node '{}' for key '{}'\", eventNodeId, event.getKey());\n                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);\n                }\n            }\n        };\n\n        final String listenerId = map.addEntryListener(listener, includeValues);\n        listeners.add(listenerId);\n        logger.debug(\"Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'\", includeValues, includeEventsFromLocalNode, listenerId);\n        return listenerId;\n    }\n\n    @Override\n    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {\n        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);\n        map.removeEntryListener(listenerId);\n        listeners.remove(listenerId);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    @Override\n    public V put(final K key, final V object) {\n        if (object == null) { return null; }\n        checkForPluginClassLoader(key);\n        checkForPluginClassLoader(object);\n        return map.put(key, object);\n    }\n\n    @Override\n    public V get(final Object key) {\n        numberOfGets++;\n        return map.get(key);\n    }\n\n    @Override\n    public V remove(final Object key) {\n        return map.remove(key);\n    }\n\n    @Override\n    public void clear() {\n        map.clear();\n    }\n\n    @Override\n    public int size() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());\n    }\n\n    @Override\n    public boolean containsKey(final Object key) {\n        return map.containsKey(key);\n    }\n\n    @Override\n    public boolean containsValue(final Object value) {\n        return map.containsValue(value);\n    }\n\n    @Override\n    public Set<Map.Entry<K, V>> entrySet() {\n        return map.entrySet();\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return map.isEmpty();\n    }\n\n    @Override\n    public Set<K> keySet() {\n        return map.keySet();\n    }\n\n    @Override\n    public void putAll(final Map<? extends K, ? extends V> entries) {\n        map.putAll(entries);\n\n        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.\n        entries.entrySet().stream().findAny().ifPresent(\n            e -> {\n                checkForPluginClassLoader(e.getKey());\n                checkForPluginClassLoader(e.getValue());\n            }\n        );\n    }\n\n    @Override\n    public Collection<V> values() {\n        return map.values();\n    }\n\n    @Override\n    public long getCacheHits() {\n        return map.getLocalMapStats().getHits();\n    }\n\n    @Override\n    public long getCacheMisses() {\n        final long hits = map.getLocalMapStats().getHits();\n        return numberOfGets > hits ? numberOfGets - hits : 0;\n    }\n\n    @Override\n    public int getCacheSize() {\n        return (int) getLongCacheSize();\n    }\n\n    @Override\n    public long getLongCacheSize() {\n        final LocalMapStats stats = map.getLocalMapStats();\n        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();\n    }\n\n    @Override\n    public long getMaxCacheSize() {\n        return CacheFactory.getMaxCacheSize(getName());\n    }\n\n    @Override\n    public void setMaxCacheSize(int i) {\n        setMaxCacheSize((long) i);\n    }\n\n    @Override\n    public void setMaxCacheSize(final long maxSize) {\n        CacheFactory.setMaxSizeProperty(getName(), maxSize);\n    }\n\n    @Override\n    public long getMaxLifetime() {\n        return CacheFactory.getMaxCacheLifetime(getName());\n    }\n\n    @Override\n    public void setMaxLifetime(final long maxLifetime) {\n        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);\n    }\n\n    void destroy() {\n        listeners.forEach(map::removeEntryListener);\n        map.destroy();\n    }\n\n    boolean lock(final K key, final long timeout) {\n        boolean result = true;\n        if (timeout < 0) {\n            map.lock(key);\n        } else if (timeout == 0) {\n            result = map.tryLock(key);\n        } else {\n            try {\n                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);\n            } catch (final InterruptedException e) {\n                logger.error(\"Failed to get cluster lock\", e);\n                result = false;\n            }\n        }\n        return result;\n    }\n\n    void unlock(final K key) {\n        try {\n            map.unlock(key);\n        } catch (final IllegalMonitorStateException e) {\n            logger.error(\"Failed to release cluster lock\", e);\n        }\n    }\n\n    /**\n     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause\n     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is\n     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is\n     * limited by a time interval.\n     *\n     * @param o the instance for which to verify the class loader\n     * @see <a href=\"https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74\">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>\n     */\n    protected void checkForPluginClassLoader(final Object o) {\n        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader\n            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )\n        {\n            // Try to determine what plugin loaded the offending class.\n            String pluginName = null;\n            try {\n                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();\n                for (final Plugin plugin : plugins) {\n                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);\n                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {\n                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);\n                        break;\n                    }\n                }\n            } catch (Exception e) {\n                logger.debug(\"An exception occurred while trying to determine the plugin class loader that loaded an instance of {}\", o.getClass(), e);\n            }\n            logger.warn(\"An instance of {} that is loaded by {} has been added to the cache. \" +\n                \"This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.\",\n                o.getClass(), pluginName != null ? pluginName : \"a PluginClassLoader\");\n            lastPluginClassLoaderWarning = Instant.now();\n        }\n    }\n}\n"}, "compile_error_details": {"src/java/org/jivesoftware/openfire/plugin/util/cache/ClusterListener.java": {"18": {"lines": [{"line_no": 17, "content": ""}, {"line_no": 18, "content": "import com.hazelcast.core.Cluster;"}, {"line_no": 19, "content": "import com.hazelcast.core.EntryListener;"}], "error_texts": ["[18,26] cannot find symbol\n", "[18,26] cannot find symbol\nsymbol: class Cluster\nlocation: package com.hazelcast.core\n"]}, "24": {"lines": [{"line_no": 23, "content": "import com.hazelcast.cluster.Member;"}, {"line_no": 24, "content": "import com.hazelcast.cluster.MemberAttributeEvent;"}, {"line_no": 25, "content": "import com.hazelcast.cluster.MembershipEvent;"}], "error_texts": ["[24,29] cannot find symbol\nsymbol: class MemberAttributeEvent\nlocation: package com.hazelcast.cluster\n", "[24,29] cannot find symbol\n"]}, "60": {"lines": [{"line_no": 59, "content": "    "}, {"line_no": 60, "content": "    private final Cluster cluster;"}, {"line_no": 61, "content": "    private final Map<NodeID, ClusterNodeInfo> clusterNodesInfo = new ConcurrentHashMap<>();"}], "error_texts": ["[60,19] cannot find symbol\nsymbol: class Cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusterListener\n", "[60,19] cannot find symbol\n"]}, "64": {"lines": [{"line_no": 63, "content": ""}, {"line_no": 64, "content": "    private final Cluster cluster;"}, {"line_no": 65, "content": "    private final Map<NodeID, ClusterNodeInfo> clusterNodesInfo = new ConcurrentHashMap<>();"}], "error_texts": ["[64,19] cannot find symbol\nsymbol: class Cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusterListener\n", "[64,19] cannot find symbol\n"]}, "65": {"lines": [{"line_no": 64, "content": "    private final Cluster cluster;"}, {"line_no": 65, "content": "    private final Map<NodeID, ClusterNodeInfo> clusterNodesInfo = new ConcurrentHashMap<>();"}, {"line_no": 66, "content": ""}], "error_texts": ["[65,48] variable clusterNodesInfo is already defined in class org.jivesoftware.openfire.plugin.util.cache.ClusterListener\n"]}, "79": {"lines": [{"line_no": 78, "content": ""}, {"line_no": 79, "content": "    ClusterListener(final Cluster cluster) {"}, {"line_no": 80, "content": ""}], "error_texts": ["[79,27] cannot find symbol\nsymbol: class Cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusterListener\n", "[79,27] cannot find symbol\n"]}, "276": {"lines": [{"line_no": 275, "content": "    @Override"}, {"line_no": 276, "content": "    public void memberAttributeChanged(final MemberAttributeEvent event) {"}, {"line_no": 277, "content": "        logger.info(\"Received a Hazelcast memberAttributeChanged event {}\", event);"}], "error_texts": ["[276,46] cannot find symbol\nsymbol: class MemberAttributeEvent\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusterListener\n", "[276,46] cannot find symbol\n"]}, "275": {"lines": [{"line_no": 274, "content": ""}, {"line_no": 275, "content": "    @Override"}, {"line_no": 276, "content": "    public void memberAttributeChanged(final MemberAttributeEvent event) {"}], "error_texts": ["[275,5] method does not override or implement a method from a supertype\n"]}}, "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCacheFactory.java": {"500": {"lines": [{"line_no": 499, "content": ""}, {"line_no": 500, "content": "    private Member getMember(final byte[] nodeID) {"}, {"line_no": 501, "content": "        final NodeID memberToFind = NodeID.getInstance(nodeID);"}], "error_texts": ["[500,13] cannot find symbol\nsymbol: class Member\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[500,13] cannot find symbol\n"]}, "654": {"lines": [{"line_no": 653, "content": ""}, {"line_no": 654, "content": "    public static NodeID getNodeID(final Member member) {"}, {"line_no": 655, "content": "        return NodeID.getInstance(member.getAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));"}], "error_texts": ["[654,42] cannot find symbol\nsymbol: class Member\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[654,42] cannot find symbol\n"]}, "190": {"lines": [{"line_no": 189, "content": "                final MemberAttributeConfig memberAttributeConfig = config.getMemberAttributeConfig();"}, {"line_no": 190, "content": "                memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.HOST_NAME_ATTRIBUTE, XMPPServer.getInstance().getServerInfo().getHostname());"}, {"line_no": 191, "content": "                memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE, XMPPServer.getInstance().getNodeID().toString());"}], "error_texts": ["[190,38] cannot find symbol\nsymbol: method setStringAttribute(java.lang.String,java.lang.String)\nlocation: variable memberAttributeConfig of type com.hazelcast.config.MemberAttributeConfig\n", "[190,38] cannot find symbol\n"]}, "191": {"lines": [{"line_no": 190, "content": "                memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.HOST_NAME_ATTRIBUTE, XMPPServer.getInstance().getServerInfo().getHostname());"}, {"line_no": 191, "content": "                memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE, XMPPServer.getInstance().getNodeID().toString());"}, {"line_no": 192, "content": "                config.setInstanceName(\"openfire\");"}], "error_texts": ["[191,38] cannot find symbol\nsymbol: method setStringAttribute(java.lang.String,java.lang.String)\nlocation: variable memberAttributeConfig of type com.hazelcast.config.MemberAttributeConfig\n", "[191,38] cannot find symbol\n"]}, "199": {"lines": [{"line_no": 198, "content": "                hazelcast = Hazelcast.newHazelcastInstance(config);"}, {"line_no": 199, "content": "                Cluster cluster = hazelcast.getCluster();"}, {"line_no": 200, "content": "                state = State.started;"}], "error_texts": ["[199,17] cannot find symbol\nsymbol: class Cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[199,17] cannot find symbol\n"]}, "204": {"lines": [{"line_no": 203, "content": "                clusterListener.joinCluster();"}, {"line_no": 204, "content": "                lifecycleListener = hazelcast.getLifecycleService().addLifecycleListener(clusterListener);"}, {"line_no": 205, "content": "                membershipListener = cluster.addMembershipListener(clusterListener);"}], "error_texts": ["[204,89] incompatible types: java.util.UUID cannot be converted to java.lang.String\n"]}, "209": {"lines": [{"line_no": 208, "content": "            } catch (final Exception e) {"}, {"line_no": 209, "content": "                cluster = null;"}, {"line_no": 210, "content": "                if (retry < CLUSTER_STARTUP_RETRY_COUNT.getValue()) {"}], "error_texts": ["[209,17] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[209,17] cannot find symbol\n"]}, "229": {"lines": [{"line_no": 228, "content": "        }"}, {"line_no": 229, "content": "        return cluster != null;"}, {"line_no": 230, "content": "    }"}], "error_texts": ["[229,16] cannot find symbol\n", "[229,16] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n"]}, "243": {"lines": [{"line_no": 242, "content": "        // Stop the cluster"}, {"line_no": 243, "content": "        hazelcast.getLifecycleService().removeLifecycleListener(lifecycleListener);"}, {"line_no": 244, "content": "        cluster.removeMembershipListener(membershipListener);"}], "error_texts": ["[243,65] incompatible types: java.lang.String cannot be converted to java.util.UUID\n"]}, "244": {"lines": [{"line_no": 243, "content": "        hazelcast.getLifecycleService().removeLifecycleListener(lifecycleListener);"}, {"line_no": 244, "content": "        cluster.removeMembershipListener(membershipListener);"}, {"line_no": 245, "content": "        Hazelcast.shutdownAll();"}], "error_texts": ["[244,9] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[244,9] cannot find symbol\n"]}, "246": {"lines": [{"line_no": 245, "content": "        Hazelcast.shutdownAll();"}, {"line_no": 246, "content": "        cluster = null;"}, {"line_no": 247, "content": "        lifecycleListener = null;"}], "error_texts": ["[246,9] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[246,9] cannot find symbol\n"]}, "284": {"lines": [{"line_no": 283, "content": "            dynamicConfig.setTimeToLiveSeconds(hazelcastLifetimeInSeconds);"}, {"line_no": 284, "content": "            dynamicConfig.setMaxSizeConfig(new MaxSizeConfig(hazelcastMaxCacheSizeInMegaBytes, MaxSizeConfig.MaxSizePolicy.USED_HEAP_SIZE));"}, {"line_no": 285, "content": "            logger.debug(\"Creating dynamic map config for cache={}, dynamicConfig={}\", name, dynamicConfig);"}], "error_texts": ["[284,48] cannot find symbol\nsymbol: class MaxSizeConfig\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[284,48] cannot find symbol\n", "[284,109] package MaxSizeConfig does not exist\n"]}, "326": {"lines": [{"line_no": 325, "content": "    public byte[] getSeniorClusterMemberID() {"}, {"line_no": 326, "content": "        Cluster cluster = hazelcast.getCluster();"}, {"line_no": 327, "content": "        if (cluster != null && !cluster.getMembers().isEmpty()) {"}], "error_texts": ["[326,9] cannot find symbol\nsymbol: class Cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[326,9] cannot find symbol\n"]}, "337": {"lines": [{"line_no": 336, "content": "    public byte[] getClusterMemberID() {"}, {"line_no": 337, "content": "        Cluster cluster = hazelcast.getCluster();"}, {"line_no": 338, "content": "        if (cluster != null) {"}], "error_texts": ["[337,9] cannot find symbol\n", "[337,9] cannot find symbol\nsymbol: class Cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n"]}, "354": {"lines": [{"line_no": 353, "content": "    public long getClusterTime() {"}, {"line_no": 354, "content": "        Cluster cluster = hazelcast.getCluster();"}, {"line_no": 355, "content": "        return cluster == null ? System.currentTimeMillis() : cluster.getClusterTime();"}], "error_texts": ["[354,9] cannot find symbol\nsymbol: class Cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[354,9] cannot find symbol\n"]}, "366": {"lines": [{"line_no": 365, "content": ""}, {"line_no": 366, "content": "        if (cluster == null) {"}, {"line_no": 367, "content": "            return;"}], "error_texts": ["[366,13] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[366,13] cannot find symbol\n"]}, "370": {"lines": [{"line_no": 369, "content": "        final Set<com.hazelcast.cluster.Member> members = new HashSet<>();"}, {"line_no": 370, "content": "        final com.hazelcast.cluster.Member current = cluster.getLocalMember();"}, {"line_no": 371, "content": "        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {"}], "error_texts": ["[370,54] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[370,54] cannot find symbol\n"]}, "371": {"lines": [{"line_no": 370, "content": "        final com.hazelcast.cluster.Member current = cluster.getLocalMember();"}, {"line_no": 371, "content": "        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {"}, {"line_no": 372, "content": "            if (!member.getUuid().equals(current.getUuid())) {"}], "error_texts": ["[371,58] cannot find symbol\n", "[371,58] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n"]}, "395": {"lines": [{"line_no": 394, "content": "    public void doClusterTask(final ClusterTask<?> task, final byte[] nodeID) {"}, {"line_no": 395, "content": "        if (cluster == null) {"}, {"line_no": 396, "content": "            return;"}], "error_texts": ["[395,13] cannot find symbol\n", "[395,13] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n"]}, "419": {"lines": [{"line_no": 418, "content": "    public <T> Collection<T> doSynchronousClusterTask(final ClusterTask<T> task, final boolean includeLocalMember) {"}, {"line_no": 419, "content": "        if (cluster == null) {"}, {"line_no": 420, "content": "            return Collections.emptyList();"}], "error_texts": ["[419,13] cannot find symbol\n", "[419,13] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n"]}, "423": {"lines": [{"line_no": 422, "content": "        final Set<com.hazelcast.cluster.Member> members = new HashSet<>();"}, {"line_no": 423, "content": "        final com.hazelcast.cluster.Member current = cluster.getLocalMember();"}, {"line_no": 424, "content": "        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {"}], "error_texts": ["[423,54] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[423,54] cannot find symbol\n"]}, "424": {"lines": [{"line_no": 423, "content": "        final com.hazelcast.cluster.Member current = cluster.getLocalMember();"}, {"line_no": 424, "content": "        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {"}, {"line_no": 425, "content": "            if (includeLocalMember || (!member.getUuid().equals(current.getUuid()))) {"}], "error_texts": ["[424,58] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[424,58] cannot find symbol\n"]}, "435": {"lines": [{"line_no": 434, "content": "                checkForPluginClassLoader(task);"}, {"line_no": 435, "content": "                final Map<Member, ? extends Future<T>> futures = hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMembers(new CallableTask<>(task), members);"}, {"line_no": 436, "content": "                long nanosLeft = TimeUnit.SECONDS.toNanos(MAX_CLUSTER_EXECUTION_TIME.getValue().getSeconds() * members.size());"}], "error_texts": ["[435,27] cannot find symbol\nsymbol: class Member\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[435,27] cannot find symbol\n"]}, "460": {"lines": [{"line_no": 459, "content": "    public <T> T doSynchronousClusterTask(final ClusterTask<T> task, final byte[] nodeID) {"}, {"line_no": 460, "content": "        if (cluster == null) {"}, {"line_no": 461, "content": "            return null;"}], "error_texts": ["[460,13] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[460,13] cannot find symbol\n"]}, "489": {"lines": [{"line_no": 488, "content": "    public ClusterNodeInfo getClusterNodeInfo(final byte[] nodeID) {"}, {"line_no": 489, "content": "        if (cluster == null) {"}, {"line_no": 490, "content": "            return null;"}], "error_texts": ["[489,13] cannot find symbol\n", "[489,13] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n"]}, "495": {"lines": [{"line_no": 494, "content": "        if (member != null) {"}, {"line_no": 495, "content": "            result = new HazelcastClusterNodeInfo(member, cluster.getClusterTime());"}, {"line_no": 496, "content": "        }"}], "error_texts": ["[495,59] cannot find symbol\n", "[495,59] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n"]}, "502": {"lines": [{"line_no": 501, "content": "        final NodeID memberToFind = NodeID.getInstance(nodeID);"}, {"line_no": 502, "content": "        for (final com.hazelcast.cluster.Member member : cluster.getMembers()) {"}, {"line_no": 503, "content": "            if (memberToFind.equals(getNodeID(member))) {"}], "error_texts": ["[502,58] cannot find symbol\n", "[502,58] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n"]}, "512": {"lines": [{"line_no": 511, "content": "    public void updateCacheStats(final Map<String, Cache> caches) {"}, {"line_no": 512, "content": "        if (!caches.isEmpty() && cluster != null) {"}, {"line_no": 513, "content": "            // Create the cacheStats map if necessary."}], "error_texts": ["[512,34] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n", "[512,34] cannot find symbol\n"]}, "517": {"lines": [{"line_no": 516, "content": "            }"}, {"line_no": 517, "content": "            final String uid = getNodeID(cluster.getLocalMember()).toString();"}, {"line_no": 518, "content": "            final Map<String, long[]> stats = new HashMap<>();"}], "error_texts": ["[517,42] cannot find symbol\n", "[517,42] cannot find symbol\nsymbol: variable cluster\nlocation: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCacheFactory\n"]}}, "src/java/org/jivesoftware/openfire/plugin/util/cluster/HazelcastClusterNodeInfo.java": {"24": {"lines": [{"line_no": 23, "content": ""}, {"line_no": 24, "content": "import com.hazelcast.core.Member;"}, {"line_no": 25, "content": ""}], "error_texts": ["[24,26] cannot find symbol\n", "[24,26] cannot find symbol\nsymbol: class Member\nlocation: package com.hazelcast.core\n"]}, "41": {"lines": [{"line_no": 40, "content": ""}, {"line_no": 41, "content": "    public HazelcastClusterNodeInfo(final Member member, final long joinedTime) {"}, {"line_no": 42, "content": "        this.hostname = member.getStringAttribute(HOST_NAME_ATTRIBUTE) + \" (\" + member.getSocketAddress().getHostString() + \")\";"}], "error_texts": ["[41,43] cannot find symbol\n", "[41,43] cannot find symbol\nsymbol: class Member\nlocation: class org.jivesoftware.openfire.plugin.util.cluster.HazelcastClusterNodeInfo\n"]}}, "src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java": {"81": {"lines": [{"line_no": 80, "content": "    void addEntryListener(final MapListener listener) {"}, {"line_no": 81, "content": "        listeners.add(map.addEntryListener(listener, false));"}, {"line_no": 82, "content": "    }"}], "error_texts": ["[81,43] incompatible types: java.util.UUID cannot be converted to java.lang.String\n"]}, "87": {"lines": [{"line_no": 86, "content": "    {"}, {"line_no": 87, "content": "        final EntryListener<K, V> listener = new EntryListener<K, V>() {"}, {"line_no": 88, "content": "            @Override"}], "error_texts": ["[87,72] <anonymous org.jivesoftware.openfire.plugin.util.cache.ClusteredCache$1> is not abstract and does not override abstract method entryExpired(com.hazelcast.core.EntryEvent<K,V>) in com.hazelcast.map.listener.EntryExpiredListener\n"]}, "143": {"lines": [{"line_no": 142, "content": ""}, {"line_no": 143, "content": "        final String listenerId = map.addEntryListener(listener, includeValues);"}, {"line_no": 144, "content": "        listeners.add(listenerId);"}], "error_texts": ["[143,55] incompatible types: java.util.UUID cannot be converted to java.lang.String\n"]}, "152": {"lines": [{"line_no": 151, "content": "        logger.debug(\"Removing clustered cache entry listener: '{}'\", listenerId);"}, {"line_no": 152, "content": "        map.removeEntryListener(listenerId);"}, {"line_no": 153, "content": "        listeners.remove(listenerId);"}], "error_texts": ["[152,33] incompatible types: java.lang.String cannot be converted to java.util.UUID\n"]}, "287": {"lines": [{"line_no": 286, "content": "    void destroy() {"}, {"line_no": 287, "content": "        listeners.forEach(map::removeEntryListener);"}, {"line_no": 288, "content": "        map.destroy();"}], "error_texts": ["[287,27] incompatible types: invalid method reference\n", "[287,27] incompatible types: invalid method reference\nincompatible types: java.lang.String cannot be converted to java.util.UUID\n"]}}}}