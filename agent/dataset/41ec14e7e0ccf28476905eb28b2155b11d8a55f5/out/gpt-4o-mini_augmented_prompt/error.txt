Traceback (most recent call last):
  File "/root/thesis/masterthesis-implementation-gpt/langchain-agent.py", line 948, in <module>
    first_shot_state = app.invoke(
                       ^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 1554, in invoke
    for chunk in self.stream(
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 1073, in stream
    _panic_or_proceed(done, inflight, step)
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 1643, in _panic_or_proceed
    raise exc
  File "/usr/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/retry.py", line 72, in run_with_retry
    task.proc.invoke(task.input, task.config)
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py", line 2502, in invoke
    input = step.invoke(input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/utils.py", line 95, in invoke
    ret = context.run(self.func, input, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/langchain-agent.py", line 899, in call_model
    response = llm_with_tools.invoke(messages)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py", line 4573, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 170, in invoke
    self.generate_prompt(
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 599, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 456, in generate
    raise e
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 446, in generate
    self._generate_with_cache(
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 671, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py", line 547, in _generate
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 643, in create
    return self._post(
           ^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1266, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 942, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1031, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1079, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1031, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1079, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1031, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1079, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1046, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.InternalServerError: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_e3583460535de6acec92e93135b666c5 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}
