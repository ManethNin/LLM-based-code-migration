Traceback (most recent call last):
  File "/root/thesis/masterthesis-implementation-gpt/langchain-agent.py", line 982, in <module>
    first_shot_state = app.invoke(
                       ^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 1281, in invoke
    for chunk in self.stream(
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 966, in stream
    _panic_or_proceed(done, inflight, loop.step)
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 1367, in _panic_or_proceed
    raise exc
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/executor.py", line 60, in done
    task.result()
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/usr/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/retry.py", line 25, in run_with_retry
    task.proc.invoke(task.input, task.config)
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py", line 2873, in invoke
    input = step.invoke(input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/utils.py", line 102, in invoke
    ret = context.run(self.func, input, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/langchain-agent.py", line 933, in call_model
    response = llm_with_tools.invoke(messages)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py", line 5060, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 274, in invoke
    self.generate_prompt(
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 714, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 571, in generate
    raise e
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 561, in generate
    self._generate_with_cache(
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 793, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py", line 601, in _generate
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 646, in create
    return self._post(
           ^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1266, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 942, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1046, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_Cdi0uhLKSq1mMrYGWJQgWE79", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}
