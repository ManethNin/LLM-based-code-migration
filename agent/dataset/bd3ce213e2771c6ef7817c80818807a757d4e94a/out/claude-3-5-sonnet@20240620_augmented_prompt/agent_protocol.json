{
    "validate_diffs": [],
    "compile_maven": [
        {
            "input": "```diff\n--- a/src/main/java/de/uniwue/helper/RecognitionHelper.java\n+++ b/src/main/java/de/uniwue/helper/RecognitionHelper.java\n@@ -14,6 +14,7 @@ import java.util.TreeMap;\n \n import org.apache.commons.io.FileUtils;\n \n+import com.fasterxml.jackson.core.JsonProcessingException;\n import com.fasterxml.jackson.databind.ObjectMapper;\n import com.fasterxml.jackson.databind.ObjectWriter;\n import com.fasterxml.jackson.databind.node.ArrayNode;\n@@ -242,7 +243,7 @@ public class RecognitionHelper {\n \t\t\t\tdataList.add(pageList);\n \t\t\t}\n \t\t\tObjectWriter writer = mapper.writer();\n-\t\t\twriter.writeValue(segmentListFile, dataList);\n+\t\t\twriter.writeValue(segmentListFile, dataList);\n \n             processHandler = new ProcessHandler();\n             processHandler.setFetchProcessConsole(true);\n```",
            "output": {
                "compilation_has_succeeded": false,
                "test_has_succeeded": false,
                "error_text": "cannot access com.fasterxml.jackson.core.exc.StreamWriteException\n",
                "updated_files": {
                    "src/main/java/de/uniwue/helper/RecognitionHelper.java": "package de.uniwue.helper;\n\nimport java.io.File;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.nio.file.*;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.TreeMap;\n\nimport org.apache.commons.io.FileUtils;\n\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.ObjectWriter;\nimport com.fasterxml.jackson.databind.node.ArrayNode;\n\nimport de.uniwue.config.ProjectConfiguration;\nimport de.uniwue.feature.ProcessConflictDetector;\nimport de.uniwue.feature.ProcessHandler;\nimport de.uniwue.feature.ProcessStateCollector;\n\n/**\n * Helper class for recognition module\n */\npublic class RecognitionHelper {\n    /**\n     * Object to access project configuration\n     */\n    private ProjectConfiguration projConf;\n\n    /**\n     * Image type of the project\n     * Possible values: { Binary, Gray }\n     */\n    private String projectImageType;\n\n\n    /**\n     * Object to use generic functionalities\n     */\n    private GenericHelper genericHelper;\n\n    /**\n     * Object to determine process states\n     */\n    private ProcessStateCollector procStateCol;\n\n    /**\n     * Helper object for process handling\n     */\n    private ProcessHandler processHandler;\n\n    /**\n     * Progress of the Recognition process\n     */\n    private int progress = -1;\n\n    /**\n     * Indicates if a Recognition process is already running\n     */\n    private boolean RecognitionRunning = false;\n\n    /**\n     * Last time the images/pagexml are modified\n     */\n    private Map<String,Long> imagesLastModified;\n\n    /**\n     * Structure to monitor the progress of the process\n     * pageId : segmentId : lineSegmentId : processedState\n     *\n     * Structure example:\n     * {\n     *     \"0002\": {\n     *         \"0002__000__paragraph\" : {\n     *             \"0002__000__paragraph__000\" : true,\n     *             \"0002__000__paragraph__001\" : false,\n     *             ...\n     *         },\n     *         ...\n     *     },\n     *     ...\n     * }\n     */\n    private TreeMap<String,TreeMap<String, TreeMap<String, Boolean>>> processState = new TreeMap<>();\n\n    /**\n     * Constructor\n     *\n     * @param projectDir Path to the project directory\n     * @param projectImageType Type of the project (binary, gray)\n     *\n     */\n    public RecognitionHelper(String projectDir, String projectImageType) {\n        this.projectImageType = projectImageType;\n        projConf = new ProjectConfiguration(projectDir);\n        genericHelper = new GenericHelper(projConf);\n        procStateCol = new ProcessStateCollector(projConf, projectImageType);\n        processHandler = new ProcessHandler();\n    }\n\n    /**\n     * Gets the process handler object\n     *\n     * @return Returns the process Helper\n     */\n    public ProcessHandler getProcessHandler() {\n        return processHandler;\n    }\n\n    /**\n     * Initializes the structure with which the progress of the process can be monitored\n     *\n     * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)\n     * @throws IOException\n     */\n    public void initialize(List<String> pageIds) throws IOException {\n        // Init the listener for image modification\n        imagesLastModified = new HashMap<>();\n        for(String pageId: pageIds) {\n            final String pageXML = projConf.OCR_DIR + pageId + projConf.CONF_EXT;\n            imagesLastModified.put(pageXML,new File(pageXML).lastModified());\n        }\n    }\n\n    /**\n     * Returns the absolute path of all line segment images for the pages in the processState\n     *\n     * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)\n     * @return List of line segment images\n     * @throws IOException\n     */\n    public List<String> getLineSegmentImagesForCurrentProcess(List<String> pageIds) throws IOException {\n        List<String> LineSegmentsOfPage = new ArrayList<String>();\n        for (String pageId : processState.keySet()) {\n            for (String segmentId : processState.get(pageId).keySet()) {\n                for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {\n                    LineSegmentsOfPage.add(projConf.PAGE_DIR + pageId + File.separator + segmentId +\n                        File.separator + lineSegmentId + projConf.getImageExtensionByType(projectImageType));\n                }\n            }\n        }\n        return LineSegmentsOfPage;\n    }\n\n    /**\n     * Returns the progress of the process\n     *\n     * @return Progress percentage\n     * @throws IOException\n     */\n    public int getProgress() throws IOException {\n        // Prevent function from calculation progress if process is not running\n        if (!RecognitionRunning)\n            return progress;\n\n        int modifiedCount = 0;\n        if(imagesLastModified != null) {\n            for(String pagexml : imagesLastModified.keySet()) {\n                if(imagesLastModified.get(pagexml) < new File(pagexml).lastModified()) {\n                    modifiedCount++;\n                }\n            }\n            progress = (modifiedCount*100) / imagesLastModified.size();\n        } else {\n            progress = -1;\n        }\n        return progress;\n    }\n\n    /**\n     * Extracts checkpoints of a String joined by a whitespace\n     *\n     * @return List of checkpoints\n     * @throws IOException\n     */\n    public List<String> extractModelsOfJoinedString(String joinedckptString){\n        String [] checkpoints = joinedckptString.split(ProjectConfiguration.MODEL_EXT + \" \");\n        List<String> ckptList = new ArrayList<>();\n        Iterator <String> ckptIterator= Arrays.asList(checkpoints).iterator();\n        while (ckptIterator.hasNext()) {\n            String ckpt = ckptIterator.next();\n            if (ckptIterator.hasNext())\n                ckpt = ckpt + ProjectConfiguration.MODEL_EXT;\n            ckptList.add(ckpt);\n        }\n        return ckptList;\n    }\n    /**\n     * Executes OCR on a list of pages\n     * Achieved with the help of the external python program \"calamary-predict\"\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     * @param cmdArgs Command line arguments for \"calamary-predict\"\n     * @throws IOException\n     */\n    public void execute(List<String> pageIds, final List<String> cmdArgs) throws IOException {\n        RecognitionRunning = true;\n        progress = 0;\n\n        List<String> cmdArgsWork = new ArrayList<>(cmdArgs);\n\n        //// Estimate Skew\n        if (cmdArgsWork.contains(\"--estimate_skew\")) {\n        \t// Calculate the skew of all regions where none was calculated before\n        \tList<String> skewparams = new ArrayList<>();\n            skewparams.add(\"skewestimate\");\n        \tfinal int maxskewIndex = cmdArgsWork.indexOf(\"--maxskew\");\n        \tif(maxskewIndex > -1) {\n        \t\tskewparams.add(cmdArgsWork.remove(maxskewIndex));\n        \t\tskewparams.add(cmdArgsWork.remove(maxskewIndex));\n        \t}\n        \tfinal int skewstepsIndex = cmdArgsWork.indexOf(\"--skewsteps\");\n        \tif(skewstepsIndex > -1) {\n        \t\tskewparams.add(cmdArgsWork.remove(skewstepsIndex));\n        \t\tskewparams.add(cmdArgsWork.remove(skewstepsIndex));\n        \t}\n\n\t\t\t// Create temp json file with all segment images (to not overload parameter list)\n\t\t\t// Temp file in a temp folder named \"skew-<random numbers>.json\"\n\t\t\tFile segmentListFile = File.createTempFile(\"skew-\",\".json\");\n\t\t\tskewparams.add(segmentListFile.toString());\n\t\t\tsegmentListFile.deleteOnExit(); // Delete if OCR4all terminates\n\t\t\tObjectMapper mapper = new ObjectMapper();\n\t\t\tArrayNode dataList = mapper.createArrayNode();\n\t\t\tfor (String pageId : pageIds) {\n\t\t\t\tArrayNode pageList = mapper.createArrayNode();\n\t\t\t\tpageList.add(projConf.getImageDirectoryByType(projectImageType) + pageId +\n\t\t\t\t\t\tprojConf.getImageExtensionByType(projectImageType));\n\t\t\t\tfinal String pageXML = projConf.OCR_DIR + pageId + projConf.CONF_EXT;\n\t\t\t\tpageList.add(pageXML);\n\n\t\t\t\t// Add affected line segment images with their absolute path to the json file\n\t\t\t\tdataList.add(pageList);\n\t\t\t}\n\t\t\tObjectWriter writer = mapper.writer();\n\t\t\twriter.writeValue(segmentListFile, dataList);\n\n            processHandler = new ProcessHandler();\n            processHandler.setFetchProcessConsole(true);\n            processHandler.startProcess(\"ocr4all-helper-scripts\", skewparams, false);\n\n        \tcmdArgsWork.remove(\"--estimate_skew\");\n        }\n\n\n        //// Recognize\n\t\t// Reset recognition data\n\t\tdeleteOldFiles(pageIds);\n\t\tinitialize(pageIds);\n\n        int index;\n        if (cmdArgsWork.contains(\"--checkpoint\")) {\n            index = cmdArgsWork.indexOf(\"--checkpoint\");\n            for(String ckpt : extractModelsOfJoinedString(cmdArgsWork.get(index + 1))) {\n                if (!new File(ckpt).exists())\n                    throw new IOException(\"Model does not exist under the specified path\");\n            }\n        }\n\n        List<String> command = new ArrayList<>();\n        // Ugly hack but helpers will be rewritten for the next release anyways. Don't use as basis for future code!\n        if(cmdArgsWork.contains(\"--data.output_glyphs\")){\n            cmdArgsWork.remove(\"--data.output_glyphs\");\n            command.add(\"--data.output_glyphs\");\n            command.add(\"True\");\n        }\n        if(cmdArgsWork.contains(\"--data.output_confidences\")){\n            cmdArgsWork.remove(\"--data.output_confidences\");\n            command.add(\"--data.output_confidences\");\n            command.add(\"True\");\n        }\n\n        command.add(\"--data.images\");\n        // Create temp json file with all segment images (to not overload parameter list)\n\t\t// Temp file in a temp folder named \"calamari-<random numbers>.json\"\n        File segmentListFile = File.createTempFile(\"calamari-\",\".files\");\n        segmentListFile.deleteOnExit();\n\n        List<String> content = new ArrayList<>();\n        for (String pageId : pageIds) {\n            // Add affected images with their absolute path to the file\n            content.add(projConf.getImageDirectoryByType(projectImageType) + pageId +\n                                projConf.getImageExtensionByType(projectImageType));\n        }\n        Files.write(segmentListFile.toPath(), content, StandardOpenOption.APPEND);\n        command.add(segmentListFile.toString());\n\n        //Add checkpoints\n        Iterator<String> cmdArgsIterator = cmdArgsWork.iterator();\n        while (cmdArgsIterator.hasNext()) {\n            String arg = cmdArgsIterator.next();\n            command.add(arg);\n            if (arg.equals(\"--checkpoint\") && cmdArgsIterator.hasNext()) {\n                command.addAll(extractModelsOfJoinedString(cmdArgsIterator.next()));\n            }\n        }\n\n        command.add(\"--data\");\n        command.add(\"PageXML\");\n        // Set output extension to input extension in order to overwrite the original file\n        // (default would've been .pred.xml)\n        command.add(\"--data.gt_extension\");\n        command.add(\".xml\");\n        command.add(\"--data.pred_extension\");\n        command.add(\".xml\");\n\n        command.add(\"--data.text_index\");\n        command.add(\"1\");\n\n        command.add(\"--verbose\");\n        command.add(\"True\");\n\n        command.add(\"--predictor.progress_bar\");\n        command.add(\"False\");\n\n        processHandler = new ProcessHandler();\n        processHandler.setFetchProcessConsole(true);\n        processHandler.startProcess(\"calamari-predict\", command, false);\n\n        // Execute progress update to fill processState data structure with correct values\n        getProgress();\n        // Process extension to ocropus-gpageseg script\n        createSkippedSegments();\n\n        progress = 100;\n        RecognitionRunning = false;\n\n        // Clean up temp segmentListFile\n        // segmentListFile.delete();\n    }\n\n    /**\n     * Resets the progress (use if an error occurs)\n     */\n    public void resetProgress() {\n        RecognitionRunning = false;\n        progress = -1;\n    }\n\n    /**\n     * Cancels the process\n     */\n    public void cancelProcess() {\n        if (processHandler != null)\n            processHandler.stopProcess();\n        RecognitionRunning = false;\n    }\n\n    /**\n     * Returns the Ids of the pages, for which line segmentation was already executed\n     *\n     * @return List with page ids\n     * @throws IOException\n     */\n    public ArrayList<String> getValidPageIds() throws IOException {\n        // Get all pages and check which ones are already line segmented\n        ArrayList<String> validPageIds = new ArrayList<String>();\n        ArrayList<String> allPageIds = genericHelper.getPageList(\"Original\");\n        for (String pageId : allPageIds) {\n            if (procStateCol.lineSegmentationState(pageId) == true)\n                validPageIds.add(pageId);\n        }\n\n        Collections.sort(validPageIds);\n        return validPageIds;\n    }\n\n    /**\n     * Deletion of old process related files\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     */\n    public void deleteOldFiles(List<String> pageIds) throws IOException {\n        // Delete potential TextEquivs already existing in the page xmls\n        for(String pageId : pageIds) {\n            File pageXML = new File(projConf.OCR_DIR + pageId + projConf.CONF_EXT);\n            if (!pageXML.exists())\n                return;\n\n            // Load pageXML and replace/delete all Textline text content\n            String pageXMLContent = new String(Files.readAllBytes(pageXML.toPath()));\n            pageXMLContent = pageXMLContent.replaceAll(\"\\\\<TextEquiv[^>]+?index=\\\"[^0]\\\"[^>]*?\\\\>[^<]*?\\\\<\\\\/TextEquiv\\\\>\", \"\");\n\n            // Save new pageXML\n            try (FileWriter fileWriter = new FileWriter(pageXML)) {\n                fileWriter.write(pageXMLContent);\n                fileWriter.flush();\n                fileWriter.close();\n            }\n    \t}\n    }\n\n    /**\n     * Creates the recognition files of the linesegments that were skipped by the ocropus-rpred script\n     *\n     * @throws IOException\n     */\n    public void createSkippedSegments() throws IOException{\n        for(String pageId : processState.keySet()) {\n            for(String segmentId :processState.get(pageId).keySet()) {\n                for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {\n                    if (processState.get(pageId).get(segmentId).get(lineSegmentId))\n                        continue;\n\n                    FileUtils.writeStringToFile(new File(projConf.PAGE_DIR + pageId + File.separator +\n                        segmentId + File.separator + lineSegmentId + projConf.REC_EXT), \"\", \"UTF8\");\n                }\n            }\n        }\n    }\n\n    /**\n     * Checks if process depending files already exist\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     * @return Information if files exist\n     */\n    public boolean doOldFilesExist(String[] pageIds) {\n        for (String pageId : pageIds) {\n            if (procStateCol.recognitionState(pageId))\n                return true;\n        }\n        return false;\n    }\n\n    /**\n     * Lists all available Models from the model directory\n     * Consider the subsequent information to load models correctly\n     *\n     * Possible model location directories:\n     * ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR\n     * ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR\n     *\n     * Model path structures on the filesystem:\n     * Default: OS_PATH/{TRAINING_IDENTIFIER}/{ID}.ckpt.json\n     * Custom:  OS_PATH/{PROJECT_NAME}/{TRAINING_IDENTIFIER}/{ID}.ckpt.json\n     *\n     * Example: /var/ocr4all/models/default/Baiter_000/Baiter.ckpt.json\n     * Display: Baiter_000/Baiter\n     * Example: /var/ocr4all/models/custom/Bibel/0/0.ckpt.json\n     * Display: Bibel/0/0\n     * Example: /var/ocr4all/models/custom/Bibel/heading/0.ckpt.json\n     * Display: Bibel/heading/0\n     *\n     * The models need to be in the following structure:\n     * ANY_PATH/{MODEL_NAME}/ANY_NAME.ckpt.json\n     *\n     * @return Map of models (key = modelName | value = path)\n     * @throws IOException\n     */\n    public static TreeMap<String, String> listModels() throws IOException{\n        TreeMap<String, String> models = new TreeMap<String, String>();\n\n        File modelsDir = new File(ProjectConfiguration.PROJ_MODEL_DIR);\n        if (!modelsDir.exists())\n            return models;\n\n        // Add all models to map (follow symbolic links on the filesystem due to Docker container)\n        Files.walk(Paths.get(ProjectConfiguration.PROJ_MODEL_DIR), FileVisitOption.FOLLOW_LINKS)\n        .map(Path::toFile)\n        .filter(fileEntry -> fileEntry.getName().endsWith(ProjectConfiguration.MODEL_EXT))\n        .forEach(\n            fileEntry -> {\n                // Remove OS path and model extension from display string (only display significant information)\n                String modelName = fileEntry.getAbsolutePath();\n                modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR, \"\");\n                modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR, \"\");\n                modelName = modelName.replace(ProjectConfiguration.MODEL_EXT, \"\");\n\n                models.put(modelName, fileEntry.getAbsolutePath());\n        });\n\n        return models;\n    }\n\n    /**\n     * Determines conflicts with the process\n     *\n     * @param currentProcesses Processes that are currently running\n     * @param inProcessFlow Indicates if the process is executed within the ProcessFlow\n     * @return Type of process conflict\n     */\n    public int getConflictType(List<String> currentProcesses, boolean inProcessFlow) {\n        return ProcessConflictDetector.recognitionConflict(currentProcesses, inProcessFlow);\n    }\n}\n"
                },
                "compile_error_details": {
                    "src/main/java/de/uniwue/helper/LineSegmentationHelper.java": {
                        "163": {
                            "lines": [
                                {
                                    "line_no": 162,
                                    "content": "        ObjectWriter writer = mapper.writer();"
                                },
                                {
                                    "line_no": 163,
                                    "content": "        writer.writeValue(segmentListFile, dataList);"
                                },
                                {
                                    "line_no": 164,
                                    "content": ""
                                }
                            ],
                            "error_texts": [
                                "[163,26] cannot access com.fasterxml.jackson.core.exc.StreamWriteException\n",
                                "[163,26] cannot access com.fasterxml.jackson.core.exc.StreamWriteException\nclass file for com.fasterxml.jackson.core.exc.StreamWriteException not found\n"
                            ]
                        }
                    }
                }
            },
            "error": "cannot access com.fasterxml.jackson.core.exc.StreamWriteException\n",
            "span_id": 9212939615209354384
        },
        {
            "input": "```diff\n--- a/src/main/java/de/uniwue/helper/RecognitionHelper.java\n+++ b/src/main/java/de/uniwue/helper/RecognitionHelper.java\n@@ -14,6 +14,7 @@ import java.util.TreeMap;\n \n import org.apache.commons.io.FileUtils;\n \n+import com.fasterxml.jackson.core.JsonProcessingException;\n import com.fasterxml.jackson.databind.ObjectMapper;\n import com.fasterxml.jackson.databind.ObjectWriter;\n import com.fasterxml.jackson.databind.node.ArrayNode;\n@@ -242,7 +243,11 @@ public class RecognitionHelper {\n \t\t\t\tdataList.add(pageList);\n \t\t\t}\n \t\t\tObjectWriter writer = mapper.writer();\n-\t\t\twriter.writeValue(segmentListFile, dataList);\n+\t\t\ttry {\n+\t\t\t\twriter.writeValue(segmentListFile, dataList);\n+\t\t\t} catch (JsonProcessingException e) {\n+\t\t\t\tthrow new IOException(\"Error writing JSON data\", e);\n+\t\t\t}\n \n             processHandler = new ProcessHandler();\n             processHandler.setFetchProcessConsole(true);\n```",
            "output": {
                "compilation_has_succeeded": false,
                "test_has_succeeded": false,
                "error_text": "cannot access com.fasterxml.jackson.core.exc.StreamWriteException\n",
                "updated_files": {
                    "src/main/java/de/uniwue/helper/RecognitionHelper.java": "package de.uniwue.helper;\n\nimport java.io.File;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.nio.file.*;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.TreeMap;\n\nimport org.apache.commons.io.FileUtils;\n\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.ObjectWriter;\nimport com.fasterxml.jackson.databind.node.ArrayNode;\n\nimport de.uniwue.config.ProjectConfiguration;\nimport de.uniwue.feature.ProcessConflictDetector;\nimport de.uniwue.feature.ProcessHandler;\nimport de.uniwue.feature.ProcessStateCollector;\n\n/**\n * Helper class for recognition module\n */\npublic class RecognitionHelper {\n    /**\n     * Object to access project configuration\n     */\n    private ProjectConfiguration projConf;\n\n    /**\n     * Image type of the project\n     * Possible values: { Binary, Gray }\n     */\n    private String projectImageType;\n\n\n    /**\n     * Object to use generic functionalities\n     */\n    private GenericHelper genericHelper;\n\n    /**\n     * Object to determine process states\n     */\n    private ProcessStateCollector procStateCol;\n\n    /**\n     * Helper object for process handling\n     */\n    private ProcessHandler processHandler;\n\n    /**\n     * Progress of the Recognition process\n     */\n    private int progress = -1;\n\n    /**\n     * Indicates if a Recognition process is already running\n     */\n    private boolean RecognitionRunning = false;\n\n    /**\n     * Last time the images/pagexml are modified\n     */\n    private Map<String,Long> imagesLastModified;\n\n    /**\n     * Structure to monitor the progress of the process\n     * pageId : segmentId : lineSegmentId : processedState\n     *\n     * Structure example:\n     * {\n     *     \"0002\": {\n     *         \"0002__000__paragraph\" : {\n     *             \"0002__000__paragraph__000\" : true,\n     *             \"0002__000__paragraph__001\" : false,\n     *             ...\n     *         },\n     *         ...\n     *     },\n     *     ...\n     * }\n     */\n    private TreeMap<String,TreeMap<String, TreeMap<String, Boolean>>> processState = new TreeMap<>();\n\n    /**\n     * Constructor\n     *\n     * @param projectDir Path to the project directory\n     * @param projectImageType Type of the project (binary, gray)\n     *\n     */\n    public RecognitionHelper(String projectDir, String projectImageType) {\n        this.projectImageType = projectImageType;\n        projConf = new ProjectConfiguration(projectDir);\n        genericHelper = new GenericHelper(projConf);\n        procStateCol = new ProcessStateCollector(projConf, projectImageType);\n        processHandler = new ProcessHandler();\n    }\n\n    /**\n     * Gets the process handler object\n     *\n     * @return Returns the process Helper\n     */\n    public ProcessHandler getProcessHandler() {\n        return processHandler;\n    }\n\n    /**\n     * Initializes the structure with which the progress of the process can be monitored\n     *\n     * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)\n     * @throws IOException\n     */\n    public void initialize(List<String> pageIds) throws IOException {\n        // Init the listener for image modification\n        imagesLastModified = new HashMap<>();\n        for(String pageId: pageIds) {\n            final String pageXML = projConf.OCR_DIR + pageId + projConf.CONF_EXT;\n            imagesLastModified.put(pageXML,new File(pageXML).lastModified());\n        }\n    }\n\n    /**\n     * Returns the absolute path of all line segment images for the pages in the processState\n     *\n     * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)\n     * @return List of line segment images\n     * @throws IOException\n     */\n    public List<String> getLineSegmentImagesForCurrentProcess(List<String> pageIds) throws IOException {\n        List<String> LineSegmentsOfPage = new ArrayList<String>();\n        for (String pageId : processState.keySet()) {\n            for (String segmentId : processState.get(pageId).keySet()) {\n                for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {\n                    LineSegmentsOfPage.add(projConf.PAGE_DIR + pageId + File.separator + segmentId +\n                        File.separator + lineSegmentId + projConf.getImageExtensionByType(projectImageType));\n                }\n            }\n        }\n        return LineSegmentsOfPage;\n    }\n\n    /**\n     * Returns the progress of the process\n     *\n     * @return Progress percentage\n     * @throws IOException\n     */\n    public int getProgress() throws IOException {\n        // Prevent function from calculation progress if process is not running\n        if (!RecognitionRunning)\n            return progress;\n\n        int modifiedCount = 0;\n        if(imagesLastModified != null) {\n            for(String pagexml : imagesLastModified.keySet()) {\n                if(imagesLastModified.get(pagexml) < new File(pagexml).lastModified()) {\n                    modifiedCount++;\n                }\n            }\n            progress = (modifiedCount*100) / imagesLastModified.size();\n        } else {\n            progress = -1;\n        }\n        return progress;\n    }\n\n    /**\n     * Extracts checkpoints of a String joined by a whitespace\n     *\n     * @return List of checkpoints\n     * @throws IOException\n     */\n    public List<String> extractModelsOfJoinedString(String joinedckptString){\n        String [] checkpoints = joinedckptString.split(ProjectConfiguration.MODEL_EXT + \" \");\n        List<String> ckptList = new ArrayList<>();\n        Iterator <String> ckptIterator= Arrays.asList(checkpoints).iterator();\n        while (ckptIterator.hasNext()) {\n            String ckpt = ckptIterator.next();\n            if (ckptIterator.hasNext())\n                ckpt = ckpt + ProjectConfiguration.MODEL_EXT;\n            ckptList.add(ckpt);\n        }\n        return ckptList;\n    }\n    /**\n     * Executes OCR on a list of pages\n     * Achieved with the help of the external python program \"calamary-predict\"\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     * @param cmdArgs Command line arguments for \"calamary-predict\"\n     * @throws IOException\n     */\n    public void execute(List<String> pageIds, final List<String> cmdArgs) throws IOException {\n        RecognitionRunning = true;\n        progress = 0;\n\n        List<String> cmdArgsWork = new ArrayList<>(cmdArgs);\n\n        //// Estimate Skew\n        if (cmdArgsWork.contains(\"--estimate_skew\")) {\n        \t// Calculate the skew of all regions where none was calculated before\n        \tList<String> skewparams = new ArrayList<>();\n            skewparams.add(\"skewestimate\");\n        \tfinal int maxskewIndex = cmdArgsWork.indexOf(\"--maxskew\");\n        \tif(maxskewIndex > -1) {\n        \t\tskewparams.add(cmdArgsWork.remove(maxskewIndex));\n        \t\tskewparams.add(cmdArgsWork.remove(maxskewIndex));\n        \t}\n        \tfinal int skewstepsIndex = cmdArgsWork.indexOf(\"--skewsteps\");\n        \tif(skewstepsIndex > -1) {\n        \t\tskewparams.add(cmdArgsWork.remove(skewstepsIndex));\n        \t\tskewparams.add(cmdArgsWork.remove(skewstepsIndex));\n        \t}\n\n\t\t\t// Create temp json file with all segment images (to not overload parameter list)\n\t\t\t// Temp file in a temp folder named \"skew-<random numbers>.json\"\n\t\t\tFile segmentListFile = File.createTempFile(\"skew-\",\".json\");\n\t\t\tskewparams.add(segmentListFile.toString());\n\t\t\tsegmentListFile.deleteOnExit(); // Delete if OCR4all terminates\n\t\t\tObjectMapper mapper = new ObjectMapper();\n\t\t\tArrayNode dataList = mapper.createArrayNode();\n\t\t\tfor (String pageId : pageIds) {\n\t\t\t\tArrayNode pageList = mapper.createArrayNode();\n\t\t\t\tpageList.add(projConf.getImageDirectoryByType(projectImageType) + pageId +\n\t\t\t\t\t\tprojConf.getImageExtensionByType(projectImageType));\n\t\t\t\tfinal String pageXML = projConf.OCR_DIR + pageId + projConf.CONF_EXT;\n\t\t\t\tpageList.add(pageXML);\n\n\t\t\t\t// Add affected line segment images with their absolute path to the json file\n\t\t\t\tdataList.add(pageList);\n\t\t\t}\n\t\t\tObjectWriter writer = mapper.writer();\n\t\t\ttry {\n\t\t\t\twriter.writeValue(segmentListFile, dataList);\n\t\t\t} catch (JsonProcessingException e) {\n\t\t\t\tthrow new IOException(\"Error writing JSON data\", e);\n\t\t\t}\n\n            processHandler = new ProcessHandler();\n            processHandler.setFetchProcessConsole(true);\n            processHandler.startProcess(\"ocr4all-helper-scripts\", skewparams, false);\n\n        \tcmdArgsWork.remove(\"--estimate_skew\");\n        }\n\n\n        //// Recognize\n\t\t// Reset recognition data\n\t\tdeleteOldFiles(pageIds);\n\t\tinitialize(pageIds);\n\n        int index;\n        if (cmdArgsWork.contains(\"--checkpoint\")) {\n            index = cmdArgsWork.indexOf(\"--checkpoint\");\n            for(String ckpt : extractModelsOfJoinedString(cmdArgsWork.get(index + 1))) {\n                if (!new File(ckpt).exists())\n                    throw new IOException(\"Model does not exist under the specified path\");\n            }\n        }\n\n        List<String> command = new ArrayList<>();\n        // Ugly hack but helpers will be rewritten for the next release anyways. Don't use as basis for future code!\n        if(cmdArgsWork.contains(\"--data.output_glyphs\")){\n            cmdArgsWork.remove(\"--data.output_glyphs\");\n            command.add(\"--data.output_glyphs\");\n            command.add(\"True\");\n        }\n        if(cmdArgsWork.contains(\"--data.output_confidences\")){\n            cmdArgsWork.remove(\"--data.output_confidences\");\n            command.add(\"--data.output_confidences\");\n            command.add(\"True\");\n        }\n\n        command.add(\"--data.images\");\n        // Create temp json file with all segment images (to not overload parameter list)\n\t\t// Temp file in a temp folder named \"calamari-<random numbers>.json\"\n        File segmentListFile = File.createTempFile(\"calamari-\",\".files\");\n        segmentListFile.deleteOnExit();\n\n        List<String> content = new ArrayList<>();\n        for (String pageId : pageIds) {\n            // Add affected images with their absolute path to the file\n            content.add(projConf.getImageDirectoryByType(projectImageType) + pageId +\n                                projConf.getImageExtensionByType(projectImageType));\n        }\n        Files.write(segmentListFile.toPath(), content, StandardOpenOption.APPEND);\n        command.add(segmentListFile.toString());\n\n        //Add checkpoints\n        Iterator<String> cmdArgsIterator = cmdArgsWork.iterator();\n        while (cmdArgsIterator.hasNext()) {\n            String arg = cmdArgsIterator.next();\n            command.add(arg);\n            if (arg.equals(\"--checkpoint\") && cmdArgsIterator.hasNext()) {\n                command.addAll(extractModelsOfJoinedString(cmdArgsIterator.next()));\n            }\n        }\n\n        command.add(\"--data\");\n        command.add(\"PageXML\");\n        // Set output extension to input extension in order to overwrite the original file\n        // (default would've been .pred.xml)\n        command.add(\"--data.gt_extension\");\n        command.add(\".xml\");\n        command.add(\"--data.pred_extension\");\n        command.add(\".xml\");\n\n        command.add(\"--data.text_index\");\n        command.add(\"1\");\n\n        command.add(\"--verbose\");\n        command.add(\"True\");\n\n        command.add(\"--predictor.progress_bar\");\n        command.add(\"False\");\n\n        processHandler = new ProcessHandler();\n        processHandler.setFetchProcessConsole(true);\n        processHandler.startProcess(\"calamari-predict\", command, false);\n\n        // Execute progress update to fill processState data structure with correct values\n        getProgress();\n        // Process extension to ocropus-gpageseg script\n        createSkippedSegments();\n\n        progress = 100;\n        RecognitionRunning = false;\n\n        // Clean up temp segmentListFile\n        // segmentListFile.delete();\n    }\n\n    /**\n     * Resets the progress (use if an error occurs)\n     */\n    public void resetProgress() {\n        RecognitionRunning = false;\n        progress = -1;\n    }\n\n    /**\n     * Cancels the process\n     */\n    public void cancelProcess() {\n        if (processHandler != null)\n            processHandler.stopProcess();\n        RecognitionRunning = false;\n    }\n\n    /**\n     * Returns the Ids of the pages, for which line segmentation was already executed\n     *\n     * @return List with page ids\n     * @throws IOException\n     */\n    public ArrayList<String> getValidPageIds() throws IOException {\n        // Get all pages and check which ones are already line segmented\n        ArrayList<String> validPageIds = new ArrayList<String>();\n        ArrayList<String> allPageIds = genericHelper.getPageList(\"Original\");\n        for (String pageId : allPageIds) {\n            if (procStateCol.lineSegmentationState(pageId) == true)\n                validPageIds.add(pageId);\n        }\n\n        Collections.sort(validPageIds);\n        return validPageIds;\n    }\n\n    /**\n     * Deletion of old process related files\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     */\n    public void deleteOldFiles(List<String> pageIds) throws IOException {\n        // Delete potential TextEquivs already existing in the page xmls\n        for(String pageId : pageIds) {\n            File pageXML = new File(projConf.OCR_DIR + pageId + projConf.CONF_EXT);\n            if (!pageXML.exists())\n                return;\n\n            // Load pageXML and replace/delete all Textline text content\n            String pageXMLContent = new String(Files.readAllBytes(pageXML.toPath()));\n            pageXMLContent = pageXMLContent.replaceAll(\"\\\\<TextEquiv[^>]+?index=\\\"[^0]\\\"[^>]*?\\\\>[^<]*?\\\\<\\\\/TextEquiv\\\\>\", \"\");\n\n            // Save new pageXML\n            try (FileWriter fileWriter = new FileWriter(pageXML)) {\n                fileWriter.write(pageXMLContent);\n                fileWriter.flush();\n                fileWriter.close();\n            }\n    \t}\n    }\n\n    /**\n     * Creates the recognition files of the linesegments that were skipped by the ocropus-rpred script\n     *\n     * @throws IOException\n     */\n    public void createSkippedSegments() throws IOException{\n        for(String pageId : processState.keySet()) {\n            for(String segmentId :processState.get(pageId).keySet()) {\n                for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {\n                    if (processState.get(pageId).get(segmentId).get(lineSegmentId))\n                        continue;\n\n                    FileUtils.writeStringToFile(new File(projConf.PAGE_DIR + pageId + File.separator +\n                        segmentId + File.separator + lineSegmentId + projConf.REC_EXT), \"\", \"UTF8\");\n                }\n            }\n        }\n    }\n\n    /**\n     * Checks if process depending files already exist\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     * @return Information if files exist\n     */\n    public boolean doOldFilesExist(String[] pageIds) {\n        for (String pageId : pageIds) {\n            if (procStateCol.recognitionState(pageId))\n                return true;\n        }\n        return false;\n    }\n\n    /**\n     * Lists all available Models from the model directory\n     * Consider the subsequent information to load models correctly\n     *\n     * Possible model location directories:\n     * ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR\n     * ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR\n     *\n     * Model path structures on the filesystem:\n     * Default: OS_PATH/{TRAINING_IDENTIFIER}/{ID}.ckpt.json\n     * Custom:  OS_PATH/{PROJECT_NAME}/{TRAINING_IDENTIFIER}/{ID}.ckpt.json\n     *\n     * Example: /var/ocr4all/models/default/Baiter_000/Baiter.ckpt.json\n     * Display: Baiter_000/Baiter\n     * Example: /var/ocr4all/models/custom/Bibel/0/0.ckpt.json\n     * Display: Bibel/0/0\n     * Example: /var/ocr4all/models/custom/Bibel/heading/0.ckpt.json\n     * Display: Bibel/heading/0\n     *\n     * The models need to be in the following structure:\n     * ANY_PATH/{MODEL_NAME}/ANY_NAME.ckpt.json\n     *\n     * @return Map of models (key = modelName | value = path)\n     * @throws IOException\n     */\n    public static TreeMap<String, String> listModels() throws IOException{\n        TreeMap<String, String> models = new TreeMap<String, String>();\n\n        File modelsDir = new File(ProjectConfiguration.PROJ_MODEL_DIR);\n        if (!modelsDir.exists())\n            return models;\n\n        // Add all models to map (follow symbolic links on the filesystem due to Docker container)\n        Files.walk(Paths.get(ProjectConfiguration.PROJ_MODEL_DIR), FileVisitOption.FOLLOW_LINKS)\n        .map(Path::toFile)\n        .filter(fileEntry -> fileEntry.getName().endsWith(ProjectConfiguration.MODEL_EXT))\n        .forEach(\n            fileEntry -> {\n                // Remove OS path and model extension from display string (only display significant information)\n                String modelName = fileEntry.getAbsolutePath();\n                modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR, \"\");\n                modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR, \"\");\n                modelName = modelName.replace(ProjectConfiguration.MODEL_EXT, \"\");\n\n                models.put(modelName, fileEntry.getAbsolutePath());\n        });\n\n        return models;\n    }\n\n    /**\n     * Determines conflicts with the process\n     *\n     * @param currentProcesses Processes that are currently running\n     * @param inProcessFlow Indicates if the process is executed within the ProcessFlow\n     * @return Type of process conflict\n     */\n    public int getConflictType(List<String> currentProcesses, boolean inProcessFlow) {\n        return ProcessConflictDetector.recognitionConflict(currentProcesses, inProcessFlow);\n    }\n}\n"
                },
                "compile_error_details": {
                    "src/main/java/de/uniwue/helper/LineSegmentationHelper.java": {
                        "163": {
                            "lines": [
                                {
                                    "line_no": 162,
                                    "content": "        ObjectWriter writer = mapper.writer();"
                                },
                                {
                                    "line_no": 163,
                                    "content": "        writer.writeValue(segmentListFile, dataList);"
                                },
                                {
                                    "line_no": 164,
                                    "content": ""
                                }
                            ],
                            "error_texts": [
                                "[163,26] cannot access com.fasterxml.jackson.core.exc.StreamWriteException\n",
                                "[163,26] cannot access com.fasterxml.jackson.core.exc.StreamWriteException\nclass file for com.fasterxml.jackson.core.exc.StreamWriteException not found\n"
                            ]
                        }
                    }
                }
            },
            "error": "cannot access com.fasterxml.jackson.core.exc.StreamWriteException\n",
            "span_id": 12436707657385859144
        },
        {
            "input": "```diff\n--- a/src/main/java/de/uniwue/helper/RecognitionHelper.java\n+++ b/src/main/java/de/uniwue/helper/RecognitionHelper.java\n@@ -14,7 +14,6 @@ import java.util.TreeMap;\n \n import org.apache.commons.io.FileUtils;\n \n-import com.fasterxml.jackson.core.JsonProcessingException;\n import com.fasterxml.jackson.databind.ObjectMapper;\n import com.fasterxml.jackson.databind.ObjectWriter;\n import com.fasterxml.jackson.databind.node.ArrayNode;\n@@ -243,11 +242,7 @@ public class RecognitionHelper {\n \t\t\t\tdataList.add(pageList);\n \t\t\t}\n \t\t\tObjectWriter writer = mapper.writer();\n-\t\t\ttry {\n-\t\t\t\twriter.writeValue(segmentListFile, dataList);\n-\t\t\t} catch (JsonProcessingException e) {\n-\t\t\t\tthrow new IOException(\"Error writing JSON data\", e);\n-\t\t\t}\n+\t\t\twriter.writeValue(segmentListFile, dataList);\n \n             processHandler = new ProcessHandler();\n             processHandler.setFetchProcessConsole(true);\n```",
            "output": {
                "compilation_has_succeeded": false,
                "test_has_succeeded": false,
                "error_text": "cannot access com.fasterxml.jackson.core.exc.StreamWriteException\n",
                "updated_files": {
                    "src/main/java/de/uniwue/helper/RecognitionHelper.java": "package de.uniwue.helper;\n\nimport java.io.File;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.nio.file.*;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.TreeMap;\n\nimport org.apache.commons.io.FileUtils;\n\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.ObjectWriter;\nimport com.fasterxml.jackson.databind.node.ArrayNode;\n\nimport de.uniwue.config.ProjectConfiguration;\nimport de.uniwue.feature.ProcessConflictDetector;\nimport de.uniwue.feature.ProcessHandler;\nimport de.uniwue.feature.ProcessStateCollector;\n\n/**\n * Helper class for recognition module\n */\npublic class RecognitionHelper {\n    /**\n     * Object to access project configuration\n     */\n    private ProjectConfiguration projConf;\n\n    /**\n     * Image type of the project\n     * Possible values: { Binary, Gray }\n     */\n    private String projectImageType;\n\n\n    /**\n     * Object to use generic functionalities\n     */\n    private GenericHelper genericHelper;\n\n    /**\n     * Object to determine process states\n     */\n    private ProcessStateCollector procStateCol;\n\n    /**\n     * Helper object for process handling\n     */\n    private ProcessHandler processHandler;\n\n    /**\n     * Progress of the Recognition process\n     */\n    private int progress = -1;\n\n    /**\n     * Indicates if a Recognition process is already running\n     */\n    private boolean RecognitionRunning = false;\n\n    /**\n     * Last time the images/pagexml are modified\n     */\n    private Map<String,Long> imagesLastModified;\n\n    /**\n     * Structure to monitor the progress of the process\n     * pageId : segmentId : lineSegmentId : processedState\n     *\n     * Structure example:\n     * {\n     *     \"0002\": {\n     *         \"0002__000__paragraph\" : {\n     *             \"0002__000__paragraph__000\" : true,\n     *             \"0002__000__paragraph__001\" : false,\n     *             ...\n     *         },\n     *         ...\n     *     },\n     *     ...\n     * }\n     */\n    private TreeMap<String,TreeMap<String, TreeMap<String, Boolean>>> processState = new TreeMap<>();\n\n    /**\n     * Constructor\n     *\n     * @param projectDir Path to the project directory\n     * @param projectImageType Type of the project (binary, gray)\n     *\n     */\n    public RecognitionHelper(String projectDir, String projectImageType) {\n        this.projectImageType = projectImageType;\n        projConf = new ProjectConfiguration(projectDir);\n        genericHelper = new GenericHelper(projConf);\n        procStateCol = new ProcessStateCollector(projConf, projectImageType);\n        processHandler = new ProcessHandler();\n    }\n\n    /**\n     * Gets the process handler object\n     *\n     * @return Returns the process Helper\n     */\n    public ProcessHandler getProcessHandler() {\n        return processHandler;\n    }\n\n    /**\n     * Initializes the structure with which the progress of the process can be monitored\n     *\n     * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)\n     * @throws IOException\n     */\n    public void initialize(List<String> pageIds) throws IOException {\n        // Init the listener for image modification\n        imagesLastModified = new HashMap<>();\n        for(String pageId: pageIds) {\n            final String pageXML = projConf.OCR_DIR + pageId + projConf.CONF_EXT;\n            imagesLastModified.put(pageXML,new File(pageXML).lastModified());\n        }\n    }\n\n    /**\n     * Returns the absolute path of all line segment images for the pages in the processState\n     *\n     * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)\n     * @return List of line segment images\n     * @throws IOException\n     */\n    public List<String> getLineSegmentImagesForCurrentProcess(List<String> pageIds) throws IOException {\n        List<String> LineSegmentsOfPage = new ArrayList<String>();\n        for (String pageId : processState.keySet()) {\n            for (String segmentId : processState.get(pageId).keySet()) {\n                for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {\n                    LineSegmentsOfPage.add(projConf.PAGE_DIR + pageId + File.separator + segmentId +\n                        File.separator + lineSegmentId + projConf.getImageExtensionByType(projectImageType));\n                }\n            }\n        }\n        return LineSegmentsOfPage;\n    }\n\n    /**\n     * Returns the progress of the process\n     *\n     * @return Progress percentage\n     * @throws IOException\n     */\n    public int getProgress() throws IOException {\n        // Prevent function from calculation progress if process is not running\n        if (!RecognitionRunning)\n            return progress;\n\n        int modifiedCount = 0;\n        if(imagesLastModified != null) {\n            for(String pagexml : imagesLastModified.keySet()) {\n                if(imagesLastModified.get(pagexml) < new File(pagexml).lastModified()) {\n                    modifiedCount++;\n                }\n            }\n            progress = (modifiedCount*100) / imagesLastModified.size();\n        } else {\n            progress = -1;\n        }\n        return progress;\n    }\n\n    /**\n     * Extracts checkpoints of a String joined by a whitespace\n     *\n     * @return List of checkpoints\n     * @throws IOException\n     */\n    public List<String> extractModelsOfJoinedString(String joinedckptString){\n        String [] checkpoints = joinedckptString.split(ProjectConfiguration.MODEL_EXT + \" \");\n        List<String> ckptList = new ArrayList<>();\n        Iterator <String> ckptIterator= Arrays.asList(checkpoints).iterator();\n        while (ckptIterator.hasNext()) {\n            String ckpt = ckptIterator.next();\n            if (ckptIterator.hasNext())\n                ckpt = ckpt + ProjectConfiguration.MODEL_EXT;\n            ckptList.add(ckpt);\n        }\n        return ckptList;\n    }\n    /**\n     * Executes OCR on a list of pages\n     * Achieved with the help of the external python program \"calamary-predict\"\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     * @param cmdArgs Command line arguments for \"calamary-predict\"\n     * @throws IOException\n     */\n    public void execute(List<String> pageIds, final List<String> cmdArgs) throws IOException {\n        RecognitionRunning = true;\n        progress = 0;\n\n        List<String> cmdArgsWork = new ArrayList<>(cmdArgs);\n\n        //// Estimate Skew\n        if (cmdArgsWork.contains(\"--estimate_skew\")) {\n        \t// Calculate the skew of all regions where none was calculated before\n        \tList<String> skewparams = new ArrayList<>();\n            skewparams.add(\"skewestimate\");\n        \tfinal int maxskewIndex = cmdArgsWork.indexOf(\"--maxskew\");\n        \tif(maxskewIndex > -1) {\n        \t\tskewparams.add(cmdArgsWork.remove(maxskewIndex));\n        \t\tskewparams.add(cmdArgsWork.remove(maxskewIndex));\n        \t}\n        \tfinal int skewstepsIndex = cmdArgsWork.indexOf(\"--skewsteps\");\n        \tif(skewstepsIndex > -1) {\n        \t\tskewparams.add(cmdArgsWork.remove(skewstepsIndex));\n        \t\tskewparams.add(cmdArgsWork.remove(skewstepsIndex));\n        \t}\n\n\t\t\t// Create temp json file with all segment images (to not overload parameter list)\n\t\t\t// Temp file in a temp folder named \"skew-<random numbers>.json\"\n\t\t\tFile segmentListFile = File.createTempFile(\"skew-\",\".json\");\n\t\t\tskewparams.add(segmentListFile.toString());\n\t\t\tsegmentListFile.deleteOnExit(); // Delete if OCR4all terminates\n\t\t\tObjectMapper mapper = new ObjectMapper();\n\t\t\tArrayNode dataList = mapper.createArrayNode();\n\t\t\tfor (String pageId : pageIds) {\n\t\t\t\tArrayNode pageList = mapper.createArrayNode();\n\t\t\t\tpageList.add(projConf.getImageDirectoryByType(projectImageType) + pageId +\n\t\t\t\t\t\tprojConf.getImageExtensionByType(projectImageType));\n\t\t\t\tfinal String pageXML = projConf.OCR_DIR + pageId + projConf.CONF_EXT;\n\t\t\t\tpageList.add(pageXML);\n\n\t\t\t\t// Add affected line segment images with their absolute path to the json file\n\t\t\t\tdataList.add(pageList);\n\t\t\t}\n\t\t\tObjectWriter writer = mapper.writer();\n\t\t\twriter.writeValue(segmentListFile, dataList);\n\n            processHandler = new ProcessHandler();\n            processHandler.setFetchProcessConsole(true);\n            processHandler.startProcess(\"ocr4all-helper-scripts\", skewparams, false);\n\n        \tcmdArgsWork.remove(\"--estimate_skew\");\n        }\n\n\n        //// Recognize\n\t\t// Reset recognition data\n\t\tdeleteOldFiles(pageIds);\n\t\tinitialize(pageIds);\n\n        int index;\n        if (cmdArgsWork.contains(\"--checkpoint\")) {\n            index = cmdArgsWork.indexOf(\"--checkpoint\");\n            for(String ckpt : extractModelsOfJoinedString(cmdArgsWork.get(index + 1))) {\n                if (!new File(ckpt).exists())\n                    throw new IOException(\"Model does not exist under the specified path\");\n            }\n        }\n\n        List<String> command = new ArrayList<>();\n        // Ugly hack but helpers will be rewritten for the next release anyways. Don't use as basis for future code!\n        if(cmdArgsWork.contains(\"--data.output_glyphs\")){\n            cmdArgsWork.remove(\"--data.output_glyphs\");\n            command.add(\"--data.output_glyphs\");\n            command.add(\"True\");\n        }\n        if(cmdArgsWork.contains(\"--data.output_confidences\")){\n            cmdArgsWork.remove(\"--data.output_confidences\");\n            command.add(\"--data.output_confidences\");\n            command.add(\"True\");\n        }\n\n        command.add(\"--data.images\");\n        // Create temp json file with all segment images (to not overload parameter list)\n\t\t// Temp file in a temp folder named \"calamari-<random numbers>.json\"\n        File segmentListFile = File.createTempFile(\"calamari-\",\".files\");\n        segmentListFile.deleteOnExit();\n\n        List<String> content = new ArrayList<>();\n        for (String pageId : pageIds) {\n            // Add affected images with their absolute path to the file\n            content.add(projConf.getImageDirectoryByType(projectImageType) + pageId +\n                                projConf.getImageExtensionByType(projectImageType));\n        }\n        Files.write(segmentListFile.toPath(), content, StandardOpenOption.APPEND);\n        command.add(segmentListFile.toString());\n\n        //Add checkpoints\n        Iterator<String> cmdArgsIterator = cmdArgsWork.iterator();\n        while (cmdArgsIterator.hasNext()) {\n            String arg = cmdArgsIterator.next();\n            command.add(arg);\n            if (arg.equals(\"--checkpoint\") && cmdArgsIterator.hasNext()) {\n                command.addAll(extractModelsOfJoinedString(cmdArgsIterator.next()));\n            }\n        }\n\n        command.add(\"--data\");\n        command.add(\"PageXML\");\n        // Set output extension to input extension in order to overwrite the original file\n        // (default would've been .pred.xml)\n        command.add(\"--data.gt_extension\");\n        command.add(\".xml\");\n        command.add(\"--data.pred_extension\");\n        command.add(\".xml\");\n\n        command.add(\"--data.text_index\");\n        command.add(\"1\");\n\n        command.add(\"--verbose\");\n        command.add(\"True\");\n\n        command.add(\"--predictor.progress_bar\");\n        command.add(\"False\");\n\n        processHandler = new ProcessHandler();\n        processHandler.setFetchProcessConsole(true);\n        processHandler.startProcess(\"calamari-predict\", command, false);\n\n        // Execute progress update to fill processState data structure with correct values\n        getProgress();\n        // Process extension to ocropus-gpageseg script\n        createSkippedSegments();\n\n        progress = 100;\n        RecognitionRunning = false;\n\n        // Clean up temp segmentListFile\n        // segmentListFile.delete();\n    }\n\n    /**\n     * Resets the progress (use if an error occurs)\n     */\n    public void resetProgress() {\n        RecognitionRunning = false;\n        progress = -1;\n    }\n\n    /**\n     * Cancels the process\n     */\n    public void cancelProcess() {\n        if (processHandler != null)\n            processHandler.stopProcess();\n        RecognitionRunning = false;\n    }\n\n    /**\n     * Returns the Ids of the pages, for which line segmentation was already executed\n     *\n     * @return List with page ids\n     * @throws IOException\n     */\n    public ArrayList<String> getValidPageIds() throws IOException {\n        // Get all pages and check which ones are already line segmented\n        ArrayList<String> validPageIds = new ArrayList<String>();\n        ArrayList<String> allPageIds = genericHelper.getPageList(\"Original\");\n        for (String pageId : allPageIds) {\n            if (procStateCol.lineSegmentationState(pageId) == true)\n                validPageIds.add(pageId);\n        }\n\n        Collections.sort(validPageIds);\n        return validPageIds;\n    }\n\n    /**\n     * Deletion of old process related files\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     */\n    public void deleteOldFiles(List<String> pageIds) throws IOException {\n        // Delete potential TextEquivs already existing in the page xmls\n        for(String pageId : pageIds) {\n            File pageXML = new File(projConf.OCR_DIR + pageId + projConf.CONF_EXT);\n            if (!pageXML.exists())\n                return;\n\n            // Load pageXML and replace/delete all Textline text content\n            String pageXMLContent = new String(Files.readAllBytes(pageXML.toPath()));\n            pageXMLContent = pageXMLContent.replaceAll(\"\\\\<TextEquiv[^>]+?index=\\\"[^0]\\\"[^>]*?\\\\>[^<]*?\\\\<\\\\/TextEquiv\\\\>\", \"\");\n\n            // Save new pageXML\n            try (FileWriter fileWriter = new FileWriter(pageXML)) {\n                fileWriter.write(pageXMLContent);\n                fileWriter.flush();\n                fileWriter.close();\n            }\n    \t}\n    }\n\n    /**\n     * Creates the recognition files of the linesegments that were skipped by the ocropus-rpred script\n     *\n     * @throws IOException\n     */\n    public void createSkippedSegments() throws IOException{\n        for(String pageId : processState.keySet()) {\n            for(String segmentId :processState.get(pageId).keySet()) {\n                for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {\n                    if (processState.get(pageId).get(segmentId).get(lineSegmentId))\n                        continue;\n\n                    FileUtils.writeStringToFile(new File(projConf.PAGE_DIR + pageId + File.separator +\n                        segmentId + File.separator + lineSegmentId + projConf.REC_EXT), \"\", \"UTF8\");\n                }\n            }\n        }\n    }\n\n    /**\n     * Checks if process depending files already exist\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     * @return Information if files exist\n     */\n    public boolean doOldFilesExist(String[] pageIds) {\n        for (String pageId : pageIds) {\n            if (procStateCol.recognitionState(pageId))\n                return true;\n        }\n        return false;\n    }\n\n    /**\n     * Lists all available Models from the model directory\n     * Consider the subsequent information to load models correctly\n     *\n     * Possible model location directories:\n     * ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR\n     * ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR\n     *\n     * Model path structures on the filesystem:\n     * Default: OS_PATH/{TRAINING_IDENTIFIER}/{ID}.ckpt.json\n     * Custom:  OS_PATH/{PROJECT_NAME}/{TRAINING_IDENTIFIER}/{ID}.ckpt.json\n     *\n     * Example: /var/ocr4all/models/default/Baiter_000/Baiter.ckpt.json\n     * Display: Baiter_000/Baiter\n     * Example: /var/ocr4all/models/custom/Bibel/0/0.ckpt.json\n     * Display: Bibel/0/0\n     * Example: /var/ocr4all/models/custom/Bibel/heading/0.ckpt.json\n     * Display: Bibel/heading/0\n     *\n     * The models need to be in the following structure:\n     * ANY_PATH/{MODEL_NAME}/ANY_NAME.ckpt.json\n     *\n     * @return Map of models (key = modelName | value = path)\n     * @throws IOException\n     */\n    public static TreeMap<String, String> listModels() throws IOException{\n        TreeMap<String, String> models = new TreeMap<String, String>();\n\n        File modelsDir = new File(ProjectConfiguration.PROJ_MODEL_DIR);\n        if (!modelsDir.exists())\n            return models;\n\n        // Add all models to map (follow symbolic links on the filesystem due to Docker container)\n        Files.walk(Paths.get(ProjectConfiguration.PROJ_MODEL_DIR), FileVisitOption.FOLLOW_LINKS)\n        .map(Path::toFile)\n        .filter(fileEntry -> fileEntry.getName().endsWith(ProjectConfiguration.MODEL_EXT))\n        .forEach(\n            fileEntry -> {\n                // Remove OS path and model extension from display string (only display significant information)\n                String modelName = fileEntry.getAbsolutePath();\n                modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR, \"\");\n                modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR, \"\");\n                modelName = modelName.replace(ProjectConfiguration.MODEL_EXT, \"\");\n\n                models.put(modelName, fileEntry.getAbsolutePath());\n        });\n\n        return models;\n    }\n\n    /**\n     * Determines conflicts with the process\n     *\n     * @param currentProcesses Processes that are currently running\n     * @param inProcessFlow Indicates if the process is executed within the ProcessFlow\n     * @return Type of process conflict\n     */\n    public int getConflictType(List<String> currentProcesses, boolean inProcessFlow) {\n        return ProcessConflictDetector.recognitionConflict(currentProcesses, inProcessFlow);\n    }\n}\n"
                },
                "compile_error_details": {
                    "src/main/java/de/uniwue/helper/LineSegmentationHelper.java": {
                        "163": {
                            "lines": [
                                {
                                    "line_no": 162,
                                    "content": "        ObjectWriter writer = mapper.writer();"
                                },
                                {
                                    "line_no": 163,
                                    "content": "        writer.writeValue(segmentListFile, dataList);"
                                },
                                {
                                    "line_no": 164,
                                    "content": ""
                                }
                            ],
                            "error_texts": [
                                "[163,26] cannot access com.fasterxml.jackson.core.exc.StreamWriteException\n",
                                "[163,26] cannot access com.fasterxml.jackson.core.exc.StreamWriteException\nclass file for com.fasterxml.jackson.core.exc.StreamWriteException not found\n"
                            ]
                        }
                    }
                }
            },
            "error": "cannot access com.fasterxml.jackson.core.exc.StreamWriteException\n",
            "span_id": 6026352523811284801
        },
        {
            "input": "```diff\n--- a/pom.xml\n+++ b/pom.xml\n@@ -11,7 +11,7 @@\n     <properties>\n         <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n         <java.version>11</java.version>\n-        <jackson.version>2.13.4.1</jackson.version>\n+        <jackson.version>2.13.4</jackson.version>\n     </properties>\n \n     <dependencies>\n@@ -19,6 +19,11 @@\n             <groupId>com.fasterxml.jackson.core</groupId>\n             <artifactId>jackson-databind</artifactId>\n             <version>${jackson.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-core</artifactId>\n+            <version>${jackson.version}</version>\n         </dependency>\n     </dependencies>\n </project>\n```",
            "output": {
                "compilation_has_succeeded": false,
                "test_has_succeeded": false,
                "error_text": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoMatch: hunk failed to apply!\npom.xml does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in pom.xml!\nMake extra sure the indentation is correct.\npom.xml does not contain these 7 exact lines in a row:\n```\n<properties>\n<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n<java.version>11</java.version>\n<jackson.version>2.13.4.1</jackson.version>\n</properties>\n<dependencies>\n```",
                "updated_files": {},
                "compile_error_details": {}
            },
            "error": "Failed to prepare diffs: Diff is not valid, UnifiedDiffNoMatch: hunk failed to apply!\npom.xml does not contain lines that match the diff you provided!\nTry again.\nDO NOT, NEVER, skip blank lines, comments, docstrings, etc!\nThe diff needs to apply cleanly to the lines in pom.xml!\nMake extra sure the indentation is correct.\npom.xml does not contain these 7 exact lines in a row:\n```\n<properties>\n<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n<java.version>11</java.version>\n<jackson.version>2.13.4.1</jackson.version>\n</properties>\n<dependencies>\n```",
            "span_id": 7951791181189487386
        },
        {
            "input": "```diff\n--- a/pom.xml\n+++ b/pom.xml\n@@ -80,12 +80,12 @@\n         <dependency>\n             <groupId>com.fasterxml.jackson.core</groupId>\n             <artifactId>jackson-databind</artifactId>\n-            <version>2.13.4.1</version>\n+            <version>2.13.4</version>\n         </dependency>\n         <dependency>\n             <groupId>com.fasterxml.jackson.core</groupId>\n             <artifactId>jackson-core</artifactId>\n-            <version>2.10.0</version>\n+            <version>2.13.4</version>\n         </dependency>\n         <!-- Apache Commons IO -->\n         <dependency>\n```",
            "output": {
                "compilation_has_succeeded": true,
                "test_has_succeeded": true,
                "error_text": "",
                "updated_files": {
                    "pom.xml": "<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>de.uniwue</groupId>\n    <artifactId>ocr4all</artifactId>\n    <packaging>war</packaging>\n    <version>0.6.1</version>\n    <name>OCR4all Maven Webapp</name>\n    <url>http://maven.apache.org</url>\n\n    <properties>\n        <spring.version>4.3.18.RELEASE</spring.version>\n\n        <!-- Java version -->\n        <maven.compiler.source>1.8</maven.compiler.source>\n        <maven.compiler.target>1.8</maven.compiler.target>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>junit</groupId>\n            <artifactId>junit</artifactId>\n            <version>4.13.1</version>\n            <scope>test</scope>\n        </dependency>\n\n        <!-- Spring dependencies -->\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-core</artifactId>\n            <version>${spring.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-web</artifactId>\n            <version>${spring.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-webmvc</artifactId>\n            <version>${spring.version}</version>\n        </dependency>\n\n        <!-- JSTL tag library -->\n        <dependency>\n            <groupId>jstl</groupId>\n            <artifactId>jstl</artifactId>\n            <version>1.2</version>\n            <scope>compile</scope>\n        </dependency>\n        <dependency>\n            <groupId>taglibs</groupId>\n            <artifactId>standard</artifactId>\n            <version>1.1.2</version>\n            <scope>compile</scope>\n        </dependency>\n\n        <!-- Jackson Core (JSON helper) -->\n        <dependency>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-databind</artifactId>\n            <version>2.13.4</version>\n        </dependency>\n        <dependency>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-core</artifactId>\n            <version>2.13.4</version>\n        </dependency>\n        <!-- Apache Commons IO -->\n        <dependency>\n            <groupId>commons-io</groupId>\n            <artifactId>commons-io</artifactId>\n            <version>2.7</version>\n        </dependency>\n\n        <dependency>\n            <groupId>org.apache.commons</groupId>\n            <artifactId>commons-exec</artifactId>\n            <version>1.3</version>\n        </dependency>\n\n        <!-- Javax Servlet (Request/Response) -->\n        <dependency>\n            <groupId>javax.servlet</groupId>\n            <artifactId>javax.servlet-api</artifactId>\n            <version>3.1.0</version>\n            <scope>provided</scope>\n        </dependency>\n        <!-- Javax Servlet (JSP due to Tomcat dependency) -->\n        <dependency>\n            <groupId>javax.servlet</groupId>\n            <artifactId>jsp-api</artifactId>\n            <version>2.0</version>\n            <scope>provided</scope>\n        </dependency>\n\n        <!-- OpenCV (https://mvnrepository.com/artifact/org.openpnp/opencv) -->\n        <dependency>\n            <groupId>org.openpnp</groupId>\n            <artifactId>opencv</artifactId>\n            <version>3.2.0-1</version>\n        </dependency>\n\n        <!-- PDFBox https://mvnrepository.com/artifact/org.apache.pdfbox/pdfbox -->\n        <dependency>\n            <groupId>org.apache.pdfbox</groupId>\n            <artifactId>pdfbox</artifactId>\n            <version>2.0.24</version>\n        </dependency>\n\n        <!-- PDFBox-tools https://mvnrepository.com/artifact/org.apache.pdfbox/pdfbox-tools -->\n        <dependency>\n            <groupId>org.apache.pdfbox</groupId>\n            <artifactId>pdfbox-tools</artifactId>\n            <version>2.0.19</version>\n        </dependency>\n\n        <dependency>\n            <groupId>org.apache.pdfbox</groupId>\n            <artifactId>jbig2-imageio</artifactId>\n            <version>3.0.3</version>\n        </dependency>\n\n        <!-- Java Advanced Imaging (JAI) Image I/O Tools -->\n        <dependency>\n            <groupId>com.github.jai-imageio</groupId>\n            <artifactId>jai-imageio-core</artifactId>\n            <version>1.4.0</version>\n        </dependency>\n        <dependency>\n            <groupId>com.github.jai-imageio</groupId>\n            <artifactId>jai-imageio-jpeg2000</artifactId>\n            <version>1.3.0</version>\n        </dependency>\n        <dependency>\n            <groupId>javax.xml.bind</groupId>\n            <artifactId>jaxb-api</artifactId>\n            <version>2.3.1</version>\n        </dependency>\n        <!-- https://mvnrepository.com/artifact/org.docx4j/docx4j-JAXB-Internal -->\n        <dependency>\n            <groupId>org.docx4j</groupId>\n            <artifactId>docx4j-JAXB-Internal</artifactId>\n            <version>8.3.1</version>\n        </dependency>\n        <!-- PAGE XML -->\n        <dependency>\n            <groupId>org.primaresearch</groupId>\n            <artifactId>basic</artifactId>\n            <version>1.5b</version>\n        </dependency>\n        <dependency>\n            <groupId>org.primaresearch</groupId>\n            <artifactId>Dla</artifactId>\n            <version>1.5b</version>\n        </dependency>\n        <dependency>\n            <groupId>org.primaresearch</groupId>\n            <artifactId>Io</artifactId>\n            <version>1.5b</version>\n        </dependency>\n        <dependency>\n            <groupId>org.primaresearch</groupId>\n            <artifactId>Maths</artifactId>\n            <version>1.5b</version>\n        </dependency>\n\n    </dependencies>\n\n\n    <repositories>\n        <repository>\n            <id>Internal project repository</id>\n            <url>file://${basedir}/src/lib/repository</url>\n        </repository>\n    </repositories>\n\n    <distributionManagement>\n        <repository>\n            <id>central</id>\n            <name>artifactory-releases</name>\n            <url>https://artifactory-ls6.informatik.uni-wuerzburg.de/artifactory/libs-snapshot</url>\n        </repository>\n        <snapshotRepository>\n            <id>snapshots</id>\n            <name>artifactory-snapshots</name>\n            <url>https://artifactory-ls6.informatik.uni-wuerzburg.de/artifactory/libs-snapshot</url>\n        </snapshotRepository>\n    </distributionManagement>\n\n    <build>\n        <finalName>ocr4all</finalName>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-war-plugin</artifactId>\n                <version>3.3.1</version>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n"
                },
                "compile_error_details": {}
            },
            "error": "[INFO] Scanning for projects...\n[INFO]\n[INFO] -------------------------< de.uniwue:ocr4all >--------------------------\n[INFO] Building OCR4all Maven Webapp 0.6.1\n[INFO] from pom.xml\n[INFO] --------------------------------[ war ]---------------------------------\n[WARNING] Could not validate integrity of download from file:///mnt/repo/src/lib/repository/org/primaresearch/basic/1.5b/basic-1.5b.pom\norg.eclipse.aether.transfer.ChecksumFailureException: Checksum validation failed, no checksums available\nat org.eclipse.aether.internal.impl.AbstractChecksumPolicy.onNoMoreChecksums (AbstractChecksumPolicy.java:63)\nat org.eclipse.aether.connector.basic.ChecksumValidator.validate (ChecksumValidator.java:112)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$GetTaskRunner.runTask (BasicRepositoryConnector.java:484)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run (BasicRepositoryConnector.java:414)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector.get (BasicRepositoryConnector.java:260)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.performDownloads (DefaultArtifactResolver.java:537)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolve (DefaultArtifactResolver.java:449)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifacts (DefaultArtifactResolver.java:261)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifact (DefaultArtifactResolver.java:243)\nat org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.loadPom (DefaultArtifactDescriptorReader.java:241)\nat org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.readArtifactDescriptor (DefaultArtifactDescriptorReader.java:182)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.resolveCachedArtifactDescriptor (DfDependencyCollector.java:382)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.getArtifactDescriptorResult (DfDependencyCollector.java:368)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.processDependency (DfDependencyCollector.java:218)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.processDependency (DfDependencyCollector.java:156)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.process (DfDependencyCollector.java:138)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.doCollectDependencies (DfDependencyCollector.java:108)\nat org.eclipse.aether.internal.impl.collect.DependencyCollectorDelegate.collectDependencies (DependencyCollectorDelegate.java:222)\nat org.eclipse.aether.internal.impl.collect.DefaultDependencyCollector.collectDependencies (DefaultDependencyCollector.java:87)\nat org.eclipse.aether.internal.impl.DefaultRepositorySystem.collectDependencies (DefaultRepositorySystem.java:306)\nat org.apache.maven.project.DefaultProjectDependenciesResolver.resolve (DefaultProjectDependenciesResolver.java:151)\nat org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.getDependencies (LifecycleDependencyResolver.java:224)\nat org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.resolveProjectDependencies (LifecycleDependencyResolver.java:136)\nat org.apache.maven.lifecycle.internal.MojoExecutor.ensureDependenciesAreResolved (MojoExecutor.java:355)\nat org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:313)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:212)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:174)\nat org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:75)\nat org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:162)\nat org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:159)\nat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\nat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\nat org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\nat org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\nat org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:261)\nat org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:173)\nat org.apache.maven.DefaultMaven.execute (DefaultMaven.java:101)\nat org.apache.maven.cli.MavenCli.execute (MavenCli.java:903)\nat org.apache.maven.cli.MavenCli.doMain (MavenCli.java:280)\nat org.apache.maven.cli.MavenCli.main (MavenCli.java:203)\nat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\nat jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\nat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke (Method.java:569)\nat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:255)\nat org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:201)\nat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:361)\nat org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:314)\n[WARNING] Checksum validation failed, no checksums available from Internal project repository for file:///mnt/repo/src/lib/repository/org/primaresearch/basic/1.5b/basic-1.5b.pom\n[WARNING] Could not validate integrity of download from file:///mnt/repo/src/lib/repository/org/primaresearch/Dla/1.5b/Dla-1.5b.pom\norg.eclipse.aether.transfer.ChecksumFailureException: Checksum validation failed, no checksums available\nat org.eclipse.aether.internal.impl.AbstractChecksumPolicy.onNoMoreChecksums (AbstractChecksumPolicy.java:63)\nat org.eclipse.aether.connector.basic.ChecksumValidator.validate (ChecksumValidator.java:112)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$GetTaskRunner.runTask (BasicRepositoryConnector.java:484)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run (BasicRepositoryConnector.java:414)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector.get (BasicRepositoryConnector.java:260)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.performDownloads (DefaultArtifactResolver.java:537)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolve (DefaultArtifactResolver.java:449)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifacts (DefaultArtifactResolver.java:261)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifact (DefaultArtifactResolver.java:243)\nat org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.loadPom (DefaultArtifactDescriptorReader.java:241)\nat org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.readArtifactDescriptor (DefaultArtifactDescriptorReader.java:182)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.resolveCachedArtifactDescriptor (DfDependencyCollector.java:382)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.getArtifactDescriptorResult (DfDependencyCollector.java:368)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.processDependency (DfDependencyCollector.java:218)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.processDependency (DfDependencyCollector.java:156)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.process (DfDependencyCollector.java:138)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.doCollectDependencies (DfDependencyCollector.java:108)\nat org.eclipse.aether.internal.impl.collect.DependencyCollectorDelegate.collectDependencies (DependencyCollectorDelegate.java:222)\nat org.eclipse.aether.internal.impl.collect.DefaultDependencyCollector.collectDependencies (DefaultDependencyCollector.java:87)\nat org.eclipse.aether.internal.impl.DefaultRepositorySystem.collectDependencies (DefaultRepositorySystem.java:306)\nat org.apache.maven.project.DefaultProjectDependenciesResolver.resolve (DefaultProjectDependenciesResolver.java:151)\nat org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.getDependencies (LifecycleDependencyResolver.java:224)\nat org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.resolveProjectDependencies (LifecycleDependencyResolver.java:136)\nat org.apache.maven.lifecycle.internal.MojoExecutor.ensureDependenciesAreResolved (MojoExecutor.java:355)\nat org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:313)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:212)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:174)\nat org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:75)\nat org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:162)\nat org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:159)\nat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\nat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\nat org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\nat org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\nat org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:261)\nat org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:173)\nat org.apache.maven.DefaultMaven.execute (DefaultMaven.java:101)\nat org.apache.maven.cli.MavenCli.execute (MavenCli.java:903)\nat org.apache.maven.cli.MavenCli.doMain (MavenCli.java:280)\nat org.apache.maven.cli.MavenCli.main (MavenCli.java:203)\nat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\nat jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\nat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke (Method.java:569)\nat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:255)\nat org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:201)\nat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:361)\nat org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:314)\n[WARNING] Checksum validation failed, no checksums available from Internal project repository for file:///mnt/repo/src/lib/repository/org/primaresearch/Dla/1.5b/Dla-1.5b.pom\n[WARNING] Could not validate integrity of download from file:///mnt/repo/src/lib/repository/org/primaresearch/Io/1.5b/Io-1.5b.pom\norg.eclipse.aether.transfer.ChecksumFailureException: Checksum validation failed, no checksums available\nat org.eclipse.aether.internal.impl.AbstractChecksumPolicy.onNoMoreChecksums (AbstractChecksumPolicy.java:63)\nat org.eclipse.aether.connector.basic.ChecksumValidator.validate (ChecksumValidator.java:112)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$GetTaskRunner.runTask (BasicRepositoryConnector.java:484)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run (BasicRepositoryConnector.java:414)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector.get (BasicRepositoryConnector.java:260)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.performDownloads (DefaultArtifactResolver.java:537)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolve (DefaultArtifactResolver.java:449)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifacts (DefaultArtifactResolver.java:261)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifact (DefaultArtifactResolver.java:243)\nat org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.loadPom (DefaultArtifactDescriptorReader.java:241)\nat org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.readArtifactDescriptor (DefaultArtifactDescriptorReader.java:182)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.resolveCachedArtifactDescriptor (DfDependencyCollector.java:382)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.getArtifactDescriptorResult (DfDependencyCollector.java:368)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.processDependency (DfDependencyCollector.java:218)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.processDependency (DfDependencyCollector.java:156)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.process (DfDependencyCollector.java:138)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.doCollectDependencies (DfDependencyCollector.java:108)\nat org.eclipse.aether.internal.impl.collect.DependencyCollectorDelegate.collectDependencies (DependencyCollectorDelegate.java:222)\nat org.eclipse.aether.internal.impl.collect.DefaultDependencyCollector.collectDependencies (DefaultDependencyCollector.java:87)\nat org.eclipse.aether.internal.impl.DefaultRepositorySystem.collectDependencies (DefaultRepositorySystem.java:306)\nat org.apache.maven.project.DefaultProjectDependenciesResolver.resolve (DefaultProjectDependenciesResolver.java:151)\nat org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.getDependencies (LifecycleDependencyResolver.java:224)\nat org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.resolveProjectDependencies (LifecycleDependencyResolver.java:136)\nat org.apache.maven.lifecycle.internal.MojoExecutor.ensureDependenciesAreResolved (MojoExecutor.java:355)\nat org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:313)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:212)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:174)\nat org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:75)\nat org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:162)\nat org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:159)\nat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\nat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\nat org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\nat org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\nat org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:261)\nat org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:173)\nat org.apache.maven.DefaultMaven.execute (DefaultMaven.java:101)\nat org.apache.maven.cli.MavenCli.execute (MavenCli.java:903)\nat org.apache.maven.cli.MavenCli.doMain (MavenCli.java:280)\nat org.apache.maven.cli.MavenCli.main (MavenCli.java:203)\nat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\nat jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\nat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke (Method.java:569)\nat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:255)\nat org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:201)\nat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:361)\nat org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:314)\n[WARNING] Checksum validation failed, no checksums available from Internal project repository for file:///mnt/repo/src/lib/repository/org/primaresearch/Io/1.5b/Io-1.5b.pom\n[WARNING] Could not validate integrity of download from file:///mnt/repo/src/lib/repository/org/primaresearch/Maths/1.5b/Maths-1.5b.pom\norg.eclipse.aether.transfer.ChecksumFailureException: Checksum validation failed, no checksums available\nat org.eclipse.aether.internal.impl.AbstractChecksumPolicy.onNoMoreChecksums (AbstractChecksumPolicy.java:63)\nat org.eclipse.aether.connector.basic.ChecksumValidator.validate (ChecksumValidator.java:112)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$GetTaskRunner.runTask (BasicRepositoryConnector.java:484)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run (BasicRepositoryConnector.java:414)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector.get (BasicRepositoryConnector.java:260)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.performDownloads (DefaultArtifactResolver.java:537)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolve (DefaultArtifactResolver.java:449)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifacts (DefaultArtifactResolver.java:261)\nat org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifact (DefaultArtifactResolver.java:243)\nat org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.loadPom (DefaultArtifactDescriptorReader.java:241)\nat org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.readArtifactDescriptor (DefaultArtifactDescriptorReader.java:182)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.resolveCachedArtifactDescriptor (DfDependencyCollector.java:382)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.getArtifactDescriptorResult (DfDependencyCollector.java:368)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.processDependency (DfDependencyCollector.java:218)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.processDependency (DfDependencyCollector.java:156)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.process (DfDependencyCollector.java:138)\nat org.eclipse.aether.internal.impl.collect.df.DfDependencyCollector.doCollectDependencies (DfDependencyCollector.java:108)\nat org.eclipse.aether.internal.impl.collect.DependencyCollectorDelegate.collectDependencies (DependencyCollectorDelegate.java:222)\nat org.eclipse.aether.internal.impl.collect.DefaultDependencyCollector.collectDependencies (DefaultDependencyCollector.java:87)\nat org.eclipse.aether.internal.impl.DefaultRepositorySystem.collectDependencies (DefaultRepositorySystem.java:306)\nat org.apache.maven.project.DefaultProjectDependenciesResolver.resolve (DefaultProjectDependenciesResolver.java:151)\nat org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.getDependencies (LifecycleDependencyResolver.java:224)\nat org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.resolveProjectDependencies (LifecycleDependencyResolver.java:136)\nat org.apache.maven.lifecycle.internal.MojoExecutor.ensureDependenciesAreResolved (MojoExecutor.java:355)\nat org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:313)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:212)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:174)\nat org.apache.maven.lifecycle.internal.MojoExecutor.access$000 (MojoExecutor.java:75)\nat org.apache.maven.lifecycle.internal.MojoExecutor$1.run (MojoExecutor.java:162)\nat org.apache.maven.plugin.DefaultMojosExecutionStrategy.execute (DefaultMojosExecutionStrategy.java:39)\nat org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:159)\nat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:105)\nat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:73)\nat org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:53)\nat org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:118)\nat org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:261)\nat org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:173)\nat org.apache.maven.DefaultMaven.execute (DefaultMaven.java:101)\nat org.apache.maven.cli.MavenCli.execute (MavenCli.java:903)\nat org.apache.maven.cli.MavenCli.doMain (MavenCli.java:280)\nat org.apache.maven.cli.MavenCli.main (MavenCli.java:203)\nat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\nat jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\nat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke (Method.java:569)\nat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:255)\nat org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:201)\nat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:361)\nat org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:314)\n[WARNING] Checksum validation failed, no checksums available from Internal project repository for file:///mnt/repo/src/lib/repository/org/primaresearch/Maths/1.5b/Maths-1.5b.pom\n[WARNING] Could not validate integrity of download from file:///mnt/repo/src/lib/repository/org/primaresearch/basic/1.5b/basic-1.5b.jar\norg.eclipse.aether.transfer.ChecksumFailureException: Checksum validation failed, no checksums available\nat org.eclipse.aether.internal.impl.AbstractChecksumPolicy.onNoMoreChecksums (AbstractChecksumPolicy.java:63)\nat org.eclipse.aether.connector.basic.ChecksumValidator.validate (ChecksumValidator.java:112)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$GetTaskRunner.runTask (BasicRepositoryConnector.java:484)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run (BasicRepositoryConnector.java:414)\nat org.eclipse.aether.util.concurrency.RunnableErrorForwarder.lambda$wrap$0 (RunnableErrorForwarder.java:66)\nat java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1136)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:635)\nat java.lang.Thread.run (Thread.java:840)\n[WARNING] Checksum validation failed, no checksums available from Internal project repository for file:///mnt/repo/src/lib/repository/org/primaresearch/basic/1.5b/basic-1.5b.jar\n[WARNING] Could not validate integrity of download from file:///mnt/repo/src/lib/repository/org/primaresearch/Io/1.5b/Io-1.5b.jar\norg.eclipse.aether.transfer.ChecksumFailureException: Checksum validation failed, no checksums available\nat org.eclipse.aether.internal.impl.AbstractChecksumPolicy.onNoMoreChecksums (AbstractChecksumPolicy.java:63)\nat org.eclipse.aether.connector.basic.ChecksumValidator.validate (ChecksumValidator.java:112)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$GetTaskRunner.runTask (BasicRepositoryConnector.java:484)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run (BasicRepositoryConnector.java:414)\nat org.eclipse.aether.util.concurrency.RunnableErrorForwarder.lambda$wrap$0 (RunnableErrorForwarder.java:66)\nat java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1136)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:635)\nat java.lang.Thread.run (Thread.java:840)\n[WARNING] Checksum validation failed, no checksums available from Internal project repository for file:///mnt/repo/src/lib/repository/org/primaresearch/Io/1.5b/Io-1.5b.jar\n[WARNING] Could not validate integrity of download from file:///mnt/repo/src/lib/repository/org/primaresearch/Maths/1.5b/Maths-1.5b.jar\norg.eclipse.aether.transfer.ChecksumFailureException: Checksum validation failed, no checksums available\nat org.eclipse.aether.internal.impl.AbstractChecksumPolicy.onNoMoreChecksums (AbstractChecksumPolicy.java:63)\nat org.eclipse.aether.connector.basic.ChecksumValidator.validate (ChecksumValidator.java:112)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$GetTaskRunner.runTask (BasicRepositoryConnector.java:484)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run (BasicRepositoryConnector.java:414)\nat org.eclipse.aether.util.concurrency.RunnableErrorForwarder.lambda$wrap$0 (RunnableErrorForwarder.java:66)\nat java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1136)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:635)\nat java.lang.Thread.run (Thread.java:840)\n[WARNING] Checksum validation failed, no checksums available from Internal project repository for file:///mnt/repo/src/lib/repository/org/primaresearch/Maths/1.5b/Maths-1.5b.jar\n[WARNING] Could not validate integrity of download from file:///mnt/repo/src/lib/repository/org/primaresearch/Dla/1.5b/Dla-1.5b.jar\norg.eclipse.aether.transfer.ChecksumFailureException: Checksum validation failed, no checksums available\nat org.eclipse.aether.internal.impl.AbstractChecksumPolicy.onNoMoreChecksums (AbstractChecksumPolicy.java:63)\nat org.eclipse.aether.connector.basic.ChecksumValidator.validate (ChecksumValidator.java:112)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$GetTaskRunner.runTask (BasicRepositoryConnector.java:484)\nat org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run (BasicRepositoryConnector.java:414)\nat org.eclipse.aether.util.concurrency.RunnableErrorForwarder.lambda$wrap$0 (RunnableErrorForwarder.java:66)\nat java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1136)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:635)\nat java.lang.Thread.run (Thread.java:840)\n[WARNING] Checksum validation failed, no checksums available from Internal project repository for file:///mnt/repo/src/lib/repository/org/primaresearch/Dla/1.5b/Dla-1.5b.jar\n[INFO]\n[INFO] --- clean:3.2.0:clean (default-clean) @ ocr4all ---\n[INFO] Deleting /mnt/repo/target\n[INFO]\n[INFO] --- resources:3.3.1:resources (default-resources) @ ocr4all ---\n[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!\n[INFO] skip non existing resourceDirectory /mnt/repo/src/main/resources\n[INFO]\n[INFO] --- compiler:3.13.0:compile (default-compile) @ ocr4all ---\n[INFO] Recompiling the module because of changed dependency.\n[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!\n[INFO] Compiling 60 source files with javac [debug target 1.8] to target/classes\n[WARNING] bootstrap class path not set in conjunction with -source 8\n[INFO]\n[INFO] --- resources:3.3.1:testResources (default-testResources) @ ocr4all ---\n[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!\n[INFO] skip non existing resourceDirectory /mnt/repo/src/test/resources\n[INFO]\n[INFO] --- compiler:3.13.0:testCompile (default-testCompile) @ ocr4all ---\n[INFO] No sources to compile\n[INFO]\n[INFO] --- surefire:3.2.5:test (default-test) @ ocr4all ---\n[INFO] No tests to run.\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 9.067 s\n[INFO] Finished at: 2024-08-04T22:00:27Z\n[INFO] ------------------------------------------------------------------------",
            "span_id": 2525176176531687880
        }
    ],
    "read_file": [
        {
            "input": "src/main/java/de/uniwue/helper/RecognitionHelper.java",
            "output": "package de.uniwue.helper;\n\nimport java.io.File;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.nio.file.*;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.TreeMap;\n\nimport org.apache.commons.io.FileUtils;\n\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.ObjectWriter;\nimport com.fasterxml.jackson.databind.node.ArrayNode;\n\nimport de.uniwue.config.ProjectConfiguration;\nimport de.uniwue.feature.ProcessConflictDetector;\nimport de.uniwue.feature.ProcessHandler;\nimport de.uniwue.feature.ProcessStateCollector;\n\n/**\n * Helper class for recognition module\n */\npublic class RecognitionHelper {\n    /**\n     * Object to access project configuration\n     */\n    private ProjectConfiguration projConf;\n\n    /**\n     * Image type of the project\n     * Possible values: { Binary, Gray }\n     */\n    private String projectImageType;\n\n\n    /**\n     * Object to use generic functionalities\n     */\n    private GenericHelper genericHelper;\n\n    /**\n     * Object to determine process states\n     */\n    private ProcessStateCollector procStateCol;\n\n    /**\n     * Helper object for process handling\n     */\n    private ProcessHandler processHandler;\n\n    /**\n     * Progress of the Recognition process\n     */\n    private int progress = -1;\n\n    /**\n     * Indicates if a Recognition process is already running\n     */\n    private boolean RecognitionRunning = false;\n\n    /**\n     * Last time the images/pagexml are modified\n     */\n    private Map<String,Long> imagesLastModified;\n\n    /**\n     * Structure to monitor the progress of the process\n     * pageId : segmentId : lineSegmentId : processedState\n     *\n     * Structure example:\n     * {\n     *     \"0002\": {\n     *         \"0002__000__paragraph\" : {\n     *             \"0002__000__paragraph__000\" : true,\n     *             \"0002__000__paragraph__001\" : false,\n     *             ...\n     *         },\n     *         ...\n     *     },\n     *     ...\n     * }\n     */\n    private TreeMap<String,TreeMap<String, TreeMap<String, Boolean>>> processState = new TreeMap<>();\n\n    /**\n     * Constructor\n     *\n     * @param projectDir Path to the project directory\n     * @param projectImageType Type of the project (binary, gray)\n     *\n     */\n    public RecognitionHelper(String projectDir, String projectImageType) {\n        this.projectImageType = projectImageType;\n        projConf = new ProjectConfiguration(projectDir);\n        genericHelper = new GenericHelper(projConf);\n        procStateCol = new ProcessStateCollector(projConf, projectImageType);\n        processHandler = new ProcessHandler();\n    }\n\n    /**\n     * Gets the process handler object\n     *\n     * @return Returns the process Helper\n     */\n    public ProcessHandler getProcessHandler() {\n        return processHandler;\n    }\n\n    /**\n     * Initializes the structure with which the progress of the process can be monitored\n     *\n     * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)\n     * @throws IOException\n     */\n    public void initialize(List<String> pageIds) throws IOException {\n        // Init the listener for image modification\n        imagesLastModified = new HashMap<>();\n        for(String pageId: pageIds) {\n            final String pageXML = projConf.OCR_DIR + pageId + projConf.CONF_EXT;\n            imagesLastModified.put(pageXML,new File(pageXML).lastModified());\n        }\n    }\n\n    /**\n     * Returns the absolute path of all line segment images for the pages in the processState\n     *\n     * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)\n     * @return List of line segment images\n     * @throws IOException\n     */\n    public List<String> getLineSegmentImagesForCurrentProcess(List<String> pageIds) throws IOException {\n        List<String> LineSegmentsOfPage = new ArrayList<String>();\n        for (String pageId : processState.keySet()) {\n            for (String segmentId : processState.get(pageId).keySet()) {\n                for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {\n                    LineSegmentsOfPage.add(projConf.PAGE_DIR + pageId + File.separator + segmentId +\n                        File.separator + lineSegmentId + projConf.getImageExtensionByType(projectImageType));\n                }\n            }\n        }\n        return LineSegmentsOfPage;\n    }\n\n    /**\n     * Returns the progress of the process\n     *\n     * @return Progress percentage\n     * @throws IOException\n     */\n    public int getProgress() throws IOException {\n        // Prevent function from calculation progress if process is not running\n        if (!RecognitionRunning)\n            return progress;\n\n        int modifiedCount = 0;\n        if(imagesLastModified != null) {\n            for(String pagexml : imagesLastModified.keySet()) {\n                if(imagesLastModified.get(pagexml) < new File(pagexml).lastModified()) {\n                    modifiedCount++;\n                }\n            }\n            progress = (modifiedCount*100) / imagesLastModified.size();\n        } else {\n            progress = -1;\n        }\n        return progress;\n    }\n\n    /**\n     * Extracts checkpoints of a String joined by a whitespace\n     *\n     * @return List of checkpoints\n     * @throws IOException\n     */\n    public List<String> extractModelsOfJoinedString(String joinedckptString){\n        String [] checkpoints = joinedckptString.split(ProjectConfiguration.MODEL_EXT + \" \");\n        List<String> ckptList = new ArrayList<>();\n        Iterator <String> ckptIterator= Arrays.asList(checkpoints).iterator();\n        while (ckptIterator.hasNext()) {\n            String ckpt = ckptIterator.next();\n            if (ckptIterator.hasNext())\n                ckpt = ckpt + ProjectConfiguration.MODEL_EXT;\n            ckptList.add(ckpt);\n        }\n        return ckptList;\n    }\n    /**\n     * Executes OCR on a list of pages\n     * Achieved with the help of the external python program \"calamary-predict\"\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     * @param cmdArgs Command line arguments for \"calamary-predict\"\n     * @throws IOException\n     */\n    public void execute(List<String> pageIds, final List<String> cmdArgs) throws IOException {\n        RecognitionRunning = true;\n        progress = 0;\n\n        List<String> cmdArgsWork = new ArrayList<>(cmdArgs);\n\n        //// Estimate Skew\n        if (cmdArgsWork.contains(\"--estimate_skew\")) {\n        \t// Calculate the skew of all regions where none was calculated before\n        \tList<String> skewparams = new ArrayList<>();\n            skewparams.add(\"skewestimate\");\n        \tfinal int maxskewIndex = cmdArgsWork.indexOf(\"--maxskew\");\n        \tif(maxskewIndex > -1) {\n        \t\tskewparams.add(cmdArgsWork.remove(maxskewIndex));\n        \t\tskewparams.add(cmdArgsWork.remove(maxskewIndex));\n        \t}\n        \tfinal int skewstepsIndex = cmdArgsWork.indexOf(\"--skewsteps\");\n        \tif(skewstepsIndex > -1) {\n        \t\tskewparams.add(cmdArgsWork.remove(skewstepsIndex));\n        \t\tskewparams.add(cmdArgsWork.remove(skewstepsIndex));\n        \t}\n\n\t\t\t// Create temp json file with all segment images (to not overload parameter list)\n\t\t\t// Temp file in a temp folder named \"skew-<random numbers>.json\"\n\t\t\tFile segmentListFile = File.createTempFile(\"skew-\",\".json\");\n\t\t\tskewparams.add(segmentListFile.toString());\n\t\t\tsegmentListFile.deleteOnExit(); // Delete if OCR4all terminates\n\t\t\tObjectMapper mapper = new ObjectMapper();\n\t\t\tArrayNode dataList = mapper.createArrayNode();\n\t\t\tfor (String pageId : pageIds) {\n\t\t\t\tArrayNode pageList = mapper.createArrayNode();\n\t\t\t\tpageList.add(projConf.getImageDirectoryByType(projectImageType) + pageId +\n\t\t\t\t\t\tprojConf.getImageExtensionByType(projectImageType));\n\t\t\t\tfinal String pageXML = projConf.OCR_DIR + pageId + projConf.CONF_EXT;\n\t\t\t\tpageList.add(pageXML);\n\n\t\t\t\t// Add affected line segment images with their absolute path to the json file\n\t\t\t\tdataList.add(pageList);\n\t\t\t}\n\t\t\tObjectWriter writer = mapper.writer();\n\t\t\twriter.writeValue(segmentListFile, dataList);\n\n            processHandler = new ProcessHandler();\n            processHandler.setFetchProcessConsole(true);\n            processHandler.startProcess(\"ocr4all-helper-scripts\", skewparams, false);\n\n        \tcmdArgsWork.remove(\"--estimate_skew\");\n        }\n\n\n        //// Recognize\n\t\t// Reset recognition data\n\t\tdeleteOldFiles(pageIds);\n\t\tinitialize(pageIds);\n\n        int index;\n        if (cmdArgsWork.contains(\"--checkpoint\")) {\n            index = cmdArgsWork.indexOf(\"--checkpoint\");\n            for(String ckpt : extractModelsOfJoinedString(cmdArgsWork.get(index + 1))) {\n                if (!new File(ckpt).exists())\n                    throw new IOException(\"Model does not exist under the specified path\");\n            }\n        }\n\n        List<String> command = new ArrayList<>();\n        // Ugly hack but helpers will be rewritten for the next release anyways. Don't use as basis for future code!\n        if(cmdArgsWork.contains(\"--data.output_glyphs\")){\n            cmdArgsWork.remove(\"--data.output_glyphs\");\n            command.add(\"--data.output_glyphs\");\n            command.add(\"True\");\n        }\n        if(cmdArgsWork.contains(\"--data.output_confidences\")){\n            cmdArgsWork.remove(\"--data.output_confidences\");\n            command.add(\"--data.output_confidences\");\n            command.add(\"True\");\n        }\n\n        command.add(\"--data.images\");\n        // Create temp json file with all segment images (to not overload parameter list)\n\t\t// Temp file in a temp folder named \"calamari-<random numbers>.json\"\n        File segmentListFile = File.createTempFile(\"calamari-\",\".files\");\n        segmentListFile.deleteOnExit();\n\n        List<String> content = new ArrayList<>();\n        for (String pageId : pageIds) {\n            // Add affected images with their absolute path to the file\n            content.add(projConf.getImageDirectoryByType(projectImageType) + pageId +\n                                projConf.getImageExtensionByType(projectImageType));\n        }\n        Files.write(segmentListFile.toPath(), content, StandardOpenOption.APPEND);\n        command.add(segmentListFile.toString());\n\n        //Add checkpoints\n        Iterator<String> cmdArgsIterator = cmdArgsWork.iterator();\n        while (cmdArgsIterator.hasNext()) {\n            String arg = cmdArgsIterator.next();\n            command.add(arg);\n            if (arg.equals(\"--checkpoint\") && cmdArgsIterator.hasNext()) {\n                command.addAll(extractModelsOfJoinedString(cmdArgsIterator.next()));\n            }\n        }\n\n        command.add(\"--data\");\n        command.add(\"PageXML\");\n        // Set output extension to input extension in order to overwrite the original file\n        // (default would've been .pred.xml)\n        command.add(\"--data.gt_extension\");\n        command.add(\".xml\");\n        command.add(\"--data.pred_extension\");\n        command.add(\".xml\");\n\n        command.add(\"--data.text_index\");\n        command.add(\"1\");\n\n        command.add(\"--verbose\");\n        command.add(\"True\");\n\n        command.add(\"--predictor.progress_bar\");\n        command.add(\"False\");\n\n        processHandler = new ProcessHandler();\n        processHandler.setFetchProcessConsole(true);\n        processHandler.startProcess(\"calamari-predict\", command, false);\n\n        // Execute progress update to fill processState data structure with correct values\n        getProgress();\n        // Process extension to ocropus-gpageseg script\n        createSkippedSegments();\n\n        progress = 100;\n        RecognitionRunning = false;\n\n        // Clean up temp segmentListFile\n        // segmentListFile.delete();\n    }\n\n    /**\n     * Resets the progress (use if an error occurs)\n     */\n    public void resetProgress() {\n        RecognitionRunning = false;\n        progress = -1;\n    }\n\n    /**\n     * Cancels the process\n     */\n    public void cancelProcess() {\n        if (processHandler != null)\n            processHandler.stopProcess();\n        RecognitionRunning = false;\n    }\n\n    /**\n     * Returns the Ids of the pages, for which line segmentation was already executed\n     *\n     * @return List with page ids\n     * @throws IOException\n     */\n    public ArrayList<String> getValidPageIds() throws IOException {\n        // Get all pages and check which ones are already line segmented\n        ArrayList<String> validPageIds = new ArrayList<String>();\n        ArrayList<String> allPageIds = genericHelper.getPageList(\"Original\");\n        for (String pageId : allPageIds) {\n            if (procStateCol.lineSegmentationState(pageId) == true)\n                validPageIds.add(pageId);\n        }\n\n        Collections.sort(validPageIds);\n        return validPageIds;\n    }\n\n    /**\n     * Deletion of old process related files\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     */\n    public void deleteOldFiles(List<String> pageIds) throws IOException {\n        // Delete potential TextEquivs already existing in the page xmls\n        for(String pageId : pageIds) {\n            File pageXML = new File(projConf.OCR_DIR + pageId + projConf.CONF_EXT);\n            if (!pageXML.exists())\n                return;\n\n            // Load pageXML and replace/delete all Textline text content\n            String pageXMLContent = new String(Files.readAllBytes(pageXML.toPath()));\n            pageXMLContent = pageXMLContent.replaceAll(\"\\\\<TextEquiv[^>]+?index=\\\"[^0]\\\"[^>]*?\\\\>[^<]*?\\\\<\\\\/TextEquiv\\\\>\", \"\");\n\n            // Save new pageXML\n            try (FileWriter fileWriter = new FileWriter(pageXML)) {\n                fileWriter.write(pageXMLContent);\n                fileWriter.flush();\n                fileWriter.close();\n            }\n    \t}\n    }\n\n    /**\n     * Creates the recognition files of the linesegments that were skipped by the ocropus-rpred script\n     *\n     * @throws IOException\n     */\n    public void createSkippedSegments() throws IOException{\n        for(String pageId : processState.keySet()) {\n            for(String segmentId :processState.get(pageId).keySet()) {\n                for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {\n                    if (processState.get(pageId).get(segmentId).get(lineSegmentId))\n                        continue;\n\n                    FileUtils.writeStringToFile(new File(projConf.PAGE_DIR + pageId + File.separator +\n                        segmentId + File.separator + lineSegmentId + projConf.REC_EXT), \"\", \"UTF8\");\n                }\n            }\n        }\n    }\n\n    /**\n     * Checks if process depending files already exist\n     *\n     * @param pageIds Identifiers of the pages (e.g 0002,0003)\n     * @return Information if files exist\n     */\n    public boolean doOldFilesExist(String[] pageIds) {\n        for (String pageId : pageIds) {\n            if (procStateCol.recognitionState(pageId))\n                return true;\n        }\n        return false;\n    }\n\n    /**\n     * Lists all available Models from the model directory\n     * Consider the subsequent information to load models correctly\n     *\n     * Possible model location directories:\n     * ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR\n     * ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR\n     *\n     * Model path structures on the filesystem:\n     * Default: OS_PATH/{TRAINING_IDENTIFIER}/{ID}.ckpt.json\n     * Custom:  OS_PATH/{PROJECT_NAME}/{TRAINING_IDENTIFIER}/{ID}.ckpt.json\n     *\n     * Example: /var/ocr4all/models/default/Baiter_000/Baiter.ckpt.json\n     * Display: Baiter_000/Baiter\n     * Example: /var/ocr4all/models/custom/Bibel/0/0.ckpt.json\n     * Display: Bibel/0/0\n     * Example: /var/ocr4all/models/custom/Bibel/heading/0.ckpt.json\n     * Display: Bibel/heading/0\n     *\n     * The models need to be in the following structure:\n     * ANY_PATH/{MODEL_NAME}/ANY_NAME.ckpt.json\n     *\n     * @return Map of models (key = modelName | value = path)\n     * @throws IOException\n     */\n    public static TreeMap<String, String> listModels() throws IOException{\n        TreeMap<String, String> models = new TreeMap<String, String>();\n\n        File modelsDir = new File(ProjectConfiguration.PROJ_MODEL_DIR);\n        if (!modelsDir.exists())\n            return models;\n\n        // Add all models to map (follow symbolic links on the filesystem due to Docker container)\n        Files.walk(Paths.get(ProjectConfiguration.PROJ_MODEL_DIR), FileVisitOption.FOLLOW_LINKS)\n        .map(Path::toFile)\n        .filter(fileEntry -> fileEntry.getName().endsWith(ProjectConfiguration.MODEL_EXT))\n        .forEach(\n            fileEntry -> {\n                // Remove OS path and model extension from display string (only display significant information)\n                String modelName = fileEntry.getAbsolutePath();\n                modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR, \"\");\n                modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR, \"\");\n                modelName = modelName.replace(ProjectConfiguration.MODEL_EXT, \"\");\n\n                models.put(modelName, fileEntry.getAbsolutePath());\n        });\n\n        return models;\n    }\n\n    /**\n     * Determines conflicts with the process\n     *\n     * @param currentProcesses Processes that are currently running\n     * @param inProcessFlow Indicates if the process is executed within the ProcessFlow\n     * @return Type of process conflict\n     */\n    public int getConflictType(List<String> currentProcesses, boolean inProcessFlow) {\n        return ProcessConflictDetector.recognitionConflict(currentProcesses, inProcessFlow);\n    }\n}\n",
            "error": "",
            "span_id": 16795791215174724923
        },
        {
            "input": "pom.xml",
            "output": "<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>de.uniwue</groupId>\n    <artifactId>ocr4all</artifactId>\n    <packaging>war</packaging>\n    <version>0.6.1</version>\n    <name>OCR4all Maven Webapp</name>\n    <url>http://maven.apache.org</url>\n\n    <properties>\n        <spring.version>4.3.18.RELEASE</spring.version>\n\n        <!-- Java version -->\n        <maven.compiler.source>1.8</maven.compiler.source>\n        <maven.compiler.target>1.8</maven.compiler.target>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>junit</groupId>\n            <artifactId>junit</artifactId>\n            <version>4.13.1</version>\n            <scope>test</scope>\n        </dependency>\n\n        <!-- Spring dependencies -->\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-core</artifactId>\n            <version>${spring.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-web</artifactId>\n            <version>${spring.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-webmvc</artifactId>\n            <version>${spring.version}</version>\n        </dependency>\n\n        <!-- JSTL tag library -->\n        <dependency>\n            <groupId>jstl</groupId>\n            <artifactId>jstl</artifactId>\n            <version>1.2</version>\n            <scope>compile</scope>\n        </dependency>\n        <dependency>\n            <groupId>taglibs</groupId>\n            <artifactId>standard</artifactId>\n            <version>1.1.2</version>\n            <scope>compile</scope>\n        </dependency>\n\n        <!-- Jackson Core (JSON helper) -->\n        <dependency>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-databind</artifactId>\n            <version>2.13.4.1</version>\n        </dependency>\n        <dependency>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-core</artifactId>\n            <version>2.10.0</version>\n        </dependency>\n        <!-- Apache Commons IO -->\n        <dependency>\n            <groupId>commons-io</groupId>\n            <artifactId>commons-io</artifactId>\n            <version>2.7</version>\n        </dependency>\n\n        <dependency>\n            <groupId>org.apache.commons</groupId>\n            <artifactId>commons-exec</artifactId>\n            <version>1.3</version>\n        </dependency>\n\n        <!-- Javax Servlet (Request/Response) -->\n        <dependency>\n            <groupId>javax.servlet</groupId>\n            <artifactId>javax.servlet-api</artifactId>\n            <version>3.1.0</version>\n            <scope>provided</scope>\n        </dependency>\n        <!-- Javax Servlet (JSP due to Tomcat dependency) -->\n        <dependency>\n            <groupId>javax.servlet</groupId>\n            <artifactId>jsp-api</artifactId>\n            <version>2.0</version>\n            <scope>provided</scope>\n        </dependency>\n\n        <!-- OpenCV (https://mvnrepository.com/artifact/org.openpnp/opencv) -->\n        <dependency>\n            <groupId>org.openpnp</groupId>\n            <artifactId>opencv</artifactId>\n            <version>3.2.0-1</version>\n        </dependency>\n\n        <!-- PDFBox https://mvnrepository.com/artifact/org.apache.pdfbox/pdfbox -->\n        <dependency>\n            <groupId>org.apache.pdfbox</groupId>\n            <artifactId>pdfbox</artifactId>\n            <version>2.0.24</version>\n        </dependency>\n\n        <!-- PDFBox-tools https://mvnrepository.com/artifact/org.apache.pdfbox/pdfbox-tools -->\n        <dependency>\n            <groupId>org.apache.pdfbox</groupId>\n            <artifactId>pdfbox-tools</artifactId>\n            <version>2.0.19</version>\n        </dependency>\n\n        <dependency>\n            <groupId>org.apache.pdfbox</groupId>\n            <artifactId>jbig2-imageio</artifactId>\n            <version>3.0.3</version>\n        </dependency>\n\n        <!-- Java Advanced Imaging (JAI) Image I/O Tools -->\n        <dependency>\n            <groupId>com.github.jai-imageio</groupId>\n            <artifactId>jai-imageio-core</artifactId>\n            <version>1.4.0</version>\n        </dependency>\n        <dependency>\n            <groupId>com.github.jai-imageio</groupId>\n            <artifactId>jai-imageio-jpeg2000</artifactId>\n            <version>1.3.0</version>\n        </dependency>\n        <dependency>\n            <groupId>javax.xml.bind</groupId>\n            <artifactId>jaxb-api</artifactId>\n            <version>2.3.1</version>\n        </dependency>\n        <!-- https://mvnrepository.com/artifact/org.docx4j/docx4j-JAXB-Internal -->\n        <dependency>\n            <groupId>org.docx4j</groupId>\n            <artifactId>docx4j-JAXB-Internal</artifactId>\n            <version>8.3.1</version>\n        </dependency>\n        <!-- PAGE XML -->\n        <dependency>\n            <groupId>org.primaresearch</groupId>\n            <artifactId>basic</artifactId>\n            <version>1.5b</version>\n        </dependency>\n        <dependency>\n            <groupId>org.primaresearch</groupId>\n            <artifactId>Dla</artifactId>\n            <version>1.5b</version>\n        </dependency>\n        <dependency>\n            <groupId>org.primaresearch</groupId>\n            <artifactId>Io</artifactId>\n            <version>1.5b</version>\n        </dependency>\n        <dependency>\n            <groupId>org.primaresearch</groupId>\n            <artifactId>Maths</artifactId>\n            <version>1.5b</version>\n        </dependency>\n\n    </dependencies>\n\n\n    <repositories>\n        <repository>\n            <id>Internal project repository</id>\n            <url>file://${basedir}/src/lib/repository</url>\n        </repository>\n    </repositories>\n\n    <distributionManagement>\n        <repository>\n            <id>central</id>\n            <name>artifactory-releases</name>\n            <url>https://artifactory-ls6.informatik.uni-wuerzburg.de/artifactory/libs-snapshot</url>\n        </repository>\n        <snapshotRepository>\n            <id>snapshots</id>\n            <name>artifactory-snapshots</name>\n            <url>https://artifactory-ls6.informatik.uni-wuerzburg.de/artifactory/libs-snapshot</url>\n        </snapshotRepository>\n    </distributionManagement>\n\n    <build>\n        <finalName>ocr4all</finalName>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-war-plugin</artifactId>\n                <version>3.3.1</version>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n",
            "error": "",
            "span_id": 12845481498026810262
        }
    ],
    "get_directory_tree": [],
    "get_language_server_suggestions": [],
    "reset_repo": []
}