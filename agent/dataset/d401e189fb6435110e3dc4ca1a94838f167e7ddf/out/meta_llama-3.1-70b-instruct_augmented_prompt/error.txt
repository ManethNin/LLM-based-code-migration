Traceback (most recent call last):
  File "/root/thesis/masterthesis-implementation-gpt/langchain-agent.py", line 992, in <module>
    first_shot_state = app.invoke(
                       ^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 1281, in invoke
    for chunk in self.stream(
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 966, in stream
    _panic_or_proceed(done, inflight, loop.step)
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 1367, in _panic_or_proceed
    raise exc
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/executor.py", line 60, in done
    task.result()
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/usr/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/pregel/retry.py", line 25, in run_with_retry
    task.proc.invoke(task.input, task.config)
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py", line 2873, in invoke
    input = step.invoke(input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langgraph/utils.py", line 102, in invoke
    ret = context.run(self.func, input, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/langchain-agent.py", line 943, in call_model
    response = llm_with_tools.invoke(messages)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py", line 5060, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 274, in invoke
    self.generate_prompt(
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 714, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 571, in generate
    raise e
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 561, in generate
    self._generate_with_cache(
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 793, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_nvidia_ai_endpoints/chat_models.py", line 289, in _generate
    response = self._client.get_req(payload=payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_nvidia_ai_endpoints/_common.py", line 460, in get_req
    response, session = self._post(self.infer_url, payload)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_nvidia_ai_endpoints/_common.py", line 357, in _post
    self._try_raise(response)
  File "/root/thesis/masterthesis-implementation-gpt/.venv/lib/python3.12/site-packages/langchain_nvidia_ai_endpoints/_common.py", line 450, in _try_raise
    raise Exception(f"{header}\n{body}") from None
Exception: [400] Bad Request
This model's maximum context length is 131072 tokens. However, you requested 134667 tokens (133643 in the messages, 1024 in the completion). Please reduce the length of the messages or completion.
RequestID: d671a294-efeb-499f-ae49-f3c8e67cf6e4
